{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "BIEdHLeqDLJH",
    "outputId": "bd25ca97-2443-4c65-d804-d9c0ff7b5586"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "root_path = './'\n",
    "dataset_path = os.path.join(root_path, 'tf_dataset')\n",
    "\n",
    "models_path = os.path.join(root_path, 'saved_models')\n",
    "if not os.path.exists(models_path):\n",
    "  os.mkdir(models_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWYY-ez0D6wt"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "image_feature_description = {\n",
    "    'enc': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    'age': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "    'img': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True)\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "\n",
    "raw_train_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path,'train.tfrecords'))\n",
    "parsed_train_dataset = raw_train_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_val_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'val.tfrecords'))\n",
    "parsed_val_dataset = raw_val_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_test_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'test.tfrecords'))\n",
    "parsed_test_dataset = raw_test_dataset.map(_parse_image_function)\n",
    "\n",
    "\n",
    "parsed_train_dataset = parsed_train_dataset.repeat()\n",
    "parsed_train_dataset = parsed_train_dataset.shuffle(1000)\n",
    "parsed_train_dataset = parsed_train_dataset.batch(BATCH_SIZE)\n",
    "dataset_iterator = parsed_train_dataset.make_one_shot_iterator()\n",
    "\n",
    "variable_dataset = dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAuHCfjlFBOy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "enc_len = 128\n",
    "age_len = 8\n",
    "img_shape = (32, 32, 3)\n",
    "width, height, depth = (32, 32, 3)\n",
    "img_len = np.prod(img_shape)\n",
    "latent_dim = enc_len + age_len + img_len\n",
    "noise_len = 16  # 32 x 32 x 3\n",
    "input_dim = enc_len + age_len + noise_len\n",
    "cond_len = enc_len + age_len\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(144, input_shape=(latent_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Dense(1),\n",
    "        keras.layers.Activation(tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # image\n",
    "    z = keras.layers.Input(shape=img_shape)\n",
    "    \n",
    "    # flatten image\n",
    "    z_flat = keras.layers.Flatten()(z)\n",
    "    \n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, z_flat])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, z], outputs)\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    model = keras.Sequential([\n",
    "        \n",
    "        # dense 1\n",
    "        keras.layers.Dense(144, input_shape=(input_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((12, 12, 1)),\n",
    "        \n",
    "        # transpose conv block 1\n",
    "        keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # transpose conv block 2\n",
    "        keras.layers.Conv2DTranspose(filters=2, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # flatten\n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        # dense 3\n",
    "        keras.layers.Dense(3072),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((width, height, depth)),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Activation(tf.nn.tanh),\n",
    "    ])\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # noise\n",
    "    x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, x])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, x], outputs)\n",
    "\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfo8J8jQ4-FH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 152)          0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 32, 32, 3)    14180910    concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 14,180,910\n",
      "Trainable params: 14,180,910\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObTb7HIf5CqA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 3072)         0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3208)         0           input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1)            462241      concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 462,241\n",
      "Trainable params: 462,241\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHTmYpPeImn5"
   },
   "outputs": [],
   "source": [
    "GLR = 0.02  # generator\n",
    "DLR = 0.001  # discriminator\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=DLR),\n",
    "    loss=keras.losses.kullback_leibler_divergence,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# condition\n",
    "c1 = keras.layers.Input(shape=(enc_len,))\n",
    "c2 = keras.layers.Input(shape=(age_len,))\n",
    "\n",
    "# noise\n",
    "x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "# freeze discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# output\n",
    "z = generator([c1, c2, x])\n",
    "out = discriminator([c1, c2, z])\n",
    "\n",
    "# GAN\n",
    "gan = keras.models.Model(inputs=[c1, c2, x], outputs=out)\n",
    "\n",
    "gan.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=GLR),\n",
    "    loss=keras.losses.kullback_leibler_divergence,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 32, 32, 3)    14180910    input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 1)            462241      input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,643,151\n",
      "Trainable params: 14,180,910\n",
      "Non-trainable params: 462,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "iSszxe2oKY02",
    "outputId": "ee5ce939-c513-4c70-9983-ae17faca6d67"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "STEPS = 1024 // BATCH_SIZE\n",
    "\n",
    "\n",
    "train_loss_g = []\n",
    "train_loss_d = []\n",
    "\n",
    "train_acc_g = []\n",
    "train_acc_d = []\n",
    "\n",
    "\n",
    "y_fake = tf.zeros((BATCH_SIZE,))\n",
    "y_true = tf.ones((BATCH_SIZE,))\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "  K.set_session(sess)\n",
    "  \n",
    "  tf.initialize_all_variables().run()\n",
    "\n",
    "  # run once\n",
    "  y_fake = y_fake.eval()\n",
    "  y_true = y_true.eval()\n",
    "\n",
    "  # epochs\n",
    "  for e in range(EPOCHS):\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "      values = sess.run([variable_dataset])\n",
    "      row = values[0]\n",
    "\n",
    "      sz = row['img'].shape[0]\n",
    "\n",
    "#       if sz != BATCH_SIZE:\n",
    "#         continue\n",
    "\n",
    "      # train discriminator\n",
    "\n",
    "      # fake data\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      x = tf.random.normal((sz, noise_len,)).eval()\n",
    "      z_fake = generator.predict([c1, c2, x])\n",
    "\n",
    "      # real data\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      z_real = tf.reshape(tf.io.decode_raw(row['img'], tf.uint8), (-1, width, height, depth)).eval()\n",
    "\n",
    "      # train\n",
    "      loss_1, acc_1 = discriminator.train_on_batch([c1, c2, z_fake], y_fake)\n",
    "      loss_2, acc_2 = discriminator.train_on_batch([c1, c2, z_real], y_true)\n",
    "\n",
    "      batch_loss = 0.5 * (float(tf.reduce_mean(loss_1).eval()) + float(tf.reduce_mean(loss_2).eval()))\n",
    "      batch_acc = 0.5 * (float(tf.reduce_mean(acc_1).eval()) + float(tf.reduce_mean(acc_2).eval()))\n",
    "\n",
    "      loss.append(batch_loss)\n",
    "      acc.append(batch_acc)\n",
    "\n",
    "    train_loss_d.append(np.mean(np.array(loss)))\n",
    "    train_acc_d.append(np.mean(np.array(acc)))\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "      values = sess.run([variable_dataset])\n",
    "      row = values[0]\n",
    "\n",
    "      sz = row['img'].shape[0]\n",
    "\n",
    "#       if sz != BATCH_SIZE:\n",
    "#         continue\n",
    "\n",
    "      # train generator\n",
    "\n",
    "      # concatenate face + age + noise\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      x = tf.random.normal((sz, noise_len,)).eval()\n",
    "\n",
    "      # train\n",
    "      loss_1, acc_1 = gan.train_on_batch([c1, c2, x], y_true)\n",
    "\n",
    "      batch_loss = float(tf.reduce_mean(loss_1).eval())\n",
    "      batch_acc = float(tf.reduce_mean(acc_1).eval())\n",
    "\n",
    "      loss.append(batch_loss)\n",
    "      acc.append(batch_acc)\n",
    "\n",
    "    train_loss_g.append(np.mean(np.array(loss)))\n",
    "    train_acc_g.append(np.mean(np.array(acc)))\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, Steps: {}, Discriminator Loss: {:.3f}, Discriminator Accuracy: %{:.2f}, GAN Loss: {:.3f}, GAN Accuracy: %{:.2f}\".format(\n",
    "          e,\n",
    "          STEPS,\n",
    "          train_loss_d[-1],\n",
    "          train_loss_g[-1],\n",
    "          train_acc_d[-1],\n",
    "          train_acc_g[-1]\n",
    "      ))\n",
    " \n",
    "    if e % 100 == 1:\n",
    "\n",
    "      pth = os.path.join(models_path, 'gan.h5')\n",
    "      gan.save(pth)\n",
    "\n",
    "      pth = os.path.join(models_path, 'generator-{}-{}-{}.h5'.format(e, train_loss_g[-1], train_acc_g[-1]))\n",
    "      generator.save(pth)\n",
    "\n",
    "      pth = os.path.join(models_path, 'discriminator.h5')\n",
    "      discriminator.save(pth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LzhKde-CaDu"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss_g, label=\"Generator Loss\");\n",
    "plt.plot(train_loss_d, label=\"Discriminator Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YhSUa3fROSg"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_acc_g, label=\"Generator Accuracy\");\n",
    "plt.plot(train_acc_d, label=\"Discriminator Accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E93kpBKFC84Z"
   },
   "source": [
    "## Visualize Generator Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 3) (32, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f9db469c4a8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    values = sess.run([variable_dataset])\n",
    "    row = values[0]\n",
    "\n",
    "    sz = row['img'].shape[0]\n",
    "\n",
    "    # fake data\n",
    "    c1 = row['enc']\n",
    "    c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "    x = tf.random.normal((sz, noise_len,)).eval()\n",
    "    z_fake = generator.predict([c1, c2, x])\n",
    "\n",
    "print(z_fake.shape, row['img'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Standalone Keras AGE-CGAN",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
