{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "BIEdHLeqDLJH",
    "outputId": "bd25ca97-2443-4c65-d804-d9c0ff7b5586"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "root_path = './'\n",
    "dataset_path = os.path.join(root_path, 'tf_dataset')\n",
    "\n",
    "models_path = os.path.join(root_path, 'saved_models')\n",
    "if not os.path.exists(models_path):\n",
    "  os.mkdir(models_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWYY-ez0D6wt"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "image_feature_description = {\n",
    "    'enc': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    'age': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "    'img': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True)\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "\n",
    "raw_train_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path,'train.tfrecords'))\n",
    "parsed_train_dataset = raw_train_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_val_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'val.tfrecords'))\n",
    "parsed_val_dataset = raw_val_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_test_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'test.tfrecords'))\n",
    "parsed_test_dataset = raw_test_dataset.map(_parse_image_function)\n",
    "\n",
    "\n",
    "parsed_train_dataset = parsed_train_dataset.repeat()\n",
    "parsed_train_dataset = parsed_train_dataset.shuffle(1000)\n",
    "parsed_train_dataset = parsed_train_dataset.batch(BATCH_SIZE)\n",
    "dataset_iterator = parsed_train_dataset.make_one_shot_iterator()\n",
    "\n",
    "variable_dataset = dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAuHCfjlFBOy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "enc_len = 128\n",
    "age_len = 8\n",
    "img_shape = (32, 32, 3)\n",
    "width, height, depth = (32, 32, 3)\n",
    "img_len = np.prod(img_shape)\n",
    "latent_dim = enc_len + age_len + img_len\n",
    "noise_len = 16  # 32 x 32 x 3\n",
    "input_dim = enc_len + age_len + noise_len\n",
    "cond_len = enc_len + age_len\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(144, input_shape=(latent_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Dense(1),\n",
    "        keras.layers.Activation(tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # image\n",
    "    z = keras.layers.Input(shape=img_shape)\n",
    "    \n",
    "    # flatten image\n",
    "    z_flat = keras.layers.Flatten()(z)\n",
    "    \n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, z_flat])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, z], outputs)\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    model = keras.Sequential([\n",
    "        \n",
    "        # dense 1\n",
    "        keras.layers.Dense(144, input_shape=(input_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((12, 12, 1)),\n",
    "        \n",
    "        # transpose conv block 1\n",
    "        keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # transpose conv block 2\n",
    "        keras.layers.Conv2DTranspose(filters=2, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # flatten\n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        # dense 3\n",
    "        keras.layers.Dense(3072),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((width, height, depth)),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Activation(tf.nn.tanh),\n",
    "    ])\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # noise\n",
    "    x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, x])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, x], outputs)\n",
    "\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfo8J8jQ4-FH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 152)          0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 32, 32, 3)    14180910    concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 14,180,910\n",
      "Trainable params: 14,180,910\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObTb7HIf5CqA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 3072)         0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3208)         0           input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1)            462241      concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 462,241\n",
      "Trainable params: 462,241\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHTmYpPeImn5"
   },
   "outputs": [],
   "source": [
    "GLR = 0.001  # generator\n",
    "DLR = 0.02  # discriminator\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=DLR),\n",
    "    loss=keras.losses.kullback_leibler_divergence,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# condition\n",
    "c1 = keras.layers.Input(shape=(enc_len,))\n",
    "c2 = keras.layers.Input(shape=(age_len,))\n",
    "\n",
    "# noise\n",
    "x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "# freeze discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# output\n",
    "z = generator([c1, c2, x])\n",
    "out = discriminator([c1, c2, z])\n",
    "\n",
    "# GAN\n",
    "gan = keras.models.Model(inputs=[c1, c2, x], outputs=out)\n",
    "\n",
    "gan.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=GLR),\n",
    "    loss=keras.losses.kullback_leibler_divergence,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 32, 32, 3)    14180910    input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 1)            462241      input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,643,151\n",
      "Trainable params: 14,180,910\n",
      "Non-trainable params: 462,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeGAN(e, z_real, z_fake):\n",
    "\n",
    "    fig, axes = plt.subplots(8, 8, figsize=(40, 36))\n",
    "\n",
    "    r_real = 0\n",
    "    r_fake = 0\n",
    "    for row, axe in enumerate(axes):\n",
    "        for col, cell in enumerate(axe):\n",
    "            if row % 2 == 0:\n",
    "                cell.imshow(z_real[r_real * 8 + col])\n",
    "            else:\n",
    "                cell.imshow(z_fake[r_fake * 8 + col])\n",
    "\n",
    "            cell.axis(\"off\")\n",
    "\n",
    "        if row % 2 == 0:\n",
    "            r_real += 1\n",
    "        else:\n",
    "            r_fake += 1\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if not os.path.exists('./visuals'):\n",
    "        os.mkdir('./visuals')\n",
    "    \n",
    "    fig.savefig('./visuals/{}.jpg'.format(str(e).zfill(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "iSszxe2oKY02",
    "outputId": "ee5ce939-c513-4c70-9983-ae17faca6d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Steps: 32, Discriminator Loss: 0.027, Discriminator Accuracy: %0.00, GAN Loss: 49.945, GAN Accuracy: %100.00\n",
      "Epoch: 1, Steps: 32, Discriminator Loss: -0.000, Discriminator Accuracy: %0.00, GAN Loss: 50.000, GAN Accuracy: %100.00\n",
      "Epoch: 2, Steps: 32, Discriminator Loss: -0.000, Discriminator Accuracy: %0.00, GAN Loss: 50.000, GAN Accuracy: %100.00\n",
      "Epoch: 3, Steps: 32, Discriminator Loss: -0.000, Discriminator Accuracy: %0.00, GAN Loss: 50.000, GAN Accuracy: %100.00\n",
      "Epoch: 4, Steps: 32, Discriminator Loss: -0.000, Discriminator Accuracy: %0.00, GAN Loss: 50.000, GAN Accuracy: %100.00\n",
      "Epoch: 5, Steps: 32, Discriminator Loss: -0.000, Discriminator Accuracy: %0.00, GAN Loss: 50.000, GAN Accuracy: %100.00\n",
      "Epoch: 6, Steps: 32, Discriminator Loss: -0.000, Discriminator Accuracy: %0.00, GAN Loss: 50.000, GAN Accuracy: %100.00\n",
      "Epoch: 7, Steps: 32, Discriminator Loss: -0.000, Discriminator Accuracy: %0.00, GAN Loss: 50.000, GAN Accuracy: %100.00\n",
      "Epoch: 8, Steps: 32, Discriminator Loss: -0.000, Discriminator Accuracy: %0.00, GAN Loss: 50.000, GAN Accuracy: %100.00\n",
      "Epoch: 9, Steps: 32, Discriminator Loss: -0.000, Discriminator Accuracy: %0.00, GAN Loss: 50.000, GAN Accuracy: %100.00\n",
      "Epoch: 10, Steps: 32, Discriminator Loss: -0.000, Discriminator Accuracy: %0.00, GAN Loss: 50.000, GAN Accuracy: %100.00\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "STEPS = 1024 // BATCH_SIZE\n",
    "\n",
    "\n",
    "train_loss_g = []\n",
    "train_loss_d = []\n",
    "\n",
    "train_acc_g = []\n",
    "train_acc_d = []\n",
    "\n",
    "\n",
    "y_fake = tf.zeros((BATCH_SIZE,))\n",
    "y_true = tf.ones((BATCH_SIZE,))\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "  K.set_session(sess)\n",
    "  \n",
    "  tf.initialize_all_variables().run()\n",
    "\n",
    "  # run once\n",
    "  y_fake = y_fake.eval()\n",
    "  y_true = y_true.eval()\n",
    "\n",
    "  # epochs\n",
    "  for e in range(EPOCHS):\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS * 8):\n",
    "\n",
    "      values = sess.run([variable_dataset])\n",
    "      row = values[0]\n",
    "\n",
    "      sz = row['img'].shape[0]\n",
    "\n",
    "#       if sz != BATCH_SIZE:\n",
    "#         continue\n",
    "\n",
    "      # train discriminator\n",
    "\n",
    "      # fake data\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      x = tf.random.normal((sz, noise_len,)).eval()\n",
    "      z_fake = generator.predict([c1, c2, x])\n",
    "\n",
    "      # real data\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      z_real = tf.reshape(tf.io.decode_raw(row['img'], tf.uint8), (-1, width, height, depth)).eval()\n",
    "\n",
    "      # train\n",
    "      loss_1, acc_1 = discriminator.train_on_batch([c1, c2, z_fake], y_fake)\n",
    "      loss_2, acc_2 = discriminator.train_on_batch([c1, c2, z_real], y_true)\n",
    "\n",
    "      batch_loss = 0.5 * (loss_1 + loss_2)\n",
    "      batch_acc = 0.5 * (acc_1 + acc_2)\n",
    "\n",
    "      loss.append(batch_loss)\n",
    "      acc.append(batch_acc)\n",
    "    \n",
    "    train_loss_d.append(np.mean(np.array(loss)))\n",
    "    train_acc_d.append(np.mean(np.array(acc)))\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "      values = sess.run([variable_dataset])\n",
    "      row = values[0]\n",
    "\n",
    "      sz = row['img'].shape[0]\n",
    "\n",
    "#       if sz != BATCH_SIZE:\n",
    "#         continue\n",
    "\n",
    "      # train generator\n",
    "\n",
    "      # concatenate face + age + noise\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      x = tf.random.normal((sz, noise_len,)).eval()\n",
    "\n",
    "      # train\n",
    "      loss_1, acc_1 = gan.train_on_batch([c1, c2, x], y_true)\n",
    "\n",
    "      loss.append(loss_1)\n",
    "      acc.append(acc_1)\n",
    "\n",
    "    train_loss_g.append(np.mean(np.array(loss)))\n",
    "    train_acc_g.append(np.mean(np.array(acc)))\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, Steps: {}, Discriminator Loss: {:.3f}, Discriminator Accuracy: %{:.2f}, GAN Loss: {:.3f}, GAN Accuracy: %{:.2f}\".format(\n",
    "          e,\n",
    "          STEPS,\n",
    "          train_loss_d[-1],\n",
    "          train_loss_g[-1],\n",
    "          train_acc_d[-1] * 100,\n",
    "          train_acc_g[-1] * 100\n",
    "      ))\n",
    " \n",
    "    if e % 10 == 0:\n",
    "\n",
    "      pth = os.path.join(models_path, 'gan.h5')\n",
    "      gan.save(pth)\n",
    "\n",
    "      pth = os.path.join(models_path, 'generator-{}-{}-{}.h5'.format(e, train_loss_g[-1], train_acc_g[-1]))\n",
    "      generator.save(pth)\n",
    "\n",
    "      pth = os.path.join(models_path, 'discriminator.h5')\n",
    "      discriminator.save(pth)\n",
    "    \n",
    "    ## visualize results\n",
    "    values = sess.run([variable_dataset])\n",
    "    row = values[0]\n",
    "\n",
    "    sz = row['img'].shape[0]\n",
    "\n",
    "    # fake data\n",
    "    c1 = row['enc']\n",
    "    c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "    x = tf.random.normal((sz, noise_len,)).eval()\n",
    "    z_fake = generator.predict([c1, c2, x])\n",
    "    \n",
    "    # real data\n",
    "    z_real = tf.reshape(tf.io.decode_raw(row['img'], tf.uint8), (-1, width, height, depth)).eval()\n",
    "    \n",
    "    visualizeGAN(e, z_real, z_fake)\n",
    "\n",
    "        \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LzhKde-CaDu"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_loss_g, label=\"Generator Loss\");\n",
    "plt.plot(train_loss_d, label=\"Discriminator Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YhSUa3fROSg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_acc_g, label=\"Generator Accuracy\");\n",
    "plt.plot(train_acc_d, label=\"Discriminator Accuracy\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E93kpBKFC84Z"
   },
   "source": [
    "## Visualize Generator Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    values = sess.run([variable_dataset])\n",
    "    row = values[0]\n",
    "\n",
    "    sz = row['img'].shape[0]\n",
    "\n",
    "    # fake data\n",
    "    c1 = row['enc']\n",
    "    c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "    x = tf.random.normal((sz, noise_len,)).eval()\n",
    "    z_fake = generator.predict([c1, c2, x])\n",
    "    \n",
    "    # real data\n",
    "    z_real = tf.reshape(tf.io.decode_raw(row['img'], tf.uint8), (-1, width, height, depth)).eval()\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(8, 8, figsize=(40, 36))\n",
    "\n",
    "r_real = 0\n",
    "r_fake = 0\n",
    "for row, axe in enumerate(axes):\n",
    "    for col, cell in enumerate(axe):\n",
    "        if row % 2 == 0:\n",
    "            cell.imshow(z_real[r_real * 8 + col])\n",
    "        else:\n",
    "            cell.imshow(z_fake[r_fake * 8 + col])\n",
    "\n",
    "        cell.axis(\"off\")\n",
    "    \n",
    "    if row % 2 == 0:\n",
    "        r_real += 1\n",
    "    else:\n",
    "        r_fake += 1\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.show();\n",
    "\n",
    "if not os.path.exists('./visuals'):\n",
    "    os.mkdir('./visuals')\n",
    "fig.savefig('./visuals/{}.jpg'.format(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Standalone Keras AGE-CGAN",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
