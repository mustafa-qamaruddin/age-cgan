{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "./faces-data-new\n",
      "Found 7864 images belonging to 1 classes.\n",
      "(32, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "root_path = './'\n",
    "dataset_path = os.path.join(root_path, 'faces-data-new')\n",
    "\n",
    "print(dataset_path)\n",
    "\n",
    "models_path = os.path.join(root_path, 'saved_models_new')\n",
    "if not os.path.exists(models_path):\n",
    "    os.mkdir(models_path)\n",
    "\n",
    "\n",
    "tgt_pth = os.path.join(root_path, 'visualize_dcgan-v1')\n",
    "\n",
    "if not os.path.exists(tgt_pth):\n",
    "    os.mkdir(tgt_pth)\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "img_rows, img_cols, img_depth = (196, 196, 3)\n",
    "\n",
    "\n",
    "def rescaleFn(img):\n",
    "    return img / 127.5 - 1\n",
    "\n",
    "\n",
    "datagen=ImageDataGenerator(preprocessing_function=rescaleFn)\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=dataset_path,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "STEP_SIZE=train_generator.n//train_generator.batch_size\n",
    "\n",
    "\n",
    "X = next(train_generator)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_8 (Reshape)          (None, 10, 10, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_30 (Conv2DT (None, 22, 22, 512)       8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_31 (Conv2DT (None, 46, 46, 256)       2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 46, 46, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 46, 46, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_32 (Conv2DT (None, 94, 94, 128)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 94, 94, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 94, 94, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_33 (Conv2DT (None, 97, 97, 64)        131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 97, 97, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 97, 97, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_34 (Conv2DT (None, 196, 196, 3)       3072      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 196, 196, 3)       0         \n",
      "=================================================================\n",
      "Total params: 2,767,616\n",
      "Trainable params: 2,765,696\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 97, 97, 64)        3072      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 97, 97, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 47, 47, 128)       131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 47, 47, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 47, 47, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 22, 22, 256)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 22, 22, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 10, 10, 512)       2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 1, 1, 1)           41472     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1, 1, 1)           0         \n",
      "=================================================================\n",
      "Total params: 2,800,640\n",
      "Trainable params: 2,798,848\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_shape = (196, 196, 3)\n",
    "img_len = np.prod(img_shape)\n",
    "latent_dim = img_len\n",
    "noise_len = 100\n",
    "input_dim = noise_len\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    return keras.Sequential([\n",
    "        # conv block 1\n",
    "        keras.layers.Conv2D(\n",
    "            filters=ndf,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=2,\n",
    "            input_shape=img_shape,\n",
    "            use_bias=False\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        \n",
    "        # conv block 2\n",
    "        keras.layers.Conv2D(\n",
    "            filters=ndf * 2,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=2,\n",
    "            use_bias=False\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        \n",
    "        # conv block 3\n",
    "        keras.layers.Conv2D(\n",
    "            filters=ndf * 4,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=2,\n",
    "            use_bias=False\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        \n",
    "        # conv block 4\n",
    "        keras.layers.Conv2D(\n",
    "            filters=ndf * 8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=2,\n",
    "            use_bias=False\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        \n",
    "        # conv block 5\n",
    "        keras.layers.Conv2D(\n",
    "            filters=1,\n",
    "            kernel_size=(9, 9),\n",
    "            strides=2,\n",
    "            use_bias=False\n",
    "        ),\n",
    "        \n",
    "        #output\n",
    "        keras.layers.Activation(tf.nn.sigmoid)\n",
    "    ])\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    \n",
    "    return keras.Sequential([\n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((10, 10, 1), input_shape=(input_dim,)),\n",
    "        \n",
    "        # transpose conv block 1\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=ngf * 8,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=2,\n",
    "            use_bias=False\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # transpose conv block 2\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=ngf * 4,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=2,\n",
    "            use_bias=False\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # transpose conv block 3\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=ngf * 2,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=2,\n",
    "            use_bias=False\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # transpose conv block 4\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=ngf,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=1,\n",
    "            use_bias=False\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # transpose conv block 5\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=3,\n",
    "            kernel_size=(4, 4),\n",
    "            strides=2,\n",
    "            use_bias=False\n",
    "        ),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Activation(tf.nn.tanh)\n",
    "    ])\n",
    "\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "generator = build_generator()\n",
    "\n",
    "generator.summary()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLR = 0.0002  # generator\n",
    "DLR = 0.0002  # discriminator\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(DLR, 0.5),\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# noise\n",
    "x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "# freeze discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# output\n",
    "z = generator(x)\n",
    "out = discriminator(z)\n",
    "\n",
    "# GAN\n",
    "gan = keras.models.Model(inputs=x, outputs=out)\n",
    "\n",
    "gan.compile(\n",
    "    optimizer=keras.optimizers.Adam(GLR , 0.5),\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeGAN(e, z_real, z_fake):\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 18))\n",
    "\n",
    "    r_real = 0\n",
    "    r_fake = 0\n",
    "    for row, axe in enumerate(axes):\n",
    "        for col, cell in enumerate(axe):\n",
    "            if row % 2 == 0:\n",
    "                cell.imshow(\n",
    "                    np.squeeze(\n",
    "                        0.5 * z_real[r_real * 4 + col] + 0.5,\n",
    "                        axis=-1\n",
    "                    ),\n",
    "                    cmap='gray'\n",
    "                )\n",
    "            else:\n",
    "                cell.imshow(\n",
    "                    np.squeeze(\n",
    "                        0.5 * z_fake[r_fake * 4 + col] + 0.5,\n",
    "                        axis=-1\n",
    "                    ),\n",
    "                    cmap='gray'\n",
    "                )\n",
    "\n",
    "            cell.axis(\"off\")\n",
    "\n",
    "        if row % 2 == 0:\n",
    "            r_real += 1\n",
    "        else:\n",
    "            r_fake += 1\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(os.path.join(tgt_pth, '{}.jpg'.format(str(e).zfill(3))))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 101\n",
    "STEPS = 1\n",
    "\n",
    "\n",
    "train_loss_g = []\n",
    "train_loss_d = []\n",
    "\n",
    "train_acc_g = []\n",
    "train_acc_d = []\n",
    "\n",
    "\n",
    "# to be visualized\n",
    "vis_noise = np.random.normal(size=(16, noise_len,))\n",
    "print(vis_noise.shape)\n",
    "\n",
    "# fake and real label\n",
    "y_fake = np.zeros(size=(BATCH_SIZE,))\n",
    "y_real = np.ones(size=(BATCH_SIZE,))\n",
    "\n",
    "\n",
    "# epochs\n",
    "for e in range(EPOCHS):\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "        \n",
    "        x, z_fake, y_fake, z_real, y_real = next(disc_itr)\n",
    "        z = np.random.normal(size=(BATCH_SIZE, noise_len))\n",
    "        x_fake = generator.predict(z)\n",
    "        x_real = next(train_generator)\n",
    "\n",
    "        # train\n",
    "        loss_2, acc_2 = discriminator.train_on_batch(x_real, y_real)\n",
    "        loss_1, acc_1 = discriminator.train_on_batch(x_fake, y_fake)\n",
    "\n",
    "        batch_loss = 0.5 * (loss_1 + loss_2)\n",
    "        batch_acc = 0.5 * (acc_1 + acc_2)\n",
    "\n",
    "        loss.append(batch_loss)\n",
    "        acc.append(batch_acc)\n",
    "\n",
    "    train_loss_d.append(np.mean(np.array(loss)))\n",
    "    train_acc_d.append(np.mean(np.array(acc)))\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "        z = np.random.normal(size=(BATCH_SIZE, noise_len))\n",
    "\n",
    "        # train\n",
    "        loss_1, acc_1 = gan.train_on_batch(z, y_true)\n",
    "\n",
    "        loss.append(loss_1)\n",
    "        acc.append(acc_1)\n",
    "\n",
    "    train_loss_g.append(np.mean(np.array(loss)))\n",
    "    train_acc_g.append(np.mean(np.array(acc)))\n",
    "\n",
    "\n",
    "    print(\"E: {}, [D ACC: %{:.2f}], [D LOSS: {:.2f}], [G ACC: %{:.2f}], [G LOSS: {:.2f}]\".format(\n",
    "          e,\n",
    "          train_acc_d[-1] * 100,\n",
    "          train_loss_d[-1] * 100,\n",
    "          train_acc_g[-1] * 100,\n",
    "          train_loss_g[-1] * 100\n",
    "      ))\n",
    "\n",
    "    if e % 25 == 0:\n",
    "        ## visualize results\n",
    "        viz_fake = generator.predict(vis_noise)\n",
    "        visualizeGAN(e, viz_real, viz_fake)\n",
    "        \n",
    "        ## save model\n",
    "        pth = os.path.join(models_path, 'gan.h5')\n",
    "        gan.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'generator-{}-{}-{}.h5'.format(e, train_loss_g[-1], train_acc_g[-1]))\n",
    "        generator.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'discriminator.h5')\n",
    "        discriminator.save(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_loss_g, label=\"Generator Loss\");\n",
    "plt.plot(train_loss_d, label=\"Discriminator Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_acc_g, label=\"Generator Accuracy\");\n",
    "plt.plot(train_acc_d, label=\"Discriminator Accuracy\");\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
