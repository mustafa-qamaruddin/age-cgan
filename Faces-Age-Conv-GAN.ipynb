{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAQBOBYyi9sc"
   },
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1554977904593,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "BIEdHLeqDLJH",
    "outputId": "90567bca-f98c-4b16-c01f-adc92d510da4"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "root_path = './'\n",
    "dataset_path = os.path.join(root_path, 'tf_dataset')\n",
    "\n",
    "models_path = os.path.join(root_path, 'saved_models')\n",
    "if not os.path.exists(models_path):\n",
    "  os.mkdir(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2751,
     "status": "ok",
     "timestamp": 1554977904597,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "MxSDNtvqj0Xs",
    "outputId": "876f60f6-e4ef-4454-bfa5-f3ff6b5a8f17"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "image_feature_description = {\n",
    "    'enc': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    'age': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "    'img': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True)\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "\n",
    "raw_train_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path,'train.tfrecords'))\n",
    "parsed_train_dataset = raw_train_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_val_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'val.tfrecords'))\n",
    "parsed_val_dataset = raw_val_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_test_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'test.tfrecords'))\n",
    "parsed_test_dataset = raw_test_dataset.map(_parse_image_function)\n",
    "\n",
    "\n",
    "parsed_train_dataset = parsed_train_dataset.repeat()\n",
    "parsed_train_dataset = parsed_train_dataset.shuffle(1000)\n",
    "parsed_train_dataset = parsed_train_dataset.batch(BATCH_SIZE)\n",
    "dataset_iterator = parsed_train_dataset.make_one_shot_iterator()\n",
    "\n",
    "variable_dataset = dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMouydu3i9sp"
   },
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3123,
     "status": "ok",
     "timestamp": 1554977905340,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "HAuHCfjlFBOy",
    "outputId": "abf88c5b-9df8-41dc-9017-9d8a2007a0b4"
   },
   "outputs": [],
   "source": [
    "enc_len = 128\n",
    "age_len = 8\n",
    "img_shape = (32, 32, 3)\n",
    "width, height, depth = (32, 32, 3)\n",
    "img_len = np.prod(img_shape)\n",
    "latent_dim = enc_len + age_len + img_len\n",
    "noise_len = 100\n",
    "input_dim = enc_len + age_len + noise_len\n",
    "cond_len = enc_len + age_len\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    conv = keras.Sequential([\n",
    "        # conv block 1\n",
    "        keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2,\n",
    "            input_shape=img_shape\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "\n",
    "        # conv block 2\n",
    "        keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        \n",
    "        # conv block 3\n",
    "        keras.layers.Conv2D(\n",
    "            filters=3,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "    ])\n",
    "    \n",
    "    conv.summary()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(128, input_shape=(27+128+8,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Dense(1),\n",
    "        keras.layers.Activation(tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # image\n",
    "    z = keras.layers.Input(shape=img_shape)\n",
    "    \n",
    "    # convolution\n",
    "    zout = conv(z)\n",
    "    \n",
    "    # flatten image\n",
    "    z_flat = keras.layers.Flatten()(zout)\n",
    "    \n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, z_flat])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, z], outputs)\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    \n",
    "    conv = keras.Sequential([\n",
    "        # transpose conv block 1\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=1,\n",
    "            input_shape=(11, 11, 1)\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # transpose conv block 2\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # transpose conv block 3\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=(2, 2),\n",
    "            strides=1\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "\n",
    "        # transpose conv block 4\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=3,\n",
    "            kernel_size=(5, 5),\n",
    "            strides=1\n",
    "        ),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Activation(tf.nn.tanh)\n",
    "    ])\n",
    "    \n",
    "    conv.summary()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(121, input_shape=(input_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((11, 11, 1))\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # noise\n",
    "    x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, x])\n",
    "    \n",
    "    # flat dense output\n",
    "    out_1 = model(inputs)\n",
    "    \n",
    "    # transpose conv output\n",
    "    outputs = conv(out_1)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, x], outputs)\n",
    "\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3046,
     "status": "ok",
     "timestamp": 1554977905345,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "tfo8J8jQ4-FH",
    "outputId": "022c24ae-1c6e-40ad-e167-964953449961"
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3013,
     "status": "ok",
     "timestamp": 1554977905348,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "ObTb7HIf5CqA",
    "outputId": "1bdb05c0-cd96-46c6-a124-68ac9ee9ddb8"
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctWfkxy5i9tR"
   },
   "source": [
    "## Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHTmYpPeImn5"
   },
   "outputs": [],
   "source": [
    "GLR = 0.002  # generator\n",
    "DLR = 0.002  # discriminator\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(DLR, 0.5),\n",
    "    loss=d_loss,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# condition\n",
    "c1 = keras.layers.Input(shape=(enc_len,))\n",
    "c2 = keras.layers.Input(shape=(age_len,))\n",
    "\n",
    "# noise\n",
    "x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "# freeze discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# output\n",
    "z = generator([c1, c2, x])\n",
    "out = discriminator([c1, c2, z])\n",
    "\n",
    "# GAN\n",
    "gan = keras.models.Model(inputs=[c1, c2, x], outputs=out)\n",
    "\n",
    "gan.compile(\n",
    "    optimizer=keras.optimizers.Adam(GLR , 0.5),\n",
    "    loss=d_loss,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1554977905707,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "o_76rZ0ti9tc",
    "outputId": "8eb9fa73-4621-40e3-fab1-fd2d52d7bbe2"
   },
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REaxJyLqi9tp"
   },
   "source": [
    "## Visualization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25210,
     "status": "ok",
     "timestamp": 1554977927807,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "4kA4g6_lt3D8",
    "outputId": "c5b38cce-ad98-49ac-9b13-950a8e2356ca"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os\n",
    "\n",
    "\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "root_path = './'\n",
    "tgt_pth = os.path.join(root_path, 'visualize_age-cgan-v1')\n",
    "\n",
    "if not os.path.exists(tgt_pth):\n",
    "  os.mkdir(tgt_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3nB78iWi9ts"
   },
   "outputs": [],
   "source": [
    "def visualizeGAN(e, z_real, z_fake):\n",
    "\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(40, 36))\n",
    "\n",
    "    r_real = 0\n",
    "    r_fake = 0\n",
    "    for row, axe in enumerate(axes):\n",
    "        for col, cell in enumerate(axe):\n",
    "            if row % 2 == 0:\n",
    "                cell.imshow(z_real[r_real * 8 + col])\n",
    "            else:\n",
    "                cell.imshow((z_fake[r_fake * 8 + col] * 255).astype(np.uint8))\n",
    "\n",
    "            cell.axis(\"off\")\n",
    "\n",
    "        if row % 2 == 0:\n",
    "            r_real += 1\n",
    "        else:\n",
    "            r_fake += 1\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    fig.savefig(os.path.join(tgt_pth, '{}.jpg'.format(str(e).zfill(3))))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noise():\n",
    "    \n",
    "    y_true = tf.ones((BATCH_SIZE,))\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # run once\n",
    "        y_true = y_true.eval()\n",
    "\n",
    "        while True:\n",
    "            values = sess.run([variable_dataset])\n",
    "            row = values[0]\n",
    "\n",
    "            sz = row['img'].shape[0]\n",
    "\n",
    "            if sz != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # fake data\n",
    "            # concatenate face + age + noise\n",
    "            c1 = row['enc']\n",
    "            c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "            x = tf.random.normal((sz, noise_len,)).eval()\n",
    "            \n",
    "            yield c1, c2, x, y_true\n",
    "\n",
    "\n",
    "def load_batch():\n",
    "    \n",
    "    y_fake = tf.zeros((BATCH_SIZE,))\n",
    "    y_true = tf.ones((BATCH_SIZE,))\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # run once\n",
    "        y_fake = y_fake.eval()\n",
    "        y_true = y_true.eval()\n",
    "\n",
    "        while True:\n",
    "            values = sess.run([variable_dataset])\n",
    "            row = values[0]\n",
    "\n",
    "            sz = row['img'].shape[0]\n",
    "\n",
    "            if sz != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # fake data\n",
    "            c1 = row['enc']\n",
    "            c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "            x = tf.random.normal((sz, noise_len,)).eval()\n",
    "            z_fake = generator.predict([c1, c2, x])\n",
    "\n",
    "            # real data\n",
    "            c1 = row['enc']\n",
    "            c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "            z_real = tf.reshape(tf.io.decode_raw(row['img'], tf.uint8), (-1, width, height, depth)).eval()\n",
    "                        \n",
    "            yield c1, c2, x, z_fake, y_fake, z_real, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GNNmDUZi9t3"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 4000\n",
    "STEPS = 1  # 60000 // BATCH_SIZE\n",
    "\n",
    "\n",
    "train_loss_g = []\n",
    "train_loss_d = []\n",
    "\n",
    "train_acc_g = []\n",
    "train_acc_d = []\n",
    "\n",
    "\n",
    "disc_itr = load_batch()\n",
    "gen_itr = load_noise()\n",
    "\n",
    "\n",
    "# epochs\n",
    "for e in range(EPOCHS):\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS * 4):\n",
    "        \n",
    "        c1, c2, x, z_fake, y_fake, z_real, y_real = next(disc_itr)\n",
    "    \n",
    "        # train\n",
    "        loss_2, acc_2 = discriminator.train_on_batch([c1, c2, z_real], y_real)\n",
    "        loss_1, acc_1 = discriminator.train_on_batch([c1, c2, z_fake], y_fake)\n",
    "\n",
    "        batch_loss = 0.5 * (loss_1 + loss_2)\n",
    "        batch_acc = 0.5 * (acc_1 + acc_2)\n",
    "\n",
    "        loss.append(batch_loss)\n",
    "        acc.append(batch_acc)\n",
    "\n",
    "    train_loss_d.append(np.mean(np.array(loss)))\n",
    "    train_acc_d.append(np.mean(np.array(acc)))\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "        c1, c2, x, y_true = next(gen_itr)\n",
    "\n",
    "        # train\n",
    "        loss_1, acc_1 = gan.train_on_batch([c1, c2, x], y_true)\n",
    "\n",
    "        loss.append(loss_1)\n",
    "        acc.append(acc_1)\n",
    "\n",
    "    train_loss_g.append(np.mean(np.array(loss)))\n",
    "    train_acc_g.append(np.mean(np.array(acc)))\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, Steps: {}, Discriminator Accuracy: %{:.2f}, GAN Accuracy: %{:.2f}\".format(\n",
    "          e,\n",
    "          STEPS,\n",
    "          train_acc_d[-1] * 100,\n",
    "          train_acc_g[-1] * 100\n",
    "      ))\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        ## visualize results\n",
    "        c1, c2, x, z_fake, y_fake, z_real, y_real = next(disc_itr)\n",
    "        visualizeGAN(e, z_real, z_fake)\n",
    "        \n",
    "        ## save model\n",
    "        pth = os.path.join(models_path, 'gan.h5')\n",
    "        gan.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'generator-{}-{}-{}.h5'.format(e, train_loss_g[-1], train_acc_g[-1]))\n",
    "        generator.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'discriminator.h5')\n",
    "        discriminator.save(pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnlcqEI8i9uH"
   },
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LzhKde-CaDu"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_loss_g, label=\"Generator Loss\");\n",
    "plt.plot(train_loss_d, label=\"Discriminator Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9iCkvcai9uS"
   },
   "source": [
    "## Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YhSUa3fROSg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_acc_g, label=\"Generator Accuracy\");\n",
    "plt.plot(train_acc_d, label=\"Discriminator Accuracy\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST Test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
