{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAQBOBYyi9sc"
   },
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1554977904593,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "BIEdHLeqDLJH",
    "outputId": "90567bca-f98c-4b16-c01f-adc92d510da4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "root_path = './'\n",
    "dataset_path = os.path.join(root_path, 'tf_dataset')\n",
    "\n",
    "models_path = os.path.join(root_path, 'saved_models')\n",
    "if not os.path.exists(models_path):\n",
    "  os.mkdir(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2751,
     "status": "ok",
     "timestamp": 1554977904597,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "MxSDNtvqj0Xs",
    "outputId": "876f60f6-e4ef-4454-bfa5-f3ff6b5a8f17"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "image_feature_description = {\n",
    "    'enc': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    'age': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "    'img': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True)\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "\n",
    "raw_train_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path,'train.tfrecords'))\n",
    "parsed_train_dataset = raw_train_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_val_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'val.tfrecords'))\n",
    "parsed_val_dataset = raw_val_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_test_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'test.tfrecords'))\n",
    "parsed_test_dataset = raw_test_dataset.map(_parse_image_function)\n",
    "\n",
    "\n",
    "parsed_train_dataset = parsed_train_dataset.repeat()\n",
    "parsed_train_dataset = parsed_train_dataset.shuffle(1000)\n",
    "parsed_train_dataset = parsed_train_dataset.batch(BATCH_SIZE)\n",
    "dataset_iterator = parsed_train_dataset.make_one_shot_iterator()\n",
    "\n",
    "variable_dataset = dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMouydu3i9sp"
   },
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3123,
     "status": "ok",
     "timestamp": 1554977905340,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "HAuHCfjlFBOy",
    "outputId": "abf88c5b-9df8-41dc-9017-9d8a2007a0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 16)        448       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 3)           867       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 3, 3)           0         \n",
      "=================================================================\n",
      "Total params: 5,955\n",
      "Trainable params: 5,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               20992     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 21,121\n",
      "Trainable params: 21,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_1 (Conv2DTr (None, 13, 13, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 27, 27, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 11,331\n",
      "Trainable params: 11,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 121)               28677     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 121)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 11, 11, 1)         0         \n",
      "=================================================================\n",
      "Total params: 28,677\n",
      "Trainable params: 28,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc_len = 128\n",
    "age_len = 8\n",
    "img_shape = (32, 32, 3)\n",
    "width, height, depth = (32, 32, 3)\n",
    "img_len = np.prod(img_shape)\n",
    "latent_dim = enc_len + age_len + img_len\n",
    "noise_len = 100\n",
    "input_dim = enc_len + age_len + noise_len\n",
    "cond_len = enc_len + age_len\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    conv = keras.Sequential([\n",
    "        # conv block 1\n",
    "        keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2,\n",
    "            input_shape=img_shape\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "\n",
    "        # conv block 2\n",
    "        keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        \n",
    "        # conv block 3\n",
    "        keras.layers.Conv2D(\n",
    "            filters=3,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "    ])\n",
    "    \n",
    "    conv.summary()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(128, input_shape=(27+128+8,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Dense(1),\n",
    "        keras.layers.Activation(tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "    clf = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(128, input_shape=(27+128+8,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Dense(age_len),\n",
    "        keras.layers.Activation(tf.nn.softmax),\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # image\n",
    "    z = keras.layers.Input(shape=img_shape)\n",
    "    \n",
    "    # convolution\n",
    "    zout = conv(z)\n",
    "    \n",
    "    # flatten image\n",
    "    z_flat = keras.layers.Flatten()(zout)\n",
    "    \n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, z_flat])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # age label\n",
    "    classes = clf(inputs)\n",
    "    \n",
    "    \n",
    "    return keras.models.Model([c1, c2, z], [outputs, classes])\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    \n",
    "    conv = keras.Sequential([\n",
    "        # transpose conv block 1\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=1,\n",
    "            input_shape=(11, 11, 1)\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # transpose conv block 2\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # transpose conv block 3\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=(2, 2),\n",
    "            strides=1\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "\n",
    "        # transpose conv block 4\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=3,\n",
    "            kernel_size=(5, 5),\n",
    "            strides=1\n",
    "        ),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Activation(tf.nn.tanh)\n",
    "    ])\n",
    "    \n",
    "    conv.summary()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(121, input_shape=(input_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((11, 11, 1))\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # noise\n",
    "    x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, x])\n",
    "    \n",
    "    # flat dense output\n",
    "    out_1 = model(inputs)\n",
    "    \n",
    "    # transpose conv output\n",
    "    outputs = conv(out_1)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, x], outputs)\n",
    "\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3046,
     "status": "ok",
     "timestamp": 1554977905345,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "tfo8J8jQ4-FH",
    "outputId": "022c24ae-1c6e-40ad-e167-964953449961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 236)          0           input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 11, 11, 1)    28677       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 32, 32, 3)    11331       sequential_5[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 40,008\n",
      "Trainable params: 40,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3013,
     "status": "ok",
     "timestamp": 1554977905348,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "ObTb7HIf5CqA",
    "outputId": "1bdb05c0-cd96-46c6-a124-68ac9ee9ddb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 3, 3, 3)      5955        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 27)           0           sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 163)          0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1)            21121       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 8)            22024       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 49,100\n",
      "Trainable params: 49,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctWfkxy5i9tR"
   },
   "source": [
    "## Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHTmYpPeImn5"
   },
   "outputs": [],
   "source": [
    "GLR = 0.002  # generator\n",
    "DLR = 0.002  # discriminator\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(DLR, 0.5),\n",
    "    loss=[d_loss, keras.losses.categorical_crossentropy],\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# condition\n",
    "c1 = keras.layers.Input(shape=(enc_len,))\n",
    "c2 = keras.layers.Input(shape=(age_len,))\n",
    "\n",
    "# noise\n",
    "x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "# freeze discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# output\n",
    "z = generator([c1, c2, x])\n",
    "out, lbl = discriminator([c1, c2, z])\n",
    "\n",
    "# GAN\n",
    "gan = keras.models.Model(inputs=[c1, c2, x], outputs=[out, lbl])\n",
    "\n",
    "gan.compile(\n",
    "    optimizer=keras.optimizers.Adam(GLR , 0.5),\n",
    "    loss=[d_loss, keras.losses.categorical_crossentropy],\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1554977905707,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "o_76rZ0ti9tc",
    "outputId": "8eb9fa73-4621-40e3-fab1-fd2d52d7bbe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 32, 32, 3)    40008       input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 [(None, 1), (None, 8 49100       input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 model_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 89,108\n",
      "Trainable params: 40,008\n",
      "Non-trainable params: 49,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REaxJyLqi9tp"
   },
   "source": [
    "## Visualization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25210,
     "status": "ok",
     "timestamp": 1554977927807,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "4kA4g6_lt3D8",
    "outputId": "c5b38cce-ad98-49ac-9b13-950a8e2356ca"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os\n",
    "\n",
    "\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "root_path = './'\n",
    "tgt_pth = os.path.join(root_path, 'visualize_age-cgan-v2')\n",
    "\n",
    "if not os.path.exists(tgt_pth):\n",
    "  os.mkdir(tgt_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3nB78iWi9ts"
   },
   "outputs": [],
   "source": [
    "def visualizeGAN(e, z_real, z_fake):\n",
    "\n",
    "    fig, axes = plt.subplots(8, 4, figsize=(40, 36))\n",
    "\n",
    "    r_real = 0\n",
    "    r_fake = 0\n",
    "    for row, axe in enumerate(axes):\n",
    "        for col, cell in enumerate(axe):\n",
    "            if row % 2 == 0:\n",
    "                cell.imshow(z_real[r_real * 4 + col])\n",
    "            else:\n",
    "                cell.imshow((z_fake[r_fake * 4 + col] * 255).astype(np.uint8))\n",
    "\n",
    "            cell.axis(\"off\")\n",
    "\n",
    "        if row % 2 == 0:\n",
    "            r_real += 1\n",
    "        else:\n",
    "            r_fake += 1\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    fig.savefig(os.path.join(tgt_pth, '{}.jpg'.format(str(e).zfill(3))))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noise():\n",
    "    \n",
    "    y_true = tf.ones((BATCH_SIZE,))\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # run once\n",
    "        y_true = y_true.eval()\n",
    "\n",
    "        while True:\n",
    "            values = sess.run([variable_dataset])\n",
    "            row = values[0]\n",
    "\n",
    "            sz = row['img'].shape[0]\n",
    "\n",
    "            if sz != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # fake data\n",
    "            # concatenate face + age + noise\n",
    "            c1 = row['enc']\n",
    "            c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "            x = tf.random.normal((sz, noise_len,)).eval()\n",
    "            \n",
    "            yield c1, c2, x, y_true\n",
    "\n",
    "\n",
    "def load_batch():\n",
    "    \n",
    "    y_fake = tf.zeros((BATCH_SIZE,))\n",
    "    y_true = tf.ones((BATCH_SIZE,))\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # run once\n",
    "        y_fake = y_fake.eval()\n",
    "        y_true = y_true.eval()\n",
    "\n",
    "        while True:\n",
    "            values = sess.run([variable_dataset])\n",
    "            row = values[0]\n",
    "\n",
    "            sz = row['img'].shape[0]\n",
    "\n",
    "            if sz != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # fake data\n",
    "            c1 = row['enc']\n",
    "            c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "            x = tf.random.normal((sz, noise_len,)).eval()\n",
    "            z_fake = generator.predict([c1, c2, x])\n",
    "\n",
    "            # real data\n",
    "            c1 = row['enc']\n",
    "            c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "            z_real = tf.reshape(tf.io.decode_raw(row['img'], tf.uint8), (-1, width, height, depth)).eval()\n",
    "                        \n",
    "            yield c1, c2, x, z_fake, y_fake, z_real, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GNNmDUZi9t3"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Steps: 1, Discriminator Accuracy: %13.97, GAN Accuracy: %48.27\n",
      "Epoch: 1, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %48.53\n",
      "Epoch: 2, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %48.43\n",
      "Epoch: 3, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %46.71\n",
      "Epoch: 4, Steps: 1, Discriminator Accuracy: %0.05, GAN Accuracy: %30.89\n",
      "Epoch: 5, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %23.13\n",
      "Epoch: 6, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %29.63\n",
      "Epoch: 7, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %30.99\n",
      "Epoch: 8, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %30.68\n",
      "Epoch: 9, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %28.61\n",
      "Epoch: 10, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %28.65\n",
      "Epoch: 11, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %27.62\n",
      "Epoch: 12, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %26.38\n",
      "Epoch: 13, Steps: 1, Discriminator Accuracy: %0.01, GAN Accuracy: %32.26\n",
      "Epoch: 14, Steps: 1, Discriminator Accuracy: %9.32, GAN Accuracy: %1.23\n",
      "Epoch: 15, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.44\n",
      "Epoch: 16, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.74\n",
      "Epoch: 17, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.64\n",
      "Epoch: 18, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.63\n",
      "Epoch: 19, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.42\n",
      "Epoch: 20, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.50\n",
      "Epoch: 21, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.80\n",
      "Epoch: 22, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.47\n",
      "Epoch: 23, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.81\n",
      "Epoch: 24, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.49\n",
      "Epoch: 25, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.39\n",
      "Epoch: 26, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.65\n",
      "Epoch: 27, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.73\n",
      "Epoch: 28, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.60\n",
      "Epoch: 29, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.68\n",
      "Epoch: 30, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.37\n",
      "Epoch: 31, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.65\n",
      "Epoch: 32, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.73\n",
      "Epoch: 33, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.30\n",
      "Epoch: 34, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.71\n",
      "Epoch: 35, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.55\n",
      "Epoch: 36, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.49\n",
      "Epoch: 37, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.86\n",
      "Epoch: 38, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.61\n",
      "Epoch: 39, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.28\n",
      "Epoch: 40, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.42\n",
      "Epoch: 41, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.73\n",
      "Epoch: 42, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.71\n",
      "Epoch: 43, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.67\n",
      "Epoch: 44, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.47\n",
      "Epoch: 45, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.46\n",
      "Epoch: 46, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.63\n",
      "Epoch: 47, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.74\n",
      "Epoch: 48, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.30\n",
      "Epoch: 49, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.50\n",
      "Epoch: 50, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.43\n",
      "Epoch: 51, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.63\n",
      "Epoch: 52, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.49\n",
      "Epoch: 53, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.40\n",
      "Epoch: 54, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.52\n",
      "Epoch: 55, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.54\n",
      "Epoch: 56, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.87\n",
      "Epoch: 57, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.70\n",
      "Epoch: 58, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.63\n",
      "Epoch: 59, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.27\n",
      "Epoch: 60, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.36\n",
      "Epoch: 61, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.18\n",
      "Epoch: 62, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.43\n",
      "Epoch: 63, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.51\n",
      "Epoch: 64, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.36\n",
      "Epoch: 65, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.44\n",
      "Epoch: 66, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.44\n",
      "Epoch: 67, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.36\n",
      "Epoch: 68, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.34\n",
      "Epoch: 69, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.64\n",
      "Epoch: 70, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.60\n",
      "Epoch: 71, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.45\n",
      "Epoch: 72, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.35\n",
      "Epoch: 73, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.46\n",
      "Epoch: 74, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.20\n",
      "Epoch: 75, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.50\n",
      "Epoch: 76, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.39\n",
      "Epoch: 77, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.54\n",
      "Epoch: 78, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.31\n",
      "Epoch: 79, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.39\n",
      "Epoch: 80, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.20\n",
      "Epoch: 81, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.48\n",
      "Epoch: 82, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.54\n",
      "Epoch: 83, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.31\n",
      "Epoch: 84, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.24\n",
      "Epoch: 85, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.22\n",
      "Epoch: 86, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.24\n",
      "Epoch: 87, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.28\n",
      "Epoch: 88, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.34\n",
      "Epoch: 89, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.23\n",
      "Epoch: 90, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.32\n",
      "Epoch: 91, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.02\n",
      "Epoch: 92, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.23\n",
      "Epoch: 93, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.36\n",
      "Epoch: 94, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.12\n",
      "Epoch: 95, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.01\n",
      "Epoch: 96, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.16\n",
      "Epoch: 97, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.35\n",
      "Epoch: 98, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.37\n",
      "Epoch: 99, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.22\n",
      "Epoch: 100, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.50\n",
      "Epoch: 101, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.08\n",
      "Epoch: 102, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.35\n",
      "Epoch: 103, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.28\n",
      "Epoch: 104, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.10\n",
      "Epoch: 105, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.43\n",
      "Epoch: 106, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.99\n",
      "Epoch: 107, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.27\n",
      "Epoch: 108, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.17\n",
      "Epoch: 109, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.16\n",
      "Epoch: 110, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.13\n",
      "Epoch: 111, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.02\n",
      "Epoch: 112, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.16\n",
      "Epoch: 113, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 114, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.06\n",
      "Epoch: 115, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.90\n",
      "Epoch: 116, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.88\n",
      "Epoch: 117, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.91\n",
      "Epoch: 118, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.86\n",
      "Epoch: 119, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.81\n",
      "Epoch: 120, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.62\n",
      "Epoch: 121, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.75\n",
      "Epoch: 122, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.62\n",
      "Epoch: 123, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.59\n",
      "Epoch: 124, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.64\n",
      "Epoch: 125, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.57\n",
      "Epoch: 126, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.58\n",
      "Epoch: 127, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.85\n",
      "Epoch: 128, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.54\n",
      "Epoch: 129, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.78\n",
      "Epoch: 130, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.00\n",
      "Epoch: 131, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.51\n",
      "Epoch: 132, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.74\n",
      "Epoch: 133, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.82\n",
      "Epoch: 134, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.77\n",
      "Epoch: 135, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.83\n",
      "Epoch: 136, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.77\n",
      "Epoch: 137, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.67\n",
      "Epoch: 138, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.87\n",
      "Epoch: 139, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.57\n",
      "Epoch: 140, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %2.03\n",
      "Epoch: 141, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.68\n",
      "Epoch: 142, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.95\n",
      "Epoch: 143, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.60\n",
      "Epoch: 144, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.76\n",
      "Epoch: 145, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.80\n",
      "Epoch: 146, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.64\n",
      "Epoch: 147, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.89\n",
      "Epoch: 148, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.80\n",
      "Epoch: 149, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.76\n",
      "Epoch: 150, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.73\n",
      "Epoch: 151, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.74\n",
      "Epoch: 152, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.77\n",
      "Epoch: 153, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.69\n",
      "Epoch: 154, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.39\n",
      "Epoch: 155, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.75\n",
      "Epoch: 156, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.55\n",
      "Epoch: 157, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.58\n",
      "Epoch: 158, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.72\n",
      "Epoch: 159, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.58\n",
      "Epoch: 160, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.59\n",
      "Epoch: 161, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.54\n",
      "Epoch: 162, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.67\n",
      "Epoch: 163, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.55\n",
      "Epoch: 164, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.48\n",
      "Epoch: 165, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.56\n",
      "Epoch: 166, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.34\n",
      "Epoch: 167, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.48\n",
      "Epoch: 168, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.37\n",
      "Epoch: 169, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.41\n",
      "Epoch: 170, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.35\n",
      "Epoch: 171, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.44\n",
      "Epoch: 172, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.58\n",
      "Epoch: 173, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.43\n",
      "Epoch: 174, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.38\n",
      "Epoch: 175, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.60\n",
      "Epoch: 176, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.41\n",
      "Epoch: 177, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.53\n",
      "Epoch: 178, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.50\n",
      "Epoch: 179, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.57\n",
      "Epoch: 180, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.52\n",
      "Epoch: 181, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.49\n",
      "Epoch: 182, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.40\n",
      "Epoch: 183, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.32\n",
      "Epoch: 184, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.40\n",
      "Epoch: 185, Steps: 1, Discriminator Accuracy: %0.00, GAN Accuracy: %1.39\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Nesting violated for default stack of <class 'tensorflow.python.client.session.Session'> objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5060\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5061\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5062\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-dc2ac7eb8e43>\u001b[0m in \u001b[0;36mload_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'enc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mz_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5180\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7ff2bd9cdc24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTEPS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_itr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-dc2ac7eb8e43>\u001b[0m in \u001b[0;36mload_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mz_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exec_type, exec_value, exec_tb)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m       self._default_session_context_manager.__exit__(exec_type, exec_value,\n\u001b[0;32m-> 1573\u001b[0;31m                                                      exec_tb)\n\u001b[0m\u001b[1;32m   1574\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexec_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5067\u001b[0m             raise AssertionError(\n\u001b[1;32m   5068\u001b[0m                 \u001b[0;34m\"Nesting violated for default stack of %s objects\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5069\u001b[0;31m                 type(default))\n\u001b[0m\u001b[1;32m   5070\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5071\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Nesting violated for default stack of <class 'tensorflow.python.client.session.Session'> objects"
     ]
    }
   ],
   "source": [
    "EPOCHS = 4000\n",
    "STEPS = 1  # 60000 // BATCH_SIZE\n",
    "\n",
    "\n",
    "train_loss_g = []\n",
    "train_loss_d = []\n",
    "\n",
    "train_acc_g = []\n",
    "train_acc_d = []\n",
    "\n",
    "\n",
    "disc_itr = load_batch()\n",
    "gen_itr = load_noise()\n",
    "\n",
    "\n",
    "# epochs\n",
    "for e in range(EPOCHS):\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS * 4):\n",
    "        \n",
    "        c1, c2, x, z_fake, y_fake, z_real, y_real = next(disc_itr)\n",
    "    \n",
    "        # train\n",
    "        loss_2, acc_2, _, _, _ = discriminator.train_on_batch([c1, c2, z_real], [y_real, c2])\n",
    "        loss_1, acc_1, _, _, _ = discriminator.train_on_batch([c1, c2, z_fake], [y_fake, c2])\n",
    "\n",
    "        batch_loss = 0.5 * (loss_1 + loss_2)\n",
    "        batch_acc = 0.5 * (acc_1 + acc_2)\n",
    "\n",
    "        loss.append(batch_loss)\n",
    "        acc.append(batch_acc)\n",
    "\n",
    "    train_loss_d.append(np.mean(np.array(loss)))\n",
    "    train_acc_d.append(np.mean(np.array(acc)))\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "        c1, c2, x, y_true = next(gen_itr)\n",
    "\n",
    "        # train\n",
    "        loss_1, acc_1, _, _, _ = gan.train_on_batch([c1, c2, x], [y_true, c2])\n",
    "\n",
    "        loss.append(loss_1)\n",
    "        acc.append(acc_1)\n",
    "\n",
    "    train_loss_g.append(np.mean(np.array(loss)))\n",
    "    train_acc_g.append(np.mean(np.array(acc)))\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, Steps: {}, Discriminator Accuracy: %{:.2f}, GAN Accuracy: %{:.2f}\".format(\n",
    "          e,\n",
    "          STEPS,\n",
    "          train_acc_d[-1] * 100,\n",
    "          train_acc_g[-1] * 100\n",
    "      ))\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        ## visualize results\n",
    "        c1, c2, x, z_fake, y_fake, z_real, y_real = next(disc_itr)\n",
    "        visualizeGAN(e, z_real, z_fake)\n",
    "        \n",
    "        ## save model\n",
    "        pth = os.path.join(models_path, 'gan.h5')\n",
    "        gan.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'generator-{}-{}-{}.h5'.format(e, train_loss_g[-1], train_acc_g[-1]))\n",
    "        generator.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'discriminator.h5')\n",
    "        discriminator.save(pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnlcqEI8i9uH"
   },
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LzhKde-CaDu"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_loss_g, label=\"Generator Loss\");\n",
    "plt.plot(train_loss_d, label=\"Discriminator Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9iCkvcai9uS"
   },
   "source": [
    "## Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YhSUa3fROSg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_acc_g, label=\"Generator Accuracy\");\n",
    "plt.plot(train_acc_d, label=\"Discriminator Accuracy\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST Test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
