{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAQBOBYyi9sc"
   },
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1554977904593,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "BIEdHLeqDLJH",
    "outputId": "90567bca-f98c-4b16-c01f-adc92d510da4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "root_path = './'\n",
    "dataset_path = os.path.join(root_path, 'tf_dataset_gray')\n",
    "\n",
    "models_path = os.path.join(root_path, 'saved_models_gray')\n",
    "if not os.path.exists(models_path):\n",
    "  os.mkdir(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2751,
     "status": "ok",
     "timestamp": 1554977904597,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "MxSDNtvqj0Xs",
    "outputId": "876f60f6-e4ef-4454-bfa5-f3ff6b5a8f17"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "\n",
    "image_feature_description = {\n",
    "    'enc': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    'age': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "    'img': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True)\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "\n",
    "raw_train_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path,'train.tfrecords'))\n",
    "parsed_train_dataset = raw_train_dataset.map(_parse_image_function)\n",
    "\n",
    "# raw_val_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'val.tfrecords'))\n",
    "# parsed_val_dataset = raw_val_dataset.map(_parse_image_function)\n",
    "\n",
    "# raw_test_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'test.tfrecords'))\n",
    "# parsed_test_dataset = raw_test_dataset.map(_parse_image_function)\n",
    "\n",
    "\n",
    "parsed_train_dataset = parsed_train_dataset.repeat()\n",
    "parsed_train_dataset = parsed_train_dataset.shuffle(6000)\n",
    "parsed_train_dataset = parsed_train_dataset.batch(BATCH_SIZE)\n",
    "dataset_iterator = parsed_train_dataset.make_one_shot_iterator()\n",
    "\n",
    "variable_dataset = dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMouydu3i9sp"
   },
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3123,
     "status": "ok",
     "timestamp": 1554977905340,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "HAuHCfjlFBOy",
    "outputId": "abf88c5b-9df8-41dc-9017-9d8a2007a0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 15, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 3)           867       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 3, 3)           0         \n",
      "=================================================================\n",
      "Total params: 5,859\n",
      "Trainable params: 5,763\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 28        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28\n",
      "Trainable params: 28\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_1 (Conv2DTr (None, 13, 13, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 27, 27, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 27, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 1)         0         \n",
      "=================================================================\n",
      "Total params: 10,049\n",
      "Trainable params: 9,889\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 121)               12221     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 121)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 11, 11, 1)         0         \n",
      "=================================================================\n",
      "Total params: 12,221\n",
      "Trainable params: 12,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc_len = 0\n",
    "age_len = 0\n",
    "img_shape = (32, 32, 1)\n",
    "width, height, depth = (32, 32, 1)\n",
    "img_len = np.prod(img_shape)\n",
    "latent_dim = enc_len + age_len + img_len\n",
    "noise_len = 100\n",
    "input_dim = enc_len + age_len + noise_len\n",
    "cond_len = enc_len + age_len\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    conv = keras.Sequential([\n",
    "        # conv block 1\n",
    "        keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2,\n",
    "            input_shape=img_shape\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        # conv block 2\n",
    "        keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # conv block 3\n",
    "        keras.layers.Conv2D(\n",
    "            filters=3,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "    ])\n",
    "    \n",
    "    conv.summary()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "#         keras.layers.Dense(128),\n",
    "#         keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Dense(1, input_shape=(27,)),\n",
    "        keras.layers.Activation(tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "#     clf = keras.Sequential([\n",
    "#         # dense 1\n",
    "#         keras.layers.Dense(128, input_shape=(27+128+8,)),\n",
    "#         keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "#         # output\n",
    "#         keras.layers.Dense(age_len),\n",
    "#         keras.layers.Activation(tf.nn.softmax),\n",
    "#     ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "#     # condition\n",
    "#     c1 = keras.layers.Input(shape=(enc_len,))\n",
    "#     c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # image\n",
    "    z = keras.layers.Input(shape=img_shape)\n",
    "    \n",
    "    # convolution\n",
    "    zout = conv(z)\n",
    "    \n",
    "    # flatten image\n",
    "    z_flat = keras.layers.Flatten()(zout)\n",
    "    \n",
    "    # concatenation\n",
    "#     inputs = keras.layers.concatenate([z_flat])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(z_flat)\n",
    "    \n",
    "    # age label\n",
    "#     classes = clf(inputs)\n",
    "    \n",
    "    \n",
    "    return keras.models.Model(z, outputs)\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    \n",
    "    conv = keras.Sequential([\n",
    "        # transpose conv block 1\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=1,\n",
    "            input_shape=(11, 11, 1)\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # transpose conv block 2\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # transpose conv block 3\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=(2, 2),\n",
    "            strides=1\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        # transpose conv block 4\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=1,\n",
    "            kernel_size=(5, 5),\n",
    "            strides=1\n",
    "        ),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Activation(tf.nn.tanh)\n",
    "    ])\n",
    "    \n",
    "    conv.summary()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(121, input_shape=(input_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((11, 11, 1))\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "#     # condition\n",
    "#     c1 = keras.layers.Input(shape=(enc_len,))\n",
    "#     c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # noise\n",
    "    x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "    # concatenation\n",
    "#     inputs = keras.layers.concatenate([x])\n",
    "    \n",
    "    # flat dense output\n",
    "    out_1 = model(x)\n",
    "    \n",
    "    # transpose conv output\n",
    "    outputs = conv(out_1)\n",
    "    \n",
    "    return keras.models.Model(x, outputs)\n",
    "\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3046,
     "status": "ok",
     "timestamp": 1554977905345,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "tfo8J8jQ4-FH",
    "outputId": "022c24ae-1c6e-40ad-e167-964953449961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 11, 11, 1)         12221     \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 32, 32, 1)         10049     \n",
      "=================================================================\n",
      "Total params: 22,270\n",
      "Trainable params: 22,110\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3013,
     "status": "ok",
     "timestamp": 1554977905348,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "ObTb7HIf5CqA",
    "outputId": "1bdb05c0-cd96-46c6-a124-68ac9ee9ddb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 3, 3, 3)           5859      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 5,887\n",
      "Trainable params: 5,791\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctWfkxy5i9tR"
   },
   "source": [
    "## Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHTmYpPeImn5"
   },
   "outputs": [],
   "source": [
    "GLR = 0.01  # generator\n",
    "DLR = 0.01  # discriminator\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(DLR, 0.5),\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# # condition\n",
    "# c1 = keras.layers.Input(shape=(enc_len,))\n",
    "# c2 = keras.layers.Input(shape=(age_len,))\n",
    "\n",
    "# noise\n",
    "x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "# freeze discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# output\n",
    "z = generator(x)\n",
    "out = discriminator(z)\n",
    "\n",
    "# GAN\n",
    "gan = keras.models.Model(inputs=x, outputs=out)\n",
    "\n",
    "gan.compile(\n",
    "    optimizer=keras.optimizers.Adam(GLR , 0.5),\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1554977905707,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "o_76rZ0ti9tc",
    "outputId": "8eb9fa73-4621-40e3-fab1-fd2d52d7bbe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 32, 32, 1)         22270     \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 5887      \n",
      "=================================================================\n",
      "Total params: 28,157\n",
      "Trainable params: 22,110\n",
      "Non-trainable params: 6,047\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REaxJyLqi9tp"
   },
   "source": [
    "## Visualization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25210,
     "status": "ok",
     "timestamp": 1554977927807,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "4kA4g6_lt3D8",
    "outputId": "c5b38cce-ad98-49ac-9b13-950a8e2356ca"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os\n",
    "\n",
    "\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "root_path = './'\n",
    "tgt_pth = os.path.join(root_path, 'visualize_age-cgan-v7')\n",
    "\n",
    "if not os.path.exists(tgt_pth):\n",
    "  os.mkdir(tgt_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3nB78iWi9ts"
   },
   "outputs": [],
   "source": [
    "def visualizeGAN(e, z_real, z_fake):\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 18))\n",
    "\n",
    "    r_real = 0\n",
    "    r_fake = 0\n",
    "    for row, axe in enumerate(axes):\n",
    "        for col, cell in enumerate(axe):\n",
    "            if row % 2 == 0:\n",
    "                cell.imshow(\n",
    "                    np.squeeze(\n",
    "                        0.5 * z_real[r_real * 4 + col] + 0.5,\n",
    "                        axis=-1\n",
    "                    ),\n",
    "                    cmap='gray'\n",
    "                )\n",
    "            else:\n",
    "                cell.imshow(\n",
    "                    np.squeeze(\n",
    "                        0.5 * z_fake[r_fake * 4 + col] + 0.5,\n",
    "                        axis=-1\n",
    "                    ),\n",
    "                    cmap='gray'\n",
    "                )\n",
    "\n",
    "            cell.axis(\"off\")\n",
    "\n",
    "        if row % 2 == 0:\n",
    "            r_real += 1\n",
    "        else:\n",
    "            r_fake += 1\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(os.path.join(tgt_pth, '{}.jpg'.format(str(e).zfill(3))))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noise():\n",
    "    \n",
    "    y_real = tf.ones((BATCH_SIZE,))\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # run once\n",
    "        y_real = y_real.eval()\n",
    "\n",
    "        while True:\n",
    "            values = sess.run([variable_dataset])\n",
    "            row = values[0]\n",
    "\n",
    "            sz = row['img'].shape[0]\n",
    "\n",
    "            if sz != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # fake data\n",
    "            # concatenate face + age + noise\n",
    "#             c1 = row['enc']\n",
    "#             c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "            x = tf.random.normal((sz, noise_len,)).eval()\n",
    "            \n",
    "            yield x, y_real\n",
    "\n",
    "\n",
    "def load_batch():\n",
    "    \n",
    "    y_fake = tf.zeros((BATCH_SIZE,))\n",
    "    y_real = tf.ones((BATCH_SIZE,))\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # run once\n",
    "        y_fake = y_fake.eval()\n",
    "        y_real = y_real.eval()\n",
    "\n",
    "        while True:\n",
    "            values = sess.run([variable_dataset])\n",
    "            row = values[0]\n",
    "\n",
    "            sz = row['img'].shape[0]\n",
    "\n",
    "            if sz != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # fake data\n",
    "#             c1 = row['enc']\n",
    "#             c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "            x = tf.random.normal((sz, noise_len,)).eval()\n",
    "            z_fake = generator.predict(x)\n",
    "\n",
    "            # real data\n",
    "#             c1 = row['enc']\n",
    "#             c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "            z_real = tf.reshape(tf.io.decode_raw(row['img'], tf.int64), (-1, width, height, depth))\n",
    "    \n",
    "            z_real = tf.cast(z_real, tf.float32)\n",
    "    \n",
    "            # scale to [-1, +1]\n",
    "            z_real = tf.math.subtract(tf.math.divide(z_real, 127.5), 1)\n",
    "        \n",
    "            z_real = z_real.eval()\n",
    "                        \n",
    "            yield x, z_fake, y_fake, z_real, y_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GNNmDUZi9t3"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 0, [D ACC: %76.37], [D LOSS: 49.66], [G ACC: %69.53], [G LOSS: 59.09]\n",
      "E: 1, [D ACC: %14.26], [D LOSS: 140.41], [G ACC: %20.70], [G LOSS: 129.79]\n",
      "E: 2, [D ACC: %65.23], [D LOSS: 77.08], [G ACC: %3.12], [G LOSS: 225.74]\n",
      "E: 3, [D ACC: %64.65], [D LOSS: 86.68], [G ACC: %7.03], [G LOSS: 199.39]\n",
      "E: 4, [D ACC: %48.44], [D LOSS: 113.60], [G ACC: %7.03], [G LOSS: 173.75]\n",
      "E: 5, [D ACC: %79.10], [D LOSS: 59.99], [G ACC: %2.73], [G LOSS: 215.24]\n",
      "E: 6, [D ACC: %87.11], [D LOSS: 46.21], [G ACC: %10.16], [G LOSS: 194.84]\n",
      "E: 7, [D ACC: %76.37], [D LOSS: 58.82], [G ACC: %13.28], [G LOSS: 175.04]\n",
      "E: 8, [D ACC: %76.17], [D LOSS: 63.16], [G ACC: %16.02], [G LOSS: 161.22]\n",
      "E: 9, [D ACC: %76.17], [D LOSS: 59.38], [G ACC: %13.28], [G LOSS: 160.77]\n",
      "E: 10, [D ACC: %78.52], [D LOSS: 52.41], [G ACC: %8.98], [G LOSS: 184.13]\n",
      "E: 11, [D ACC: %85.94], [D LOSS: 40.15], [G ACC: %7.03], [G LOSS: 215.76]\n",
      "E: 12, [D ACC: %92.97], [D LOSS: 28.27], [G ACC: %7.03], [G LOSS: 247.75]\n",
      "E: 13, [D ACC: %94.53], [D LOSS: 25.95], [G ACC: %2.73], [G LOSS: 253.06]\n",
      "E: 14, [D ACC: %93.36], [D LOSS: 24.61], [G ACC: %7.03], [G LOSS: 306.93]\n",
      "E: 15, [D ACC: %93.95], [D LOSS: 19.76], [G ACC: %3.91], [G LOSS: 318.90]\n",
      "E: 16, [D ACC: %92.97], [D LOSS: 20.20], [G ACC: %4.30], [G LOSS: 322.24]\n",
      "E: 17, [D ACC: %85.74], [D LOSS: 37.95], [G ACC: %8.59], [G LOSS: 314.18]\n",
      "E: 18, [D ACC: %88.87], [D LOSS: 31.10], [G ACC: %4.30], [G LOSS: 380.68]\n",
      "E: 19, [D ACC: %95.31], [D LOSS: 18.87], [G ACC: %1.95], [G LOSS: 444.93]\n",
      "E: 20, [D ACC: %96.68], [D LOSS: 24.42], [G ACC: %1.56], [G LOSS: 489.47]\n",
      "E: 21, [D ACC: %98.83], [D LOSS: 13.59], [G ACC: %1.95], [G LOSS: 451.72]\n",
      "E: 22, [D ACC: %97.46], [D LOSS: 13.82], [G ACC: %1.56], [G LOSS: 515.33]\n",
      "E: 23, [D ACC: %98.63], [D LOSS: 4.67], [G ACC: %0.39], [G LOSS: 587.72]\n",
      "E: 24, [D ACC: %99.02], [D LOSS: 7.58], [G ACC: %1.56], [G LOSS: 615.69]\n",
      "E: 25, [D ACC: %98.05], [D LOSS: 7.99], [G ACC: %1.17], [G LOSS: 618.07]\n",
      "E: 26, [D ACC: %86.72], [D LOSS: 36.27], [G ACC: %1.17], [G LOSS: 707.23]\n",
      "E: 27, [D ACC: %98.24], [D LOSS: 7.62], [G ACC: %3.12], [G LOSS: 461.91]\n",
      "E: 28, [D ACC: %65.23], [D LOSS: 102.60], [G ACC: %3.52], [G LOSS: 546.68]\n",
      "E: 29, [D ACC: %98.05], [D LOSS: 12.58], [G ACC: %0.39], [G LOSS: 627.84]\n",
      "E: 30, [D ACC: %99.02], [D LOSS: 9.57], [G ACC: %1.17], [G LOSS: 554.16]\n",
      "E: 31, [D ACC: %93.55], [D LOSS: 25.37], [G ACC: %1.56], [G LOSS: 471.53]\n",
      "E: 32, [D ACC: %96.29], [D LOSS: 24.21], [G ACC: %1.95], [G LOSS: 436.26]\n",
      "E: 33, [D ACC: %97.07], [D LOSS: 20.37], [G ACC: %2.73], [G LOSS: 391.03]\n",
      "E: 34, [D ACC: %96.48], [D LOSS: 13.18], [G ACC: %8.20], [G LOSS: 398.34]\n",
      "E: 35, [D ACC: %96.09], [D LOSS: 15.76], [G ACC: %5.08], [G LOSS: 424.60]\n",
      "E: 36, [D ACC: %96.48], [D LOSS: 14.88], [G ACC: %4.30], [G LOSS: 442.07]\n",
      "E: 37, [D ACC: %99.41], [D LOSS: 4.61], [G ACC: %0.78], [G LOSS: 533.33]\n",
      "E: 38, [D ACC: %83.59], [D LOSS: 57.35], [G ACC: %0.39], [G LOSS: 580.58]\n",
      "E: 39, [D ACC: %99.22], [D LOSS: 4.43], [G ACC: %0.00], [G LOSS: 697.67]\n",
      "E: 40, [D ACC: %91.02], [D LOSS: 31.93], [G ACC: %0.39], [G LOSS: 681.78]\n",
      "E: 41, [D ACC: %97.85], [D LOSS: 12.80], [G ACC: %0.39], [G LOSS: 587.08]\n",
      "E: 42, [D ACC: %86.33], [D LOSS: 30.98], [G ACC: %0.00], [G LOSS: 751.06]\n",
      "E: 43, [D ACC: %95.70], [D LOSS: 23.79], [G ACC: %0.78], [G LOSS: 508.27]\n",
      "E: 44, [D ACC: %99.02], [D LOSS: 9.99], [G ACC: %0.78], [G LOSS: 464.54]\n",
      "E: 45, [D ACC: %100.00], [D LOSS: 3.27], [G ACC: %0.39], [G LOSS: 445.22]\n",
      "E: 46, [D ACC: %96.09], [D LOSS: 12.62], [G ACC: %0.00], [G LOSS: 1046.57]\n",
      "E: 47, [D ACC: %87.70], [D LOSS: 31.05], [G ACC: %0.00], [G LOSS: 1594.56]\n",
      "E: 48, [D ACC: %89.45], [D LOSS: 73.72], [G ACC: %0.39], [G LOSS: 1053.36]\n",
      "E: 49, [D ACC: %58.79], [D LOSS: 218.05], [G ACC: %0.39], [G LOSS: 1249.14]\n",
      "E: 50, [D ACC: %64.45], [D LOSS: 45.78], [G ACC: %0.39], [G LOSS: 995.69]\n",
      "E: 51, [D ACC: %98.63], [D LOSS: 14.27], [G ACC: %2.73], [G LOSS: 461.26]\n",
      "E: 52, [D ACC: %97.27], [D LOSS: 12.41], [G ACC: %19.14], [G LOSS: 218.78]\n",
      "E: 53, [D ACC: %98.83], [D LOSS: 7.60], [G ACC: %94.53], [G LOSS: 16.42]\n",
      "E: 54, [D ACC: %99.02], [D LOSS: 8.17], [G ACC: %94.92], [G LOSS: 15.16]\n",
      "E: 55, [D ACC: %98.05], [D LOSS: 10.98], [G ACC: %98.83], [G LOSS: 3.67]\n",
      "E: 56, [D ACC: %99.02], [D LOSS: 4.93], [G ACC: %99.22], [G LOSS: 1.91]\n",
      "E: 57, [D ACC: %99.80], [D LOSS: 1.35], [G ACC: %100.00], [G LOSS: 1.00]\n",
      "E: 58, [D ACC: %99.61], [D LOSS: 3.23], [G ACC: %100.00], [G LOSS: 0.21]\n",
      "E: 59, [D ACC: %99.41], [D LOSS: 3.36], [G ACC: %100.00], [G LOSS: 0.08]\n",
      "E: 60, [D ACC: %99.61], [D LOSS: 3.56], [G ACC: %100.00], [G LOSS: 0.06]\n",
      "E: 61, [D ACC: %99.22], [D LOSS: 3.92], [G ACC: %100.00], [G LOSS: 0.06]\n",
      "E: 62, [D ACC: %99.22], [D LOSS: 3.66], [G ACC: %100.00], [G LOSS: 0.05]\n",
      "E: 63, [D ACC: %99.02], [D LOSS: 7.79], [G ACC: %100.00], [G LOSS: 0.04]\n",
      "E: 64, [D ACC: %99.80], [D LOSS: 4.48], [G ACC: %100.00], [G LOSS: 0.09]\n",
      "E: 65, [D ACC: %100.00], [D LOSS: 0.23], [G ACC: %100.00], [G LOSS: 0.18]\n",
      "E: 66, [D ACC: %100.00], [D LOSS: 1.47], [G ACC: %100.00], [G LOSS: 0.15]\n",
      "E: 67, [D ACC: %100.00], [D LOSS: 0.58], [G ACC: %100.00], [G LOSS: 0.22]\n",
      "E: 68, [D ACC: %99.61], [D LOSS: 2.07], [G ACC: %100.00], [G LOSS: 0.12]\n",
      "E: 69, [D ACC: %100.00], [D LOSS: 0.84], [G ACC: %100.00], [G LOSS: 0.21]\n",
      "E: 70, [D ACC: %99.61], [D LOSS: 1.01], [G ACC: %99.61], [G LOSS: 1.40]\n",
      "E: 71, [D ACC: %99.80], [D LOSS: 1.24], [G ACC: %100.00], [G LOSS: 1.11]\n",
      "E: 72, [D ACC: %99.80], [D LOSS: 1.25], [G ACC: %100.00], [G LOSS: 0.98]\n",
      "E: 73, [D ACC: %99.80], [D LOSS: 0.99], [G ACC: %90.62], [G LOSS: 26.91]\n",
      "E: 74, [D ACC: %100.00], [D LOSS: 0.44], [G ACC: %99.61], [G LOSS: 1.92]\n",
      "E: 75, [D ACC: %100.00], [D LOSS: 0.12], [G ACC: %100.00], [G LOSS: 0.39]\n",
      "E: 76, [D ACC: %100.00], [D LOSS: 0.23], [G ACC: %99.61], [G LOSS: 0.69]\n",
      "E: 77, [D ACC: %100.00], [D LOSS: 0.59], [G ACC: %100.00], [G LOSS: 0.17]\n",
      "E: 78, [D ACC: %100.00], [D LOSS: 0.72], [G ACC: %100.00], [G LOSS: 0.06]\n",
      "E: 79, [D ACC: %99.80], [D LOSS: 0.69], [G ACC: %100.00], [G LOSS: 0.02]\n",
      "E: 80, [D ACC: %99.80], [D LOSS: 1.67], [G ACC: %100.00], [G LOSS: 0.02]\n",
      "E: 81, [D ACC: %99.80], [D LOSS: 0.50], [G ACC: %100.00], [G LOSS: 0.01]\n",
      "E: 82, [D ACC: %100.00], [D LOSS: 0.25], [G ACC: %100.00], [G LOSS: 0.01]\n",
      "E: 83, [D ACC: %100.00], [D LOSS: 0.18], [G ACC: %100.00], [G LOSS: 0.02]\n",
      "E: 84, [D ACC: %100.00], [D LOSS: 0.26], [G ACC: %100.00], [G LOSS: 0.01]\n",
      "E: 85, [D ACC: %100.00], [D LOSS: 0.14], [G ACC: %100.00], [G LOSS: 0.02]\n",
      "E: 86, [D ACC: %100.00], [D LOSS: 0.20], [G ACC: %100.00], [G LOSS: 0.06]\n",
      "E: 87, [D ACC: %100.00], [D LOSS: 0.10], [G ACC: %100.00], [G LOSS: 0.03]\n",
      "E: 88, [D ACC: %100.00], [D LOSS: 0.11], [G ACC: %100.00], [G LOSS: 0.15]\n",
      "E: 89, [D ACC: %99.80], [D LOSS: 3.30], [G ACC: %100.00], [G LOSS: 0.30]\n",
      "E: 90, [D ACC: %100.00], [D LOSS: 0.50], [G ACC: %99.22], [G LOSS: 4.47]\n",
      "E: 91, [D ACC: %98.83], [D LOSS: 7.69], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 92, [D ACC: %50.78], [D LOSS: 344.31], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 93, [D ACC: %90.04], [D LOSS: 161.22], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 94, [D ACC: %91.99], [D LOSS: 130.10], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 95, [D ACC: %92.38], [D LOSS: 123.60], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 96, [D ACC: %90.82], [D LOSS: 148.40], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 97, [D ACC: %91.21], [D LOSS: 142.02], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 98, [D ACC: %91.21], [D LOSS: 142.02], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 99, [D ACC: %90.62], [D LOSS: 150.89], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 100, [D ACC: %90.23], [D LOSS: 154.80], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 101, [D ACC: %91.41], [D LOSS: 133.18], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 102, [D ACC: %91.41], [D LOSS: 138.88], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 103, [D ACC: %89.84], [D LOSS: 163.93], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 104, [D ACC: %91.02], [D LOSS: 145.01], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 105, [D ACC: %90.43], [D LOSS: 154.41], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 106, [D ACC: %91.21], [D LOSS: 141.84], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 107, [D ACC: %91.99], [D LOSS: 129.42], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 108, [D ACC: %90.04], [D LOSS: 160.70], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 109, [D ACC: %90.82], [D LOSS: 148.12], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 110, [D ACC: %90.43], [D LOSS: 151.92], [G ACC: %0.00], [G LOSS: 1611.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 111, [D ACC: %91.21], [D LOSS: 141.80], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 112, [D ACC: %92.77], [D LOSS: 116.63], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 113, [D ACC: %93.16], [D LOSS: 110.48], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 114, [D ACC: %93.36], [D LOSS: 107.24], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 115, [D ACC: %91.60], [D LOSS: 135.52], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 116, [D ACC: %91.99], [D LOSS: 129.24], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 117, [D ACC: %93.16], [D LOSS: 110.36], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 118, [D ACC: %90.04], [D LOSS: 160.63], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 119, [D ACC: %95.51], [D LOSS: 72.58], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 120, [D ACC: %90.62], [D LOSS: 151.18], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 121, [D ACC: %93.36], [D LOSS: 107.13], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 122, [D ACC: %88.87], [D LOSS: 179.49], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 123, [D ACC: %91.02], [D LOSS: 144.89], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 124, [D ACC: %90.62], [D LOSS: 151.19], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 125, [D ACC: %93.16], [D LOSS: 110.26], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 126, [D ACC: %92.97], [D LOSS: 113.44], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 127, [D ACC: %93.16], [D LOSS: 110.26], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 128, [D ACC: %89.06], [D LOSS: 176.35], [G ACC: %0.00], [G LOSS: 1611.67]\n",
      "E: 129, [D ACC: %93.36], [D LOSS: 104.37], [G ACC: %0.00], [G LOSS: 1588.56]\n",
      "E: 130, [D ACC: %88.87], [D LOSS: 176.74], [G ACC: %0.39], [G LOSS: 1099.32]\n",
      "E: 131, [D ACC: %67.58], [D LOSS: 227.25], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 132, [D ACC: %90.23], [D LOSS: 156.62], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 133, [D ACC: %91.21], [D LOSS: 133.69], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 134, [D ACC: %93.36], [D LOSS: 107.46], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 135, [D ACC: %87.70], [D LOSS: 195.97], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 136, [D ACC: %91.60], [D LOSS: 132.11], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 137, [D ACC: %90.04], [D LOSS: 155.76], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 138, [D ACC: %91.41], [D LOSS: 139.60], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 139, [D ACC: %90.62], [D LOSS: 150.15], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 140, [D ACC: %89.84], [D LOSS: 164.46], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 141, [D ACC: %90.43], [D LOSS: 152.49], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 142, [D ACC: %91.60], [D LOSS: 133.77], [G ACC: %0.00], [G LOSS: 1611.25]\n",
      "E: 143, [D ACC: %89.84], [D LOSS: 158.78], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 144, [D ACC: %91.21], [D LOSS: 142.20], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 145, [D ACC: %91.41], [D LOSS: 136.13], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 146, [D ACC: %91.21], [D LOSS: 142.15], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 147, [D ACC: %91.41], [D LOSS: 135.96], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 148, [D ACC: %92.97], [D LOSS: 113.90], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 149, [D ACC: %91.41], [D LOSS: 133.41], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 150, [D ACC: %89.45], [D LOSS: 170.24], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 151, [D ACC: %92.19], [D LOSS: 122.49], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 152, [D ACC: %91.02], [D LOSS: 140.46], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 153, [D ACC: %89.84], [D LOSS: 163.97], [G ACC: %0.00], [G LOSS: 1611.22]\n",
      "E: 154, [D ACC: %91.41], [D LOSS: 138.76], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 155, [D ACC: %92.58], [D LOSS: 119.94], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 156, [D ACC: %93.36], [D LOSS: 107.36], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 157, [D ACC: %91.21], [D LOSS: 139.79], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 158, [D ACC: %89.06], [D LOSS: 176.36], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 159, [D ACC: %91.02], [D LOSS: 144.95], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 160, [D ACC: %90.43], [D LOSS: 154.42], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 161, [D ACC: %90.23], [D LOSS: 152.35], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 162, [D ACC: %91.99], [D LOSS: 129.21], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 163, [D ACC: %89.84], [D LOSS: 163.91], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 164, [D ACC: %92.19], [D LOSS: 123.26], [G ACC: %0.00], [G LOSS: 1610.02]\n",
      "E: 165, [D ACC: %91.60], [D LOSS: 135.51], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 166, [D ACC: %91.60], [D LOSS: 135.46], [G ACC: %0.00], [G LOSS: 1611.81]\n",
      "E: 167, [D ACC: %91.99], [D LOSS: 129.23], [G ACC: %0.00], [G LOSS: 1606.70]\n",
      "E: 168, [D ACC: %90.43], [D LOSS: 154.32], [G ACC: %0.00], [G LOSS: 1611.02]\n",
      "E: 169, [D ACC: %91.02], [D LOSS: 142.29], [G ACC: %0.00], [G LOSS: 1610.61]\n",
      "E: 170, [D ACC: %92.38], [D LOSS: 123.02], [G ACC: %0.00], [G LOSS: 1611.00]\n",
      "E: 171, [D ACC: %93.36], [D LOSS: 107.27], [G ACC: %0.00], [G LOSS: 1609.66]\n",
      "E: 172, [D ACC: %90.62], [D LOSS: 150.92], [G ACC: %0.00], [G LOSS: 1606.16]\n",
      "E: 173, [D ACC: %91.41], [D LOSS: 138.66], [G ACC: %0.00], [G LOSS: 1603.68]\n",
      "E: 174, [D ACC: %91.60], [D LOSS: 134.48], [G ACC: %0.00], [G LOSS: 1562.62]\n",
      "E: 175, [D ACC: %90.43], [D LOSS: 151.41], [G ACC: %0.00], [G LOSS: 1507.91]\n",
      "E: 176, [D ACC: %88.28], [D LOSS: 181.26], [G ACC: %0.00], [G LOSS: 1330.16]\n",
      "E: 177, [D ACC: %92.77], [D LOSS: 102.42], [G ACC: %0.39], [G LOSS: 951.04]\n",
      "E: 178, [D ACC: %86.13], [D LOSS: 162.02], [G ACC: %0.00], [G LOSS: 1291.12]\n",
      "E: 179, [D ACC: %92.58], [D LOSS: 119.92], [G ACC: %0.00], [G LOSS: 1187.22]\n",
      "E: 180, [D ACC: %89.84], [D LOSS: 158.61], [G ACC: %8.20], [G LOSS: 716.05]\n",
      "E: 181, [D ACC: %83.59], [D LOSS: 176.60], [G ACC: %1.95], [G LOSS: 1254.36]\n",
      "E: 182, [D ACC: %86.33], [D LOSS: 162.20], [G ACC: %2.73], [G LOSS: 1072.95]\n",
      "E: 183, [D ACC: %75.00], [D LOSS: 221.74], [G ACC: %1.56], [G LOSS: 658.31]\n",
      "E: 184, [D ACC: %90.04], [D LOSS: 159.19], [G ACC: %0.00], [G LOSS: 729.22]\n",
      "E: 185, [D ACC: %91.02], [D LOSS: 117.21], [G ACC: %3.52], [G LOSS: 538.64]\n",
      "E: 186, [D ACC: %86.13], [D LOSS: 187.19], [G ACC: %7.42], [G LOSS: 469.76]\n",
      "E: 187, [D ACC: %89.06], [D LOSS: 151.87], [G ACC: %8.20], [G LOSS: 471.55]\n",
      "E: 188, [D ACC: %90.43], [D LOSS: 140.54], [G ACC: %5.08], [G LOSS: 492.55]\n",
      "E: 189, [D ACC: %91.02], [D LOSS: 128.52], [G ACC: %3.91], [G LOSS: 549.44]\n",
      "E: 190, [D ACC: %90.82], [D LOSS: 142.49], [G ACC: %1.56], [G LOSS: 578.74]\n",
      "E: 191, [D ACC: %91.60], [D LOSS: 132.01], [G ACC: %3.52], [G LOSS: 620.13]\n",
      "E: 192, [D ACC: %90.23], [D LOSS: 153.32], [G ACC: %5.08], [G LOSS: 593.21]\n",
      "E: 193, [D ACC: %89.65], [D LOSS: 140.28], [G ACC: %2.34], [G LOSS: 644.44]\n",
      "E: 194, [D ACC: %90.43], [D LOSS: 134.37], [G ACC: %0.78], [G LOSS: 785.60]\n",
      "E: 195, [D ACC: %89.26], [D LOSS: 157.96], [G ACC: %0.78], [G LOSS: 897.16]\n",
      "E: 196, [D ACC: %90.04], [D LOSS: 146.12], [G ACC: %0.39], [G LOSS: 947.70]\n",
      "E: 197, [D ACC: %90.62], [D LOSS: 149.76], [G ACC: %0.39], [G LOSS: 983.95]\n",
      "E: 198, [D ACC: %89.84], [D LOSS: 153.62], [G ACC: %0.00], [G LOSS: 980.82]\n",
      "E: 199, [D ACC: %90.23], [D LOSS: 154.17], [G ACC: %0.00], [G LOSS: 968.01]\n",
      "E: 200, [D ACC: %89.06], [D LOSS: 168.75], [G ACC: %0.39], [G LOSS: 853.11]\n",
      "E: 201, [D ACC: %91.99], [D LOSS: 126.90], [G ACC: %0.00], [G LOSS: 774.85]\n",
      "E: 202, [D ACC: %90.82], [D LOSS: 147.26], [G ACC: %1.17], [G LOSS: 595.78]\n",
      "E: 203, [D ACC: %90.62], [D LOSS: 150.58], [G ACC: %1.56], [G LOSS: 566.03]\n",
      "E: 204, [D ACC: %92.19], [D LOSS: 126.81], [G ACC: %0.00], [G LOSS: 284.99]\n",
      "E: 205, [D ACC: %100.00], [D LOSS: 10.23], [G ACC: %98.44], [G LOSS: 48.49]\n",
      "E: 206, [D ACC: %99.61], [D LOSS: 1.14], [G ACC: %96.48], [G LOSS: 34.55]\n",
      "E: 207, [D ACC: %99.80], [D LOSS: 1.99], [G ACC: %99.22], [G LOSS: 27.52]\n",
      "E: 208, [D ACC: %99.80], [D LOSS: 3.73], [G ACC: %99.61], [G LOSS: 22.65]\n",
      "E: 209, [D ACC: %99.61], [D LOSS: 1.07], [G ACC: %100.00], [G LOSS: 17.81]\n",
      "E: 210, [D ACC: %99.41], [D LOSS: 3.51], [G ACC: %100.00], [G LOSS: 19.69]\n",
      "E: 211, [D ACC: %100.00], [D LOSS: 0.18], [G ACC: %100.00], [G LOSS: 21.30]\n",
      "E: 212, [D ACC: %100.00], [D LOSS: 0.14], [G ACC: %100.00], [G LOSS: 22.14]\n",
      "E: 213, [D ACC: %100.00], [D LOSS: 0.12], [G ACC: %100.00], [G LOSS: 22.79]\n",
      "E: 214, [D ACC: %99.80], [D LOSS: 3.32], [G ACC: %100.00], [G LOSS: 23.42]\n",
      "E: 215, [D ACC: %99.80], [D LOSS: 0.39], [G ACC: %100.00], [G LOSS: 24.37]\n",
      "E: 216, [D ACC: %100.00], [D LOSS: 0.16], [G ACC: %100.00], [G LOSS: 24.77]\n",
      "E: 217, [D ACC: %100.00], [D LOSS: 0.12], [G ACC: %100.00], [G LOSS: 24.93]\n",
      "E: 218, [D ACC: %100.00], [D LOSS: 0.08], [G ACC: %100.00], [G LOSS: 25.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 219, [D ACC: %100.00], [D LOSS: 0.13], [G ACC: %99.61], [G LOSS: 30.69]\n",
      "E: 220, [D ACC: %100.00], [D LOSS: 0.20], [G ACC: %100.00], [G LOSS: 25.62]\n",
      "E: 221, [D ACC: %100.00], [D LOSS: 0.25], [G ACC: %100.00], [G LOSS: 26.51]\n",
      "E: 222, [D ACC: %100.00], [D LOSS: 0.24], [G ACC: %100.00], [G LOSS: 27.09]\n",
      "E: 223, [D ACC: %100.00], [D LOSS: 0.08], [G ACC: %99.61], [G LOSS: 29.07]\n",
      "E: 224, [D ACC: %100.00], [D LOSS: 0.10], [G ACC: %100.00], [G LOSS: 28.17]\n",
      "E: 225, [D ACC: %100.00], [D LOSS: 0.15], [G ACC: %100.00], [G LOSS: 28.81]\n",
      "E: 226, [D ACC: %100.00], [D LOSS: 0.07], [G ACC: %100.00], [G LOSS: 29.17]\n",
      "E: 227, [D ACC: %100.00], [D LOSS: 0.15], [G ACC: %100.00], [G LOSS: 29.48]\n",
      "E: 228, [D ACC: %100.00], [D LOSS: 0.08], [G ACC: %100.00], [G LOSS: 29.87]\n",
      "E: 229, [D ACC: %100.00], [D LOSS: 0.16], [G ACC: %100.00], [G LOSS: 29.77]\n",
      "E: 230, [D ACC: %100.00], [D LOSS: 0.09], [G ACC: %100.00], [G LOSS: 29.87]\n",
      "E: 231, [D ACC: %100.00], [D LOSS: 0.08], [G ACC: %100.00], [G LOSS: 30.25]\n",
      "E: 232, [D ACC: %99.61], [D LOSS: 3.85], [G ACC: %100.00], [G LOSS: 29.47]\n",
      "E: 233, [D ACC: %100.00], [D LOSS: 0.25], [G ACC: %100.00], [G LOSS: 30.41]\n",
      "E: 234, [D ACC: %100.00], [D LOSS: 0.13], [G ACC: %100.00], [G LOSS: 31.79]\n",
      "E: 235, [D ACC: %100.00], [D LOSS: 0.17], [G ACC: %100.00], [G LOSS: 32.34]\n",
      "E: 236, [D ACC: %100.00], [D LOSS: 0.18], [G ACC: %100.00], [G LOSS: 32.91]\n",
      "E: 237, [D ACC: %100.00], [D LOSS: 0.26], [G ACC: %100.00], [G LOSS: 34.40]\n",
      "E: 238, [D ACC: %100.00], [D LOSS: 0.13], [G ACC: %100.00], [G LOSS: 35.95]\n",
      "E: 239, [D ACC: %100.00], [D LOSS: 0.16], [G ACC: %100.00], [G LOSS: 37.25]\n",
      "E: 240, [D ACC: %99.80], [D LOSS: 0.52], [G ACC: %100.00], [G LOSS: 38.63]\n",
      "E: 241, [D ACC: %99.80], [D LOSS: 0.39], [G ACC: %100.00], [G LOSS: 41.56]\n",
      "E: 242, [D ACC: %100.00], [D LOSS: 0.29], [G ACC: %100.00], [G LOSS: 41.37]\n",
      "E: 243, [D ACC: %100.00], [D LOSS: 0.34], [G ACC: %100.00], [G LOSS: 39.39]\n",
      "E: 244, [D ACC: %100.00], [D LOSS: 0.19], [G ACC: %100.00], [G LOSS: 40.28]\n",
      "E: 245, [D ACC: %100.00], [D LOSS: 0.11], [G ACC: %100.00], [G LOSS: 41.38]\n",
      "E: 246, [D ACC: %100.00], [D LOSS: 0.26], [G ACC: %100.00], [G LOSS: 42.03]\n",
      "E: 247, [D ACC: %100.00], [D LOSS: 0.16], [G ACC: %100.00], [G LOSS: 42.76]\n",
      "E: 248, [D ACC: %100.00], [D LOSS: 0.23], [G ACC: %100.00], [G LOSS: 43.48]\n",
      "E: 249, [D ACC: %100.00], [D LOSS: 0.08], [G ACC: %100.00], [G LOSS: 44.46]\n",
      "E: 250, [D ACC: %100.00], [D LOSS: 0.16], [G ACC: %100.00], [G LOSS: 45.67]\n",
      "E: 251, [D ACC: %100.00], [D LOSS: 0.27], [G ACC: %100.00], [G LOSS: 47.34]\n",
      "E: 252, [D ACC: %100.00], [D LOSS: 0.09], [G ACC: %100.00], [G LOSS: 48.76]\n",
      "E: 253, [D ACC: %99.80], [D LOSS: 0.42], [G ACC: %100.00], [G LOSS: 50.89]\n",
      "E: 254, [D ACC: %99.80], [D LOSS: 0.37], [G ACC: %100.00], [G LOSS: 54.39]\n",
      "E: 255, [D ACC: %100.00], [D LOSS: 0.24], [G ACC: %100.00], [G LOSS: 58.13]\n",
      "E: 256, [D ACC: %100.00], [D LOSS: 0.19], [G ACC: %100.00], [G LOSS: 60.02]\n",
      "E: 257, [D ACC: %100.00], [D LOSS: 0.11], [G ACC: %100.00], [G LOSS: 61.57]\n",
      "E: 258, [D ACC: %100.00], [D LOSS: 0.21], [G ACC: %100.00], [G LOSS: 64.32]\n",
      "E: 259, [D ACC: %100.00], [D LOSS: 0.22], [G ACC: %100.00], [G LOSS: 67.71]\n",
      "E: 260, [D ACC: %100.00], [D LOSS: 0.26], [G ACC: %0.00], [G LOSS: 71.06]\n",
      "E: 261, [D ACC: %100.00], [D LOSS: 0.15], [G ACC: %0.00], [G LOSS: 73.30]\n",
      "E: 262, [D ACC: %100.00], [D LOSS: 0.12], [G ACC: %0.00], [G LOSS: 75.48]\n",
      "E: 263, [D ACC: %100.00], [D LOSS: 0.30], [G ACC: %0.00], [G LOSS: 76.97]\n",
      "E: 264, [D ACC: %100.00], [D LOSS: 0.17], [G ACC: %0.00], [G LOSS: 79.77]\n",
      "E: 265, [D ACC: %100.00], [D LOSS: 0.13], [G ACC: %0.00], [G LOSS: 82.45]\n",
      "E: 266, [D ACC: %99.80], [D LOSS: 3.47], [G ACC: %0.00], [G LOSS: 84.18]\n",
      "E: 267, [D ACC: %100.00], [D LOSS: 0.32], [G ACC: %0.00], [G LOSS: 89.77]\n",
      "E: 268, [D ACC: %100.00], [D LOSS: 0.38], [G ACC: %0.00], [G LOSS: 98.06]\n",
      "E: 269, [D ACC: %100.00], [D LOSS: 0.23], [G ACC: %0.00], [G LOSS: 105.17]\n",
      "E: 270, [D ACC: %100.00], [D LOSS: 0.22], [G ACC: %0.00], [G LOSS: 107.37]\n",
      "E: 271, [D ACC: %99.80], [D LOSS: 0.41], [G ACC: %0.00], [G LOSS: 105.73]\n",
      "E: 272, [D ACC: %100.00], [D LOSS: 0.30], [G ACC: %0.00], [G LOSS: 108.43]\n",
      "E: 273, [D ACC: %100.00], [D LOSS: 0.29], [G ACC: %0.00], [G LOSS: 113.51]\n",
      "E: 274, [D ACC: %100.00], [D LOSS: 0.32], [G ACC: %0.00], [G LOSS: 115.50]\n",
      "E: 275, [D ACC: %100.00], [D LOSS: 0.21], [G ACC: %0.00], [G LOSS: 121.17]\n",
      "E: 276, [D ACC: %99.80], [D LOSS: 0.95], [G ACC: %0.00], [G LOSS: 130.90]\n",
      "E: 277, [D ACC: %100.00], [D LOSS: 0.24], [G ACC: %0.00], [G LOSS: 143.18]\n",
      "E: 278, [D ACC: %99.80], [D LOSS: 0.91], [G ACC: %0.00], [G LOSS: 137.66]\n",
      "E: 279, [D ACC: %100.00], [D LOSS: 0.24], [G ACC: %0.00], [G LOSS: 141.42]\n",
      "E: 280, [D ACC: %100.00], [D LOSS: 0.44], [G ACC: %0.00], [G LOSS: 148.36]\n",
      "E: 281, [D ACC: %100.00], [D LOSS: 0.46], [G ACC: %0.00], [G LOSS: 160.35]\n",
      "E: 282, [D ACC: %99.80], [D LOSS: 1.75], [G ACC: %0.00], [G LOSS: 133.07]\n",
      "E: 283, [D ACC: %100.00], [D LOSS: 0.50], [G ACC: %0.00], [G LOSS: 146.25]\n",
      "E: 284, [D ACC: %99.80], [D LOSS: 0.66], [G ACC: %0.00], [G LOSS: 165.71]\n",
      "E: 285, [D ACC: %100.00], [D LOSS: 0.40], [G ACC: %0.00], [G LOSS: 177.60]\n",
      "E: 286, [D ACC: %99.80], [D LOSS: 0.51], [G ACC: %0.00], [G LOSS: 195.78]\n",
      "E: 287, [D ACC: %100.00], [D LOSS: 0.26], [G ACC: %0.00], [G LOSS: 212.47]\n",
      "E: 288, [D ACC: %100.00], [D LOSS: 0.23], [G ACC: %0.00], [G LOSS: 226.15]\n",
      "E: 289, [D ACC: %100.00], [D LOSS: 0.16], [G ACC: %0.00], [G LOSS: 237.13]\n",
      "E: 290, [D ACC: %99.61], [D LOSS: 1.21], [G ACC: %0.00], [G LOSS: 233.44]\n",
      "E: 291, [D ACC: %100.00], [D LOSS: 0.38], [G ACC: %0.00], [G LOSS: 248.74]\n",
      "E: 292, [D ACC: %100.00], [D LOSS: 0.30], [G ACC: %0.00], [G LOSS: 268.34]\n",
      "E: 293, [D ACC: %100.00], [D LOSS: 0.28], [G ACC: %0.00], [G LOSS: 286.61]\n",
      "E: 294, [D ACC: %100.00], [D LOSS: 0.32], [G ACC: %0.00], [G LOSS: 294.29]\n",
      "E: 295, [D ACC: %99.80], [D LOSS: 0.94], [G ACC: %0.00], [G LOSS: 291.45]\n",
      "E: 296, [D ACC: %100.00], [D LOSS: 0.39], [G ACC: %0.00], [G LOSS: 311.76]\n",
      "E: 297, [D ACC: %99.80], [D LOSS: 3.38], [G ACC: %0.00], [G LOSS: 326.93]\n",
      "E: 298, [D ACC: %99.80], [D LOSS: 0.38], [G ACC: %0.00], [G LOSS: 335.11]\n",
      "E: 299, [D ACC: %100.00], [D LOSS: 0.43], [G ACC: %0.00], [G LOSS: 339.11]\n",
      "E: 300, [D ACC: %99.80], [D LOSS: 0.86], [G ACC: %0.00], [G LOSS: 343.44]\n",
      "E: 301, [D ACC: %100.00], [D LOSS: 0.30], [G ACC: %0.00], [G LOSS: 358.23]\n",
      "E: 302, [D ACC: %99.80], [D LOSS: 3.54], [G ACC: %0.00], [G LOSS: 366.45]\n",
      "E: 303, [D ACC: %100.00], [D LOSS: 0.40], [G ACC: %0.00], [G LOSS: 385.67]\n",
      "E: 304, [D ACC: %99.80], [D LOSS: 0.55], [G ACC: %0.00], [G LOSS: 403.69]\n",
      "E: 305, [D ACC: %100.00], [D LOSS: 0.23], [G ACC: %0.00], [G LOSS: 419.16]\n",
      "E: 306, [D ACC: %100.00], [D LOSS: 0.67], [G ACC: %0.00], [G LOSS: 423.65]\n",
      "E: 307, [D ACC: %100.00], [D LOSS: 0.24], [G ACC: %0.00], [G LOSS: 444.42]\n",
      "E: 308, [D ACC: %100.00], [D LOSS: 0.46], [G ACC: %0.00], [G LOSS: 460.48]\n",
      "E: 309, [D ACC: %100.00], [D LOSS: 0.42], [G ACC: %0.00], [G LOSS: 463.52]\n",
      "E: 310, [D ACC: %100.00], [D LOSS: 0.38], [G ACC: %0.00], [G LOSS: 465.62]\n",
      "E: 311, [D ACC: %100.00], [D LOSS: 0.45], [G ACC: %0.00], [G LOSS: 459.58]\n",
      "E: 312, [D ACC: %100.00], [D LOSS: 0.26], [G ACC: %0.00], [G LOSS: 466.25]\n",
      "E: 313, [D ACC: %100.00], [D LOSS: 0.72], [G ACC: %0.00], [G LOSS: 442.57]\n",
      "E: 314, [D ACC: %100.00], [D LOSS: 0.88], [G ACC: %0.00], [G LOSS: 409.20]\n",
      "E: 315, [D ACC: %100.00], [D LOSS: 0.56], [G ACC: %0.00], [G LOSS: 443.26]\n",
      "E: 316, [D ACC: %100.00], [D LOSS: 0.93], [G ACC: %0.00], [G LOSS: 455.62]\n",
      "E: 317, [D ACC: %99.80], [D LOSS: 0.35], [G ACC: %0.00], [G LOSS: 489.68]\n",
      "E: 318, [D ACC: %100.00], [D LOSS: 0.33], [G ACC: %0.00], [G LOSS: 524.94]\n",
      "E: 319, [D ACC: %100.00], [D LOSS: 0.41], [G ACC: %0.00], [G LOSS: 540.57]\n",
      "E: 320, [D ACC: %100.00], [D LOSS: 0.17], [G ACC: %0.00], [G LOSS: 559.02]\n",
      "E: 321, [D ACC: %100.00], [D LOSS: 0.41], [G ACC: %0.00], [G LOSS: 558.72]\n",
      "E: 322, [D ACC: %100.00], [D LOSS: 0.22], [G ACC: %0.00], [G LOSS: 566.17]\n",
      "E: 323, [D ACC: %100.00], [D LOSS: 0.31], [G ACC: %0.00], [G LOSS: 573.13]\n",
      "E: 324, [D ACC: %100.00], [D LOSS: 0.34], [G ACC: %0.00], [G LOSS: 570.25]\n",
      "E: 325, [D ACC: %100.00], [D LOSS: 0.18], [G ACC: %0.00], [G LOSS: 584.16]\n",
      "E: 326, [D ACC: %100.00], [D LOSS: 0.20], [G ACC: %0.00], [G LOSS: 597.52]\n",
      "E: 327, [D ACC: %100.00], [D LOSS: 0.33], [G ACC: %0.00], [G LOSS: 594.93]\n",
      "E: 328, [D ACC: %100.00], [D LOSS: 0.15], [G ACC: %0.00], [G LOSS: 607.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 329, [D ACC: %100.00], [D LOSS: 0.14], [G ACC: %0.00], [G LOSS: 618.10]\n",
      "E: 330, [D ACC: %100.00], [D LOSS: 0.11], [G ACC: %0.00], [G LOSS: 631.16]\n",
      "E: 331, [D ACC: %100.00], [D LOSS: 0.62], [G ACC: %0.00], [G LOSS: 590.41]\n",
      "E: 332, [D ACC: %100.00], [D LOSS: 0.18], [G ACC: %0.00], [G LOSS: 591.64]\n",
      "E: 333, [D ACC: %99.80], [D LOSS: 3.44], [G ACC: %0.00], [G LOSS: 591.18]\n",
      "E: 334, [D ACC: %100.00], [D LOSS: 0.13], [G ACC: %0.00], [G LOSS: 602.90]\n",
      "E: 335, [D ACC: %100.00], [D LOSS: 0.18], [G ACC: %0.00], [G LOSS: 613.18]\n",
      "E: 336, [D ACC: %99.80], [D LOSS: 3.29], [G ACC: %0.00], [G LOSS: 625.70]\n",
      "E: 337, [D ACC: %100.00], [D LOSS: 0.15], [G ACC: %0.00], [G LOSS: 634.29]\n",
      "E: 338, [D ACC: %100.00], [D LOSS: 0.44], [G ACC: %0.00], [G LOSS: 609.68]\n",
      "E: 339, [D ACC: %100.00], [D LOSS: 0.12], [G ACC: %0.00], [G LOSS: 616.71]\n",
      "E: 340, [D ACC: %100.00], [D LOSS: 0.13], [G ACC: %0.00], [G LOSS: 628.72]\n",
      "E: 341, [D ACC: %100.00], [D LOSS: 0.19], [G ACC: %0.00], [G LOSS: 633.47]\n",
      "E: 342, [D ACC: %100.00], [D LOSS: 0.09], [G ACC: %0.00], [G LOSS: 645.34]\n",
      "E: 343, [D ACC: %100.00], [D LOSS: 0.10], [G ACC: %0.00], [G LOSS: 656.61]\n",
      "E: 344, [D ACC: %100.00], [D LOSS: 0.10], [G ACC: %0.00], [G LOSS: 665.78]\n",
      "E: 345, [D ACC: %100.00], [D LOSS: 0.26], [G ACC: %0.00], [G LOSS: 654.94]\n",
      "E: 346, [D ACC: %100.00], [D LOSS: 0.08], [G ACC: %0.00], [G LOSS: 660.71]\n",
      "E: 347, [D ACC: %100.00], [D LOSS: 0.08], [G ACC: %0.00], [G LOSS: 670.32]\n",
      "E: 348, [D ACC: %100.00], [D LOSS: 0.09], [G ACC: %0.00], [G LOSS: 678.16]\n",
      "E: 349, [D ACC: %100.00], [D LOSS: 0.07], [G ACC: %0.00], [G LOSS: 686.22]\n",
      "E: 350, [D ACC: %100.00], [D LOSS: 0.08], [G ACC: %0.00], [G LOSS: 692.54]\n",
      "E: 351, [D ACC: %100.00], [D LOSS: 0.13], [G ACC: %0.00], [G LOSS: 690.76]\n",
      "E: 352, [D ACC: %100.00], [D LOSS: 0.07], [G ACC: %0.00], [G LOSS: 695.19]\n",
      "E: 353, [D ACC: %100.00], [D LOSS: 0.06], [G ACC: %0.00], [G LOSS: 701.70]\n",
      "E: 354, [D ACC: %100.00], [D LOSS: 0.21], [G ACC: %0.00], [G LOSS: 689.35]\n",
      "E: 355, [D ACC: %99.80], [D LOSS: 3.33], [G ACC: %0.00], [G LOSS: 677.21]\n",
      "E: 356, [D ACC: %100.00], [D LOSS: 0.06], [G ACC: %0.00], [G LOSS: 681.58]\n",
      "E: 357, [D ACC: %100.00], [D LOSS: 0.06], [G ACC: %0.00], [G LOSS: 689.54]\n",
      "E: 358, [D ACC: %100.00], [D LOSS: 0.06], [G ACC: %0.00], [G LOSS: 697.82]\n",
      "E: 359, [D ACC: %100.00], [D LOSS: 0.05], [G ACC: %0.00], [G LOSS: 705.94]\n",
      "E: 360, [D ACC: %100.00], [D LOSS: 0.10], [G ACC: %0.00], [G LOSS: 707.01]\n",
      "E: 361, [D ACC: %100.00], [D LOSS: 0.06], [G ACC: %0.00], [G LOSS: 712.20]\n",
      "E: 362, [D ACC: %100.00], [D LOSS: 0.13], [G ACC: %0.00], [G LOSS: 707.90]\n",
      "E: 363, [D ACC: %99.61], [D LOSS: 2.69], [G ACC: %0.00], [G LOSS: 671.81]\n",
      "E: 364, [D ACC: %100.00], [D LOSS: 0.09], [G ACC: %0.00], [G LOSS: 668.15]\n",
      "E: 365, [D ACC: %100.00], [D LOSS: 0.22], [G ACC: %0.00], [G LOSS: 656.37]\n",
      "E: 366, [D ACC: %100.00], [D LOSS: 20.41], [G ACC: %0.00], [G LOSS: 855.54]\n",
      "E: 367, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 1368.55]\n",
      "E: 368, [D ACC: %99.02], [D LOSS: 6.91], [G ACC: %0.00], [G LOSS: 807.13]\n",
      "E: 369, [D ACC: %100.00], [D LOSS: 0.05], [G ACC: %0.00], [G LOSS: 651.87]\n",
      "E: 370, [D ACC: %100.00], [D LOSS: 0.10], [G ACC: %0.00], [G LOSS: 623.80]\n",
      "E: 371, [D ACC: %100.00], [D LOSS: 0.10], [G ACC: %0.00], [G LOSS: 630.56]\n",
      "E: 372, [D ACC: %100.00], [D LOSS: 0.17], [G ACC: %0.00], [G LOSS: 642.21]\n",
      "E: 373, [D ACC: %100.00], [D LOSS: 0.08], [G ACC: %0.00], [G LOSS: 656.76]\n",
      "E: 374, [D ACC: %100.00], [D LOSS: 0.07], [G ACC: %0.00], [G LOSS: 670.54]\n",
      "E: 375, [D ACC: %100.00], [D LOSS: 0.06], [G ACC: %0.00], [G LOSS: 682.87]\n",
      "E: 376, [D ACC: %99.80], [D LOSS: 3.20], [G ACC: %0.00], [G LOSS: 693.72]\n",
      "E: 377, [D ACC: %99.61], [D LOSS: 4.37], [G ACC: %0.00], [G LOSS: 690.44]\n",
      "E: 378, [D ACC: %100.00], [D LOSS: 0.05], [G ACC: %0.00], [G LOSS: 696.95]\n",
      "E: 379, [D ACC: %100.00], [D LOSS: 0.05], [G ACC: %0.00], [G LOSS: 705.53]\n",
      "E: 380, [D ACC: %100.00], [D LOSS: 0.04], [G ACC: %0.00], [G LOSS: 714.03]\n",
      "E: 381, [D ACC: %100.00], [D LOSS: 0.04], [G ACC: %0.00], [G LOSS: 721.94]\n",
      "E: 382, [D ACC: %100.00], [D LOSS: 0.04], [G ACC: %0.00], [G LOSS: 729.40]\n",
      "E: 383, [D ACC: %100.00], [D LOSS: 0.03], [G ACC: %0.00], [G LOSS: 736.34]\n",
      "E: 384, [D ACC: %100.00], [D LOSS: 0.03], [G ACC: %0.00], [G LOSS: 742.85]\n",
      "E: 385, [D ACC: %100.00], [D LOSS: 0.03], [G ACC: %0.00], [G LOSS: 748.94]\n",
      "E: 386, [D ACC: %100.00], [D LOSS: 0.03], [G ACC: %0.00], [G LOSS: 754.60]\n",
      "E: 387, [D ACC: %100.00], [D LOSS: 0.03], [G ACC: %0.00], [G LOSS: 760.07]\n",
      "E: 388, [D ACC: %100.00], [D LOSS: 0.03], [G ACC: %0.00], [G LOSS: 765.15]\n",
      "E: 389, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 770.04]\n",
      "E: 390, [D ACC: %100.00], [D LOSS: 0.03], [G ACC: %0.00], [G LOSS: 774.51]\n",
      "E: 391, [D ACC: %100.00], [D LOSS: 0.03], [G ACC: %0.00], [G LOSS: 778.61]\n",
      "E: 392, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 782.86]\n",
      "E: 393, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 786.93]\n",
      "E: 394, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 790.73]\n",
      "E: 395, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 794.50]\n",
      "E: 396, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 798.22]\n",
      "E: 397, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 801.66]\n",
      "E: 398, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 805.02]\n",
      "E: 399, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 808.37]\n",
      "E: 400, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 811.49]\n",
      "E: 401, [D ACC: %100.00], [D LOSS: 0.03], [G ACC: %0.00], [G LOSS: 813.90]\n",
      "E: 402, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 816.80]\n",
      "E: 403, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 819.75]\n",
      "E: 404, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 822.67]\n",
      "E: 405, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 825.49]\n",
      "E: 406, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 828.13]\n",
      "E: 407, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 830.68]\n",
      "E: 408, [D ACC: %100.00], [D LOSS: 0.02], [G ACC: %0.00], [G LOSS: 833.11]\n",
      "E: 409, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 835.60]\n",
      "E: 410, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 838.08]\n",
      "E: 411, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 840.56]\n",
      "E: 412, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 842.95]\n",
      "E: 413, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 845.28]\n",
      "E: 414, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 847.55]\n",
      "E: 415, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 849.58]\n",
      "E: 416, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 851.73]\n",
      "E: 417, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 853.75]\n",
      "E: 418, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 855.90]\n",
      "E: 419, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 857.95]\n",
      "E: 420, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 859.79]\n",
      "E: 421, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 861.64]\n",
      "E: 422, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 863.62]\n",
      "E: 423, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 865.65]\n",
      "E: 424, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 867.58]\n",
      "E: 425, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 869.44]\n",
      "E: 426, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 871.21]\n",
      "E: 427, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 872.94]\n",
      "E: 428, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 874.58]\n",
      "E: 429, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 876.12]\n",
      "E: 430, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 877.62]\n",
      "E: 431, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 879.32]\n",
      "E: 432, [D ACC: %99.80], [D LOSS: 3.16], [G ACC: %0.00], [G LOSS: 880.82]\n",
      "E: 433, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 882.47]\n",
      "E: 434, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 883.79]\n",
      "E: 435, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 885.19]\n",
      "E: 436, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 886.75]\n",
      "E: 437, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 888.26]\n",
      "E: 438, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 889.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 439, [D ACC: %100.00], [D LOSS: 0.01], [G ACC: %0.00], [G LOSS: 890.82]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "STEPS = 1  # 60000 // BATCH_SIZE\n",
    "\n",
    "\n",
    "train_loss_g = []\n",
    "train_loss_d = []\n",
    "\n",
    "train_acc_g = []\n",
    "train_acc_d = []\n",
    "\n",
    "\n",
    "disc_itr = load_batch()\n",
    "gen_itr = load_noise()\n",
    "\n",
    "\n",
    "# epochs\n",
    "for e in range(EPOCHS):\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "        \n",
    "        x, z_fake, y_fake, z_real, y_real = next(disc_itr)\n",
    "\n",
    "        # train\n",
    "        loss_2, acc_2 = discriminator.train_on_batch(z_real, y_real)\n",
    "        loss_1, acc_1 = discriminator.train_on_batch(z_fake, y_fake)\n",
    "\n",
    "        batch_loss = 0.5 * (loss_1 + loss_2)\n",
    "        batch_acc = 0.5 * (acc_1 + acc_2)\n",
    "\n",
    "        loss.append(batch_loss)\n",
    "        acc.append(batch_acc)\n",
    "\n",
    "    train_loss_d.append(np.mean(np.array(loss)))\n",
    "    train_acc_d.append(np.mean(np.array(acc)))\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "        x, y_true = next(gen_itr)\n",
    "\n",
    "        # train\n",
    "        loss_1, acc_1 = gan.train_on_batch(x, y_true)\n",
    "\n",
    "        loss.append(loss_1)\n",
    "        acc.append(acc_1)\n",
    "\n",
    "    train_loss_g.append(np.mean(np.array(loss)))\n",
    "    train_acc_g.append(np.mean(np.array(acc)))\n",
    "\n",
    "\n",
    "    print(\"E: {}, [D ACC: %{:.2f}], [D LOSS: {:.2f}], [G ACC: %{:.2f}], [G LOSS: {:.2f}]\".format(\n",
    "          e,\n",
    "          train_acc_d[-1] * 100,\n",
    "          train_loss_d[-1] * 100,\n",
    "          train_acc_g[-1] * 100,\n",
    "          train_loss_g[-1] * 100\n",
    "      ))\n",
    "\n",
    "    if e % 100 == 0:\n",
    "        ## visualize results\n",
    "        x, z_fake, y_fake, z_real, y_real = next(disc_itr)\n",
    "        visualizeGAN(e, z_real, z_fake)\n",
    "        \n",
    "        ## save model\n",
    "        pth = os.path.join(models_path, 'gan.h5')\n",
    "        gan.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'generator-{}-{}-{}.h5'.format(e, train_loss_g[-1], train_acc_g[-1]))\n",
    "        generator.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'discriminator.h5')\n",
    "        discriminator.save(pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnlcqEI8i9uH"
   },
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LzhKde-CaDu"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_loss_g, label=\"Generator Loss\");\n",
    "plt.plot(train_loss_d, label=\"Discriminator Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9iCkvcai9uS"
   },
   "source": [
    "## Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YhSUa3fROSg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_acc_g, label=\"Generator Accuracy\");\n",
    "plt.plot(train_acc_d, label=\"Discriminator Accuracy\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "pth = os.path.join(models_path, 'gray-gan.h5')\n",
    "gan.save(pth)\n",
    "\n",
    "pth = os.path.join(models_path, 'gray-generator.h5')\n",
    "generator.save(pth)\n",
    "\n",
    "pth = os.path.join(models_path, 'gray-discriminator.h5')\n",
    "discriminator.save(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST Test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
