{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAQBOBYyi9sc"
   },
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1554977904593,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "BIEdHLeqDLJH",
    "outputId": "90567bca-f98c-4b16-c01f-adc92d510da4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "root_path = './'\n",
    "\n",
    "models_path = os.path.join(root_path, 'saved_models_mnist_v9')\n",
    "if not os.path.exists(models_path):\n",
    "    os.mkdir(models_path)\n",
    "\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = (x_train / 127.5) - 1, (x_test / 127.5) - 1\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2751,
     "status": "ok",
     "timestamp": 1554977904597,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "MxSDNtvqj0Xs",
    "outputId": "876f60f6-e4ef-4454-bfa5-f3ff6b5a8f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(60000, 28, 28, 1) (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "y_train = to_categorical(y_train)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-5tD_u3kY9T"
   },
   "outputs": [],
   "source": [
    "def custom_loader():\n",
    "\n",
    "  trainset_size = x_train.shape[0]\n",
    "\n",
    "  p = 0\n",
    "  while True:\n",
    "\n",
    "    idx_from = (p * BATCH_SIZE) % trainset_size\n",
    "\n",
    "    idx_to = idx_from + BATCH_SIZE\n",
    "\n",
    "    batch_x = x_train[idx_from: idx_to]\n",
    "    batch_y = y_train[idx_from: idx_to]\n",
    "    \n",
    "    p += 1\n",
    "  \n",
    "    yield batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2498,
     "status": "ok",
     "timestamp": 1554977904621,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "3YQeAq8il_eI",
    "outputId": "40a7ee0a-86f7-4c97-c0d1-43276af0db75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 28, 28, 1) (256, 10)\n",
      "(256, 28, 28, 1) (256, 10)\n",
      "(256, 28, 28, 1) (256, 10)\n"
     ]
    }
   ],
   "source": [
    "custom_gen = custom_loader()\n",
    "for i in range(3):\n",
    "  batch_x, batch_y = next(custom_gen)\n",
    "  print(batch_x.shape, batch_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMouydu3i9sp"
   },
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3123,
     "status": "ok",
     "timestamp": 1554977905340,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "HAuHCfjlFBOy",
    "outputId": "abf88c5b-9df8-41dc-9017-9d8a2007a0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "D M1:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 6, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 3)           867       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 2, 3)           0         \n",
      "=================================================================\n",
      "Total params: 5,859\n",
      "Trainable params: 5,763\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "D M2:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 23        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 23\n",
      "Trainable params: 23\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "G M2:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_1 (Conv2DTr (None, 13, 13, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 27, 27, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 27, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         33        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,121\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "G M1:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 121)               7381      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 121)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 11, 11, 1)         0         \n",
      "=================================================================\n",
      "Total params: 7,381\n",
      "Trainable params: 7,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc_len = 0\n",
    "age_len = 10\n",
    "img_shape = (28, 28, 1)\n",
    "width, height, depth = (28, 28, 1)\n",
    "img_len = np.prod(img_shape)\n",
    "latent_dim = enc_len + age_len + img_len\n",
    "noise_len = 50  # 32 x 32 x 3\n",
    "input_dim = enc_len + age_len + noise_len\n",
    "cond_len = enc_len + age_len\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    conv = keras.Sequential([\n",
    "        # conv block 1\n",
    "        keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2,\n",
    "            input_shape=img_shape\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        # conv block 2\n",
    "        keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # conv block 3\n",
    "        keras.layers.Conv2D(\n",
    "            filters=3,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "    ])\n",
    "    \n",
    "    print(\"D M1:\")\n",
    "    conv.summary()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # output\n",
    "        keras.layers.Dense(1, input_shape=(age_len+12,)),\n",
    "        keras.layers.Activation(tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "    clf = keras.Sequential([\n",
    "        # output\n",
    "        keras.layers.Dense(age_len, input_shape=(age_len+12,)),\n",
    "        keras.layers.Activation(tf.nn.softmax),\n",
    "    ])\n",
    "    \n",
    "    print(\"D M2:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # condition\n",
    "#     c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # image\n",
    "    z = keras.layers.Input(shape=img_shape)\n",
    "    \n",
    "    # convolution\n",
    "    zout = conv(z)\n",
    "    \n",
    "    # flatten image\n",
    "    z_flat = keras.layers.Flatten()(zout)\n",
    "    \n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c2, z_flat])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # 0, 1, 2, 3, .. 9\n",
    "    lbl = clf(inputs)\n",
    "    \n",
    "    return keras.models.Model([c2, z], [outputs, lbl])\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    \n",
    "    conv = keras.Sequential([\n",
    "        # transpose conv block 1\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=1,\n",
    "            input_shape=(11, 11, 1)\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # transpose conv block 2\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # transpose conv block 3\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=(2, 2),\n",
    "            strides=1\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        # transpose conv block 4\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=1,\n",
    "            kernel_size=(1, 1),\n",
    "            strides=1\n",
    "        ),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Activation(tf.nn.tanh)\n",
    "    ])\n",
    "    \n",
    "    print(\"G M2:\")\n",
    "    conv.summary()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(121, input_shape=(input_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((11, 11, 1))\n",
    "    ])\n",
    "    \n",
    "    print(\"G M1:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # condition\n",
    "#     c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # noise\n",
    "    x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c2, x])\n",
    "    \n",
    "    # flat dense output\n",
    "    out_1 = model(inputs)\n",
    "    \n",
    "    # transpose conv output\n",
    "    outputs = conv(out_1)\n",
    "    \n",
    "    return keras.models.Model([c2, x], outputs)\n",
    "\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3046,
     "status": "ok",
     "timestamp": 1554977905345,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "tfo8J8jQ4-FH",
    "outputId": "022c24ae-1c6e-40ad-e167-964953449961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 60)           0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 11, 11, 1)    7381        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 28, 28, 1)    9281        sequential_4[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 16,662\n",
      "Trainable params: 16,502\n",
      "Non-trainable params: 160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3013,
     "status": "ok",
     "timestamp": 1554977905348,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "ObTb7HIf5CqA",
    "outputId": "1bdb05c0-cd96-46c6-a124-68ac9ee9ddb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 2, 2, 3)      5859        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12)           0           sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 22)           0           input_1[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1)            23          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,882\n",
      "Trainable params: 5,786\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctWfkxy5i9tR"
   },
   "source": [
    "## Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHTmYpPeImn5"
   },
   "outputs": [],
   "source": [
    "GLR = 0.01  # generator\n",
    "DLR = 0.01  # discriminator\n",
    "\n",
    "\n",
    "# Wasserstein\n",
    "def d_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(DLR, 0.5),\n",
    "    loss=[keras.losses.binary_crossentropy, keras.losses.categorical_crossentropy],\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# condition\n",
    "# c1 = keras.layers.Input(shape=(enc_len,))\n",
    "c2 = keras.layers.Input(shape=(age_len,))\n",
    "\n",
    "# noise\n",
    "x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "# freeze discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# output\n",
    "z = generator([c2, x])\n",
    "out, lbl = discriminator([c2, z])\n",
    "\n",
    "# GAN\n",
    "gan = keras.models.Model(inputs=[c2, x], outputs=[out, lbl])\n",
    "\n",
    "gan.compile(\n",
    "    optimizer=keras.optimizers.Adam(GLR , 0.5),\n",
    "    loss=[keras.losses.binary_crossentropy, keras.losses.categorical_cross_entropy],\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1554977905707,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "o_76rZ0ti9tc",
    "outputId": "8eb9fa73-4621-40e3-fab1-fd2d52d7bbe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 28, 28, 1)    16662       input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            5882        input_5[0][0]                    \n",
      "                                                                 model_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,544\n",
      "Trainable params: 16,502\n",
      "Non-trainable params: 6,042\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REaxJyLqi9tp"
   },
   "source": [
    "## Visualization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25210,
     "status": "ok",
     "timestamp": 1554977927807,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "4kA4g6_lt3D8",
    "outputId": "c5b38cce-ad98-49ac-9b13-950a8e2356ca"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os\n",
    "\n",
    "\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "root_path = './'\n",
    "tgt_pth = os.path.join(root_path, 'visualize_mnist-v20')\n",
    "\n",
    "if not os.path.exists(tgt_pth):\n",
    "  os.mkdir(tgt_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3nB78iWi9ts"
   },
   "outputs": [],
   "source": [
    "def visualizeGAN(e, z_real, z_fake, conditions=None):\n",
    "\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "\n",
    "    r_real = 0\n",
    "    r_fake = 0\n",
    "    for row, axe in enumerate(axes):\n",
    "        for col, cell in enumerate(axe):\n",
    "            if row % 2 == 0 and z_real is not None:\n",
    "                cell.imshow(\n",
    "                    np.squeeze(\n",
    "                        0.5 * z_real[r_real * 4 + col] + 0.5,\n",
    "                        axis=-1\n",
    "                    ),\n",
    "                    cmap='gray'\n",
    "                )\n",
    "            else:\n",
    "                cell.imshow(\n",
    "                    np.squeeze(\n",
    "                        0.5 * z_fake[r_fake * 5 + col] + 0.5,\n",
    "                        axis=-1\n",
    "                    ),\n",
    "                    cmap='gray'\n",
    "                )\n",
    "                cell.set_title(\n",
    "                    str(\n",
    "                        np.argmax(\n",
    "                            conditions[r_fake * 5 + col]\n",
    "                        )\n",
    "                    ) + \": \" + str(\n",
    "                        conditions[r_fake * 5 + col]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            cell.axis(\"off\")\n",
    "\n",
    "        if row % 2 == 0 and z_real is not None:\n",
    "            r_real += 1\n",
    "        else:\n",
    "            r_fake += 1\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(os.path.join(tgt_pth, '{}.jpg'.format(str(e).zfill(3))))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noise():\n",
    "    \n",
    "    y_true = tf.ones((BATCH_SIZE,))\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # run once\n",
    "        y_true = y_true.eval()\n",
    "\n",
    "        while True:\n",
    "            batch_x, batch_y = next(custom_gen)\n",
    "\n",
    "            sz = batch_x.shape[0]\n",
    "\n",
    "            if sz != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # fake data\n",
    "            c2 = tf.cast(batch_y, tf.float32).eval()\n",
    "            x = tf.random.normal((sz, noise_len,)).eval()\n",
    "            \n",
    "            yield c2, x, y_true\n",
    "\n",
    "\n",
    "def load_batch():\n",
    "    \n",
    "    y_fake = tf.zeros((BATCH_SIZE,))\n",
    "    y_true = tf.ones((BATCH_SIZE,))\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # run once\n",
    "        y_fake = y_fake.eval()\n",
    "        y_true = y_true.eval()\n",
    "\n",
    "        while True:\n",
    "            batch_x, batch_y = next(custom_gen)\n",
    "\n",
    "            sz = batch_x.shape[0]\n",
    "\n",
    "            if sz != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # fake data\n",
    "            c2 = tf.cast(batch_y, tf.float32).eval()\n",
    "            x = tf.random.normal((sz, noise_len,)).eval()\n",
    "            z_fake = generator.predict([c2, x])\n",
    "\n",
    "            # real data\n",
    "            c2 = tf.cast(batch_y, tf.float32).eval()\n",
    "            z_real = batch_x\n",
    "                        \n",
    "            yield c2, x, z_fake, y_fake, z_real, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GNNmDUZi9t3"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 0, D:[ACC: %85.99, LOSS: 30.14], G:[ACC: %41.02, LOSS: 90.78]\n",
      "E: 1, D:[ACC: %80.86, LOSS: 38.33], G:[ACC: %0.39, LOSS: 489.34]\n",
      "E: 2, D:[ACC: %85.94, LOSS: 31.26], G:[ACC: %0.00, LOSS: 437.58]\n",
      "E: 3, D:[ACC: %96.24, LOSS: 11.27], G:[ACC: %0.39, LOSS: 487.58]\n",
      "E: 4, D:[ACC: %94.48, LOSS: 15.40], G:[ACC: %0.00, LOSS: 404.61]\n",
      "E: 5, D:[ACC: %98.68, LOSS: 6.07], G:[ACC: %0.00, LOSS: 618.42]\n",
      "E: 6, D:[ACC: %99.71, LOSS: 2.04], G:[ACC: %0.00, LOSS: 694.08]\n",
      "E: 7, D:[ACC: %99.51, LOSS: 3.03], G:[ACC: %0.00, LOSS: 741.18]\n",
      "E: 8, D:[ACC: %99.80, LOSS: 1.90], G:[ACC: %0.00, LOSS: 689.42]\n",
      "E: 9, D:[ACC: %99.71, LOSS: 2.03], G:[ACC: %0.00, LOSS: 726.29]\n",
      "E: 10, D:[ACC: %93.36, LOSS: 19.07], G:[ACC: %0.00, LOSS: 802.16]\n",
      "E: 11, D:[ACC: %89.50, LOSS: 24.60], G:[ACC: %0.39, LOSS: 747.72]\n",
      "E: 12, D:[ACC: %95.80, LOSS: 11.58], G:[ACC: %2.73, LOSS: 520.00]\n",
      "E: 13, D:[ACC: %88.23, LOSS: 29.45], G:[ACC: %0.39, LOSS: 700.10]\n",
      "E: 14, D:[ACC: %95.36, LOSS: 12.54], G:[ACC: %1.95, LOSS: 545.11]\n",
      "E: 15, D:[ACC: %94.24, LOSS: 13.95], G:[ACC: %1.95, LOSS: 559.63]\n",
      "E: 16, D:[ACC: %94.87, LOSS: 13.73], G:[ACC: %0.78, LOSS: 535.41]\n",
      "E: 17, D:[ACC: %71.04, LOSS: 83.85], G:[ACC: %19.92, LOSS: 259.55]\n",
      "E: 18, D:[ACC: %87.70, LOSS: 28.10], G:[ACC: %7.81, LOSS: 355.48]\n",
      "E: 19, D:[ACC: %94.53, LOSS: 15.97], G:[ACC: %4.30, LOSS: 357.44]\n",
      "E: 20, D:[ACC: %92.58, LOSS: 19.10], G:[ACC: %14.84, LOSS: 262.66]\n",
      "E: 21, D:[ACC: %82.08, LOSS: 44.85], G:[ACC: %13.67, LOSS: 253.00]\n",
      "E: 22, D:[ACC: %94.92, LOSS: 14.35], G:[ACC: %20.70, LOSS: 222.53]\n",
      "E: 23, D:[ACC: %71.24, LOSS: 71.08], G:[ACC: %21.48, LOSS: 182.20]\n",
      "E: 24, D:[ACC: %77.54, LOSS: 46.46], G:[ACC: %14.06, LOSS: 185.45]\n",
      "E: 25, D:[ACC: %79.30, LOSS: 43.92], G:[ACC: %7.03, LOSS: 215.42]\n",
      "E: 26, D:[ACC: %83.35, LOSS: 36.81], G:[ACC: %1.17, LOSS: 275.39]\n",
      "E: 27, D:[ACC: %68.65, LOSS: 66.57], G:[ACC: %12.89, LOSS: 159.18]\n",
      "E: 28, D:[ACC: %81.15, LOSS: 41.33], G:[ACC: %12.11, LOSS: 170.15]\n",
      "E: 29, D:[ACC: %81.01, LOSS: 43.37], G:[ACC: %14.84, LOSS: 170.96]\n",
      "E: 30, D:[ACC: %82.81, LOSS: 41.21], G:[ACC: %4.30, LOSS: 234.25]\n",
      "E: 31, D:[ACC: %81.40, LOSS: 41.80], G:[ACC: %2.73, LOSS: 221.32]\n",
      "E: 32, D:[ACC: %81.05, LOSS: 42.34], G:[ACC: %3.12, LOSS: 241.36]\n",
      "E: 33, D:[ACC: %87.89, LOSS: 30.74], G:[ACC: %1.56, LOSS: 327.63]\n",
      "E: 34, D:[ACC: %86.43, LOSS: 31.49], G:[ACC: %3.12, LOSS: 293.84]\n",
      "E: 35, D:[ACC: %83.59, LOSS: 36.70], G:[ACC: %6.25, LOSS: 243.65]\n",
      "E: 36, D:[ACC: %85.35, LOSS: 35.75], G:[ACC: %4.69, LOSS: 299.88]\n",
      "E: 37, D:[ACC: %83.25, LOSS: 38.66], G:[ACC: %1.56, LOSS: 303.49]\n",
      "E: 38, D:[ACC: %85.94, LOSS: 32.93], G:[ACC: %0.78, LOSS: 334.09]\n",
      "E: 39, D:[ACC: %86.18, LOSS: 32.88], G:[ACC: %0.78, LOSS: 331.63]\n",
      "E: 40, D:[ACC: %86.91, LOSS: 30.85], G:[ACC: %2.34, LOSS: 346.51]\n",
      "E: 41, D:[ACC: %93.26, LOSS: 19.90], G:[ACC: %1.17, LOSS: 403.56]\n",
      "E: 42, D:[ACC: %84.23, LOSS: 35.15], G:[ACC: %2.73, LOSS: 370.90]\n",
      "E: 43, D:[ACC: %95.21, LOSS: 15.20], G:[ACC: %5.08, LOSS: 345.25]\n",
      "E: 44, D:[ACC: %92.97, LOSS: 19.42], G:[ACC: %3.12, LOSS: 352.15]\n",
      "E: 45, D:[ACC: %93.51, LOSS: 18.26], G:[ACC: %0.39, LOSS: 574.01]\n",
      "E: 46, D:[ACC: %64.16, LOSS: 99.35], G:[ACC: %8.20, LOSS: 186.98]\n",
      "E: 47, D:[ACC: %89.21, LOSS: 28.80], G:[ACC: %5.08, LOSS: 280.99]\n",
      "E: 48, D:[ACC: %91.80, LOSS: 23.29], G:[ACC: %3.12, LOSS: 303.66]\n",
      "E: 49, D:[ACC: %80.42, LOSS: 43.41], G:[ACC: %4.69, LOSS: 271.49]\n",
      "E: 50, D:[ACC: %87.40, LOSS: 32.27], G:[ACC: %6.25, LOSS: 287.34]\n",
      "E: 51, D:[ACC: %88.13, LOSS: 28.25], G:[ACC: %2.73, LOSS: 336.38]\n",
      "E: 52, D:[ACC: %71.48, LOSS: 62.48], G:[ACC: %15.62, LOSS: 193.20]\n",
      "E: 53, D:[ACC: %89.84, LOSS: 26.25], G:[ACC: %5.08, LOSS: 288.51]\n",
      "E: 54, D:[ACC: %89.36, LOSS: 27.29], G:[ACC: %1.95, LOSS: 324.93]\n",
      "E: 55, D:[ACC: %73.29, LOSS: 55.15], G:[ACC: %5.08, LOSS: 261.65]\n",
      "E: 56, D:[ACC: %80.42, LOSS: 41.29], G:[ACC: %3.52, LOSS: 267.99]\n",
      "E: 57, D:[ACC: %85.94, LOSS: 32.95], G:[ACC: %4.30, LOSS: 276.70]\n",
      "E: 58, D:[ACC: %85.94, LOSS: 34.02], G:[ACC: %1.95, LOSS: 316.62]\n",
      "E: 59, D:[ACC: %85.99, LOSS: 33.82], G:[ACC: %4.30, LOSS: 270.62]\n",
      "E: 60, D:[ACC: %74.56, LOSS: 52.93], G:[ACC: %5.86, LOSS: 302.09]\n",
      "E: 61, D:[ACC: %80.27, LOSS: 43.90], G:[ACC: %5.08, LOSS: 265.74]\n",
      "E: 62, D:[ACC: %76.56, LOSS: 51.33], G:[ACC: %1.95, LOSS: 305.25]\n",
      "E: 63, D:[ACC: %85.64, LOSS: 33.29], G:[ACC: %24.22, LOSS: 153.92]\n",
      "E: 64, D:[ACC: %66.89, LOSS: 77.76], G:[ACC: %10.55, LOSS: 196.27]\n",
      "E: 65, D:[ACC: %83.40, LOSS: 38.44], G:[ACC: %2.73, LOSS: 264.21]\n",
      "E: 66, D:[ACC: %85.99, LOSS: 33.19], G:[ACC: %3.12, LOSS: 271.80]\n",
      "E: 67, D:[ACC: %83.15, LOSS: 39.41], G:[ACC: %7.81, LOSS: 218.70]\n",
      "E: 68, D:[ACC: %80.76, LOSS: 44.52], G:[ACC: %3.12, LOSS: 256.23]\n",
      "E: 69, D:[ACC: %82.37, LOSS: 39.80], G:[ACC: %3.52, LOSS: 256.79]\n",
      "E: 70, D:[ACC: %89.21, LOSS: 29.16], G:[ACC: %0.39, LOSS: 346.50]\n",
      "E: 71, D:[ACC: %83.84, LOSS: 36.42], G:[ACC: %3.12, LOSS: 269.73]\n",
      "E: 72, D:[ACC: %85.25, LOSS: 35.80], G:[ACC: %1.95, LOSS: 314.61]\n",
      "E: 73, D:[ACC: %82.47, LOSS: 38.35], G:[ACC: %2.34, LOSS: 314.86]\n",
      "E: 74, D:[ACC: %72.66, LOSS: 56.26], G:[ACC: %12.89, LOSS: 193.87]\n",
      "E: 75, D:[ACC: %82.23, LOSS: 40.06], G:[ACC: %0.39, LOSS: 327.37]\n",
      "E: 76, D:[ACC: %88.28, LOSS: 29.12], G:[ACC: %1.56, LOSS: 333.19]\n",
      "E: 77, D:[ACC: %77.49, LOSS: 47.57], G:[ACC: %4.69, LOSS: 256.43]\n",
      "E: 78, D:[ACC: %85.55, LOSS: 33.42], G:[ACC: %1.95, LOSS: 271.45]\n",
      "E: 79, D:[ACC: %78.08, LOSS: 47.39], G:[ACC: %0.39, LOSS: 318.54]\n",
      "E: 80, D:[ACC: %80.08, LOSS: 43.96], G:[ACC: %7.42, LOSS: 241.12]\n",
      "E: 81, D:[ACC: %85.16, LOSS: 35.75], G:[ACC: %0.78, LOSS: 307.38]\n",
      "E: 82, D:[ACC: %82.81, LOSS: 39.39], G:[ACC: %3.12, LOSS: 296.11]\n",
      "E: 83, D:[ACC: %76.56, LOSS: 51.51], G:[ACC: %5.08, LOSS: 256.67]\n",
      "E: 84, D:[ACC: %77.93, LOSS: 47.67], G:[ACC: %3.12, LOSS: 248.34]\n",
      "E: 85, D:[ACC: %82.13, LOSS: 38.92], G:[ACC: %3.52, LOSS: 308.49]\n",
      "E: 86, D:[ACC: %73.58, LOSS: 56.70], G:[ACC: %7.81, LOSS: 214.71]\n",
      "E: 87, D:[ACC: %81.93, LOSS: 39.76], G:[ACC: %5.08, LOSS: 242.17]\n",
      "E: 88, D:[ACC: %81.40, LOSS: 42.34], G:[ACC: %9.38, LOSS: 218.39]\n",
      "E: 89, D:[ACC: %76.81, LOSS: 48.30], G:[ACC: %2.34, LOSS: 280.70]\n",
      "E: 90, D:[ACC: %78.17, LOSS: 44.83], G:[ACC: %12.11, LOSS: 182.63]\n",
      "E: 91, D:[ACC: %82.52, LOSS: 40.60], G:[ACC: %9.77, LOSS: 213.00]\n",
      "E: 92, D:[ACC: %84.33, LOSS: 36.64], G:[ACC: %13.67, LOSS: 216.39]\n",
      "E: 93, D:[ACC: %69.38, LOSS: 62.86], G:[ACC: %7.42, LOSS: 219.06]\n",
      "E: 94, D:[ACC: %80.32, LOSS: 43.52], G:[ACC: %2.73, LOSS: 261.00]\n",
      "E: 95, D:[ACC: %81.01, LOSS: 42.18], G:[ACC: %2.73, LOSS: 283.48]\n",
      "E: 96, D:[ACC: %89.31, LOSS: 28.89], G:[ACC: %12.89, LOSS: 216.88]\n",
      "E: 97, D:[ACC: %72.07, LOSS: 59.07], G:[ACC: %4.69, LOSS: 275.71]\n",
      "E: 98, D:[ACC: %78.42, LOSS: 47.73], G:[ACC: %2.73, LOSS: 271.18]\n",
      "E: 99, D:[ACC: %76.22, LOSS: 49.50], G:[ACC: %3.12, LOSS: 259.29]\n",
      "E: 100, D:[ACC: %78.22, LOSS: 46.17], G:[ACC: %16.80, LOSS: 187.23]\n",
      "E: 101, D:[ACC: %84.91, LOSS: 35.42], G:[ACC: %8.20, LOSS: 231.65]\n",
      "E: 102, D:[ACC: %76.37, LOSS: 49.01], G:[ACC: %5.47, LOSS: 225.56]\n",
      "E: 103, D:[ACC: %76.27, LOSS: 49.05], G:[ACC: %2.34, LOSS: 247.86]\n",
      "E: 104, D:[ACC: %80.71, LOSS: 42.53], G:[ACC: %3.52, LOSS: 234.34]\n",
      "E: 105, D:[ACC: %81.20, LOSS: 40.66], G:[ACC: %7.03, LOSS: 215.19]\n",
      "E: 106, D:[ACC: %79.59, LOSS: 44.82], G:[ACC: %5.47, LOSS: 226.15]\n",
      "E: 107, D:[ACC: %80.52, LOSS: 41.98], G:[ACC: %4.30, LOSS: 235.68]\n",
      "E: 108, D:[ACC: %75.59, LOSS: 50.94], G:[ACC: %15.62, LOSS: 206.55]\n",
      "E: 109, D:[ACC: %79.93, LOSS: 42.48], G:[ACC: %1.95, LOSS: 286.32]\n",
      "E: 110, D:[ACC: %72.02, LOSS: 55.70], G:[ACC: %3.52, LOSS: 261.27]\n",
      "E: 111, D:[ACC: %79.30, LOSS: 44.44], G:[ACC: %1.95, LOSS: 290.19]\n",
      "E: 112, D:[ACC: %78.86, LOSS: 45.93], G:[ACC: %5.47, LOSS: 257.51]\n",
      "E: 113, D:[ACC: %80.13, LOSS: 43.09], G:[ACC: %11.33, LOSS: 211.15]\n",
      "E: 114, D:[ACC: %82.13, LOSS: 40.59], G:[ACC: %3.12, LOSS: 238.02]\n",
      "E: 115, D:[ACC: %70.80, LOSS: 57.90], G:[ACC: %6.25, LOSS: 227.88]\n",
      "E: 116, D:[ACC: %74.22, LOSS: 52.78], G:[ACC: %3.52, LOSS: 259.26]\n",
      "E: 117, D:[ACC: %79.00, LOSS: 44.13], G:[ACC: %2.73, LOSS: 244.76]\n",
      "E: 118, D:[ACC: %78.91, LOSS: 43.96], G:[ACC: %7.42, LOSS: 221.30]\n",
      "E: 119, D:[ACC: %78.42, LOSS: 44.94], G:[ACC: %3.91, LOSS: 212.62]\n",
      "E: 120, D:[ACC: %81.84, LOSS: 40.79], G:[ACC: %4.69, LOSS: 217.05]\n",
      "E: 121, D:[ACC: %75.44, LOSS: 49.67], G:[ACC: %5.08, LOSS: 230.15]\n",
      "E: 122, D:[ACC: %78.52, LOSS: 47.08], G:[ACC: %3.52, LOSS: 229.64]\n",
      "E: 123, D:[ACC: %80.81, LOSS: 42.70], G:[ACC: %5.47, LOSS: 256.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 124, D:[ACC: %79.69, LOSS: 42.07], G:[ACC: %4.30, LOSS: 266.78]\n",
      "E: 125, D:[ACC: %82.62, LOSS: 40.16], G:[ACC: %7.03, LOSS: 250.36]\n",
      "E: 126, D:[ACC: %74.76, LOSS: 51.00], G:[ACC: %1.17, LOSS: 274.94]\n",
      "E: 127, D:[ACC: %80.22, LOSS: 43.27], G:[ACC: %7.42, LOSS: 216.89]\n",
      "E: 128, D:[ACC: %77.15, LOSS: 46.80], G:[ACC: %2.73, LOSS: 260.08]\n",
      "E: 129, D:[ACC: %77.78, LOSS: 46.07], G:[ACC: %5.08, LOSS: 258.60]\n",
      "E: 130, D:[ACC: %75.93, LOSS: 49.93], G:[ACC: %6.64, LOSS: 239.78]\n",
      "E: 131, D:[ACC: %74.71, LOSS: 52.03], G:[ACC: %2.73, LOSS: 267.85]\n",
      "E: 132, D:[ACC: %76.81, LOSS: 48.81], G:[ACC: %4.30, LOSS: 243.58]\n",
      "E: 133, D:[ACC: %82.71, LOSS: 38.88], G:[ACC: %3.91, LOSS: 277.99]\n",
      "E: 134, D:[ACC: %80.08, LOSS: 43.17], G:[ACC: %3.52, LOSS: 295.00]\n",
      "E: 135, D:[ACC: %75.73, LOSS: 50.13], G:[ACC: %10.94, LOSS: 205.32]\n",
      "E: 136, D:[ACC: %78.76, LOSS: 44.70], G:[ACC: %5.08, LOSS: 247.17]\n",
      "E: 137, D:[ACC: %80.81, LOSS: 42.38], G:[ACC: %5.86, LOSS: 256.16]\n",
      "E: 138, D:[ACC: %80.22, LOSS: 42.78], G:[ACC: %7.42, LOSS: 272.96]\n",
      "E: 139, D:[ACC: %68.26, LOSS: 63.21], G:[ACC: %14.06, LOSS: 185.17]\n",
      "E: 140, D:[ACC: %76.86, LOSS: 48.62], G:[ACC: %11.33, LOSS: 198.78]\n",
      "E: 141, D:[ACC: %78.81, LOSS: 45.37], G:[ACC: %6.25, LOSS: 236.31]\n",
      "E: 142, D:[ACC: %75.88, LOSS: 50.00], G:[ACC: %3.91, LOSS: 259.85]\n",
      "E: 143, D:[ACC: %79.49, LOSS: 44.00], G:[ACC: %10.55, LOSS: 212.85]\n",
      "E: 144, D:[ACC: %77.73, LOSS: 48.06], G:[ACC: %1.17, LOSS: 275.56]\n",
      "E: 145, D:[ACC: %79.54, LOSS: 44.47], G:[ACC: %4.69, LOSS: 235.77]\n",
      "E: 146, D:[ACC: %75.98, LOSS: 51.87], G:[ACC: %3.91, LOSS: 238.80]\n",
      "E: 147, D:[ACC: %79.20, LOSS: 43.61], G:[ACC: %6.25, LOSS: 226.78]\n",
      "E: 148, D:[ACC: %85.11, LOSS: 37.23], G:[ACC: %5.86, LOSS: 257.01]\n",
      "E: 149, D:[ACC: %77.44, LOSS: 46.14], G:[ACC: %8.98, LOSS: 211.90]\n",
      "E: 150, D:[ACC: %73.63, LOSS: 52.86], G:[ACC: %4.30, LOSS: 225.12]\n",
      "E: 151, D:[ACC: %84.13, LOSS: 37.13], G:[ACC: %4.30, LOSS: 268.17]\n",
      "E: 152, D:[ACC: %85.55, LOSS: 34.45], G:[ACC: %1.95, LOSS: 316.41]\n",
      "E: 153, D:[ACC: %84.28, LOSS: 35.90], G:[ACC: %4.69, LOSS: 305.08]\n",
      "E: 154, D:[ACC: %78.03, LOSS: 46.68], G:[ACC: %4.69, LOSS: 244.25]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "STEPS = 1  # 60000 // BATCH_SIZE\n",
    "\n",
    "\n",
    "train_loss_g = []\n",
    "train_loss_d = []\n",
    "\n",
    "train_acc_g = []\n",
    "train_acc_d = []\n",
    "\n",
    "\n",
    "disc_itr = load_batch()\n",
    "gen_itr = load_noise()\n",
    "\n",
    "\n",
    "# fixed test sample\n",
    "noise = np.random.normal(size=(age_len, noise_len,) )\n",
    "conditions = np.identity(age_len)\n",
    "\n",
    "\n",
    "# epochs\n",
    "for e in range(EPOCHS):\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS * 4):\n",
    "        \n",
    "        c2, x, z_fake, y_fake, z_real, y_real = next(disc_itr)\n",
    "    \n",
    "        # train\n",
    "        l1, acc_1, l2, acc_2, loss_1 = discriminator.train_on_batch([c2, z_real], [y_real, c2])\n",
    "        l3, acc_3, l4, acc_4, loss_2 = discriminator.train_on_batch([c2, z_fake], [y_fake, c2])\n",
    "\n",
    "        batch_loss = 0.5 * (loss_1 + loss_2)\n",
    "        batch_acc = 0.5 * (acc_1 + acc_3)\n",
    "\n",
    "        loss.append(batch_loss)\n",
    "        acc.append(batch_acc)\n",
    "\n",
    "    train_loss_d.append(np.mean(np.array(loss)))\n",
    "    train_acc_d.append(np.mean(np.array(acc)))\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "      c2, x, y_true = next(gen_itr)\n",
    "\n",
    "      # train\n",
    "      l1, acc_1, l2, acc_2, loss_1 = gan.train_on_batch([c2, x], [y_true, c2])\n",
    "\n",
    "      loss.append(loss_1)\n",
    "      acc.append(acc_1)\n",
    "\n",
    "    train_loss_g.append(np.mean(np.array(loss)))\n",
    "    train_acc_g.append(np.mean(np.array(acc)))\n",
    "\n",
    "\n",
    "    print(\"E: {}, D:[ACC: %{:.2f}, LOSS: {:.2f}], G:[ACC: %{:.2f}, LOSS: {:.2f}]\".format(\n",
    "          e,\n",
    "          train_acc_d[-1] * 100,\n",
    "          train_loss_d[-1] * 100,\n",
    "          train_acc_g[-1] * 100,\n",
    "          train_loss_g[-1] * 100\n",
    "      ))\n",
    "\n",
    "    if e % 25 == 0:\n",
    "        ## visualize results\n",
    "        synthesized = generator.predict([conditions, noise])\n",
    "        visualizeGAN(e, None, synthesized, conditions)\n",
    "        \n",
    "        ## save model\n",
    "        pth = os.path.join(models_path, 'gan.h5')\n",
    "        gan.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'generator-{}-{}-{}.h5'.format(e, train_loss_g[-1], train_acc_g[-1]))\n",
    "        generator.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'discriminator.h5')\n",
    "        discriminator.save(pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnlcqEI8i9uH"
   },
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LzhKde-CaDu"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_loss_g, label=\"Generator Loss\");\n",
    "plt.plot(train_loss_d, label=\"Discriminator Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9iCkvcai9uS"
   },
   "source": [
    "## Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YhSUa3fROSg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_acc_g, label=\"Generator Accuracy\");\n",
    "plt.plot(train_acc_d, label=\"Discriminator Accuracy\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1koOVNb_i9vD"
   },
   "outputs": [],
   "source": [
    "generator.save('./mnist-gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.save('./mnist-disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save('./mnist-gan.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST Test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
