{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "BIEdHLeqDLJH",
    "outputId": "bd25ca97-2443-4c65-d804-d9c0ff7b5586"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "root_path = './'\n",
    "dataset_path = os.path.join(root_path, 'tf_dataset')\n",
    "\n",
    "models_path = os.path.join(root_path, 'saved_models')\n",
    "if not os.path.exists(models_path):\n",
    "  os.mkdir(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XY64NlGCDdCr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "\n",
    "import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWYY-ez0D6wt"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "image_feature_description = {\n",
    "    'enc': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    'age': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "    'img': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True)\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "\n",
    "raw_train_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path,'train.tfrecords'))\n",
    "parsed_train_dataset = raw_train_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_val_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'val.tfrecords'))\n",
    "parsed_val_dataset = raw_val_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_test_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'test.tfrecords'))\n",
    "parsed_test_dataset = raw_test_dataset.map(_parse_image_function)\n",
    "\n",
    "\n",
    "parsed_train_dataset = parsed_train_dataset.repeat()\n",
    "parsed_train_dataset = parsed_train_dataset.shuffle(1000)\n",
    "parsed_train_dataset = parsed_train_dataset.batch(BATCH_SIZE)\n",
    "dataset_iterator = parsed_train_dataset.make_one_shot_iterator()\n",
    "\n",
    "variable_dataset = dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAuHCfjlFBOy"
   },
   "outputs": [],
   "source": [
    "enc_len = 128\n",
    "age_len = 8\n",
    "img_shape = (32, 32, 3)\n",
    "width, height, depth = (32, 32, 3)\n",
    "img_len = np.prod(img_shape)\n",
    "latent_dim = enc_len + age_len + img_len\n",
    "noise_len = 100  # 32 x 32 x 3\n",
    "input_dim = enc_len + age_len + noise_len\n",
    "cond_len = enc_len + age_len\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(144, input_shape=(latent_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((12, 12, 1)),\n",
    "        \n",
    "        # conv block 1\n",
    "        keras.layers.Conv2D(filters=8, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # conv block 2\n",
    "        keras.layers.Conv2D(filters=4, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "#         # conv block 3\n",
    "#         keras.layers.Conv2D(filters=2, kernel_size=(3, 3), padding='same'),\n",
    "#         keras.layers.Activation(tf.nn.relu),\n",
    "#         keras.layers.MaxPooling2D(),\n",
    "#         keras.layers.Dropout(0.2),\n",
    "        \n",
    "#         # conv block 4\n",
    "#         keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding='same'),\n",
    "#         keras.layers.Activation(tf.nn.relu),\n",
    "#         keras.layers.MaxPooling2D(),\n",
    "#         keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # flatten\n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        # dense 2\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Dense(1),\n",
    "        keras.layers.Activation(tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # image\n",
    "    z = keras.layers.Input(shape=img_shape)\n",
    "    \n",
    "    # flatten image\n",
    "    z_flat = keras.layers.Flatten()(z)\n",
    "    \n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, z_flat])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, z], outputs)\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    model = keras.Sequential([\n",
    "        \n",
    "        # dense 1\n",
    "        keras.layers.Dense(144, input_shape=(input_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((12, 12, 1)),\n",
    "        \n",
    "        # transpose conv block 1\n",
    "        keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # transpose conv block 2\n",
    "        keras.layers.Conv2DTranspose(filters=2, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # transpose conv block 3\n",
    "        keras.layers.Conv2DTranspose(filters=2, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # transpose conv block 4\n",
    "        keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # flatten\n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        # dense 3\n",
    "        keras.layers.Dense(3072),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((width, height, depth)),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Activation(tf.nn.tanh),\n",
    "    ])\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # noise\n",
    "    x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, x])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, x], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoYXZ0kE46LH"
   },
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfo8J8jQ4-FH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 236)          0           input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 32, 32, 3)    113283495   concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 113,283,495\n",
      "Trainable params: 113,283,495\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObTb7HIf5CqA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 3072)         0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3208)         0           input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 1)            464901      concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 464,901\n",
      "Trainable params: 464,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHTmYpPeImn5"
   },
   "outputs": [],
   "source": [
    "GLR = 0.02  # generator\n",
    "DLR = 0.001  # discriminator\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=DLR),\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# condition\n",
    "c1 = keras.layers.Input(shape=(enc_len,))\n",
    "c2 = keras.layers.Input(shape=(age_len,))\n",
    "\n",
    "# noise\n",
    "x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "# freeze discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# output\n",
    "z = generator([c1, c2, x])\n",
    "out = discriminator([c1, c2, z])\n",
    "\n",
    "# GAN\n",
    "gan = keras.models.Model(inputs=[c1, c2, x], outputs=out)\n",
    "\n",
    "gan.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=GLR),\n",
    "    loss=keras.losses.kullback_leibler_divergence,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mmrborLIvNK"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  values = sess.run([variable_dataset])\n",
    "  print(values)\n",
    "  print(values[0]['age'], values[0]['enc'])\n",
    "  print(tf.io.decode_raw(values[0]['img'], tf.uint8).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZNLvw1uCEiz"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  for i in range(4000//16):\n",
    "    values = sess.run([variable_dataset])\n",
    "    print(values[0]['age'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RK7vMyQWLp1V"
   },
   "outputs": [],
   "source": [
    "parsed_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "iSszxe2oKY02",
    "outputId": "ee5ce939-c513-4c70-9983-ae17faca6d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "EPOCHS = 10000\n",
    "STEPS = 1024 // BATCH_SIZE\n",
    "\n",
    "\n",
    "train_loss_g = []\n",
    "val_loss_g = []\n",
    "\n",
    "train_loss_d = []\n",
    "val_loss_d = []\n",
    "\n",
    "\n",
    "train_acc_g = []\n",
    "val_acc_g = []\n",
    "\n",
    "train_acc_d = []\n",
    "val_acc_d = []\n",
    "\n",
    "\n",
    "y_fake = tf.zeros((BATCH_SIZE,))\n",
    "y_true = tf.ones((BATCH_SIZE,))\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "  K.set_session(sess)\n",
    "  \n",
    "  tf.initialize_all_variables().run()\n",
    "\n",
    "  # epochs\n",
    "  for e in range(EPOCHS):\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "      values = sess.run([variable_dataset])\n",
    "      row = values[0]\n",
    "\n",
    "      sz = row['img'].shape[0]\n",
    "\n",
    "#       if sz != BATCH_SIZE:\n",
    "#         continue\n",
    "\n",
    "      # train discriminator\n",
    "\n",
    "      # fake data\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      x = tf.random.normal((sz, noise_len,)).eval()\n",
    "      z_fake = generator.predict([c1, c2, x])\n",
    "\n",
    "      # real data\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      z_real = tf.reshape(tf.io.decode_raw(row['img'], tf.uint8), (-1, width, height, depth)).eval()\n",
    "\n",
    "      # train\n",
    "      loss_1, acc_1 = discriminator.train_on_batch([c1, c2, z_fake], y_fake.eval())\n",
    "      loss_2, acc_2 = discriminator.train_on_batch([c1, c2, z_real], y_true.eval())\n",
    "\n",
    "      batch_loss = 0.5 * (float(tf.reduce_mean(loss_1).eval()) + float(tf.reduce_mean(loss_2).eval()))\n",
    "      batch_acc = 0.5 * (float(tf.reduce_mean(acc_1).eval()) + float(tf.reduce_mean(acc_2).eval()))\n",
    "\n",
    "      loss.append(batch_loss)\n",
    "      acc.append(batch_acc)\n",
    "\n",
    "    train_loss_d.append(np.mean(np.array(loss)))\n",
    "    train_acc_d.append(np.mean(np.array(acc)))\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "      values = sess.run([variable_dataset])\n",
    "      row = values[0]\n",
    "\n",
    "      sz = row['img'].shape[0]\n",
    "\n",
    "#       if sz != BATCH_SIZE:\n",
    "#         continue\n",
    "\n",
    "      # train generator\n",
    "\n",
    "      # concatenate face + age + noise\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      x = tf.random.normal((sz, noise_len,)).eval()\n",
    "\n",
    "      # train\n",
    "      loss_1, acc_1 = gan.train_on_batch([c1, c2, x], y_true.eval())\n",
    "\n",
    "      batch_loss = float(tf.reduce_mean(loss_1).eval())\n",
    "      batch_acc = float(tf.reduce_mean(acc_1).eval())\n",
    "\n",
    "      loss.append(batch_loss)\n",
    "      acc.append(batch_acc)\n",
    "\n",
    "    train_loss_g.append(np.mean(np.array(loss)))\n",
    "    train_acc_g.append(np.mean(np.array(acc)))\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, Steps: {}, Discriminator Loss: {:.3f}, Discriminator Accuracy: %{:.2f}, GAN Loss: {:.3f}, GAN Accuracy: %{:.2f}\".format(\n",
    "          e,\n",
    "          STEPS,\n",
    "          train_loss_d[-1],\n",
    "          train_loss_g[-1],\n",
    "          train_acc_d[-1],\n",
    "          train_acc_g[-1]\n",
    "      ))\n",
    " \n",
    "    if e % 100 == 1:\n",
    "\n",
    "      pth = os.path.join(models_path, 'gan.h5')\n",
    "      gan.save(pth)\n",
    "\n",
    "      pth = os.path.join(models_path, 'generator-{}-{}-{}.h5'.format(e, train_loss_g[-1], train_acc_g[-1]))\n",
    "      generator.save(pth)\n",
    "\n",
    "      pth = os.path.join(models_path, 'discriminator.h5')\n",
    "      discriminator.save(pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0Uxu-RaTBiI"
   },
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRFK2jHCpfpK"
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKLt5f22piWS"
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LzhKde-CaDu"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_g, label=\"Generator Loss\");\n",
    "plt.plot(train_loss_d, label=\"Discriminator Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YhSUa3fROSg"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_acc_g, label=\"Generator Accuracy\");\n",
    "plt.plot(train_acc_d, label=\"Discriminator Accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E93kpBKFC84Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Standalone Keras AGE-CGAN",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
