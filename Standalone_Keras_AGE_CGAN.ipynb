{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "BIEdHLeqDLJH",
    "outputId": "bd25ca97-2443-4c65-d804-d9c0ff7b5586"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "root_path = './'\n",
    "dataset_path = os.path.join(root_path, 'tf_dataset')\n",
    "\n",
    "models_path = os.path.join(root_path, 'saved_models')\n",
    "if not os.path.exists(models_path):\n",
    "  os.mkdir(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XY64NlGCDdCr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "\n",
    "import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWYY-ez0D6wt"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "\n",
    "image_feature_description = {\n",
    "    'enc': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    'age': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "    'img': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True)\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "\n",
    "raw_train_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path,'train.tfrecords'))\n",
    "parsed_train_dataset = raw_train_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_val_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'val.tfrecords'))\n",
    "parsed_val_dataset = raw_val_dataset.map(_parse_image_function)\n",
    "\n",
    "raw_test_dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, 'test.tfrecords'))\n",
    "parsed_test_dataset = raw_test_dataset.map(_parse_image_function)\n",
    "\n",
    "\n",
    "parsed_train_dataset = parsed_train_dataset.repeat()\n",
    "parsed_train_dataset = parsed_train_dataset.shuffle(1000)\n",
    "parsed_train_dataset = parsed_train_dataset.batch(BATCH_SIZE)\n",
    "dataset_iterator = parsed_train_dataset.make_one_shot_iterator()\n",
    "\n",
    "variable_dataset = dataset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAuHCfjlFBOy"
   },
   "outputs": [],
   "source": [
    "enc_len = 128\n",
    "age_len = 8\n",
    "img_shape = (32, 32, 3)\n",
    "width, height, depth = (32, 32, 3)\n",
    "img_len = np.prod(img_shape)\n",
    "latent_dim = enc_len + age_len + img_len\n",
    "noise_len = 100  # 32 x 32 x 3\n",
    "input_dim = enc_len + age_len + noise_len\n",
    "cond_len = enc_len + age_len\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(144, input_shape=(latent_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((12, 12, 1)),\n",
    "        \n",
    "        # conv block 1\n",
    "        keras.layers.Conv2D(filters=8, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # conv block 2\n",
    "        keras.layers.Conv2D(filters=4, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "#         # conv block 3\n",
    "#         keras.layers.Conv2D(filters=2, kernel_size=(3, 3), padding='same'),\n",
    "#         keras.layers.Activation(tf.nn.relu),\n",
    "#         keras.layers.MaxPooling2D(),\n",
    "#         keras.layers.Dropout(0.2),\n",
    "        \n",
    "#         # conv block 4\n",
    "#         keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding='same'),\n",
    "#         keras.layers.Activation(tf.nn.relu),\n",
    "#         keras.layers.MaxPooling2D(),\n",
    "#         keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # flatten\n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        # dense 2\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Dense(1),\n",
    "        keras.layers.Activation(tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # image\n",
    "    z = keras.layers.Input(shape=img_shape)\n",
    "    \n",
    "    # flatten image\n",
    "    z_flat = keras.layers.Flatten()(z)\n",
    "    \n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, z_flat])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, z], outputs)\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    model = keras.Sequential([\n",
    "        \n",
    "        # dense 1\n",
    "        keras.layers.Dense(144, input_shape=(input_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((12, 12, 1)),\n",
    "        \n",
    "        # transpose conv block 1\n",
    "        keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # transpose conv block 2\n",
    "        keras.layers.Conv2DTranspose(filters=2, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # transpose conv block 3\n",
    "        keras.layers.Conv2DTranspose(filters=2, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # transpose conv block 4\n",
    "        keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), padding='same'),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.UpSampling2D(size=(2,2)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # flatten\n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        # dense 3\n",
    "        keras.layers.Dense(3072),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((width, height, depth)),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Activation(tf.nn.tanh),\n",
    "    ])\n",
    "    \n",
    "    # condition\n",
    "    c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # noise\n",
    "    x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c1, c2, x])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    return keras.models.Model([c1, c2, x], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoYXZ0kE46LH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator()\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfo8J8jQ4-FH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 236)          0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 32, 32, 3)    113283495   concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 113,283,495\n",
      "Trainable params: 113,283,495\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObTb7HIf5CqA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3072)         0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3208)         0           input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1)            464901      concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 464,901\n",
      "Trainable params: 464,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHTmYpPeImn5"
   },
   "outputs": [],
   "source": [
    "GLR = 0.02  # generator\n",
    "DLR = 0.001  # discriminator\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=DLR),\n",
    "    loss=keras.losses.kullback_leibler_divergence,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# condition\n",
    "c1 = keras.layers.Input(shape=(enc_len,))\n",
    "c2 = keras.layers.Input(shape=(age_len,))\n",
    "\n",
    "# noise\n",
    "x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "# freeze discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# output\n",
    "z = generator([c1, c2, x])\n",
    "out = discriminator([c1, c2, z])\n",
    "\n",
    "# GAN\n",
    "gan = keras.models.Model(inputs=[c1, c2, x], outputs=out)\n",
    "\n",
    "gan.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=GLR),\n",
    "    loss=keras.losses.kullback_leibler_divergence,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mmrborLIvNK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': array([[0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0]]), 'enc': array([[-7.26971477e-02,  7.17800707e-02,  8.82160813e-02,\n",
      "        -8.18104669e-02, -7.90959448e-02, -5.96554875e-02,\n",
      "        -2.41319612e-02, -1.20586231e-01,  1.17698476e-01,\n",
      "        -1.59430653e-01,  1.57633767e-01, -1.00669883e-01,\n",
      "        -2.30072364e-01, -3.09263729e-02, -2.00881660e-02,\n",
      "         1.83538437e-01, -1.32000074e-01, -1.60702944e-01,\n",
      "        -1.22243211e-01,  1.83078274e-02,  3.06281596e-02,\n",
      "         2.03765929e-02, -5.43838963e-02,  6.30166978e-02,\n",
      "        -5.66880330e-02, -3.32251608e-01, -6.35823607e-02,\n",
      "        -8.61983448e-02, -6.09786436e-03,  1.14731193e-02,\n",
      "        -2.87986174e-02,  9.69129801e-02, -1.35701567e-01,\n",
      "        -4.09994163e-02,  4.61715423e-02,  1.07372642e-01,\n",
      "        -1.41959414e-02, -4.57401611e-02,  1.54507264e-01,\n",
      "        -2.95228809e-02, -2.85151005e-01,  7.09810108e-03,\n",
      "         3.91827039e-02,  1.83032677e-01,  2.25876540e-01,\n",
      "         5.88971376e-03, -7.08885491e-05, -8.97776335e-02,\n",
      "         1.13409370e-01, -2.26962954e-01, -1.08883604e-02,\n",
      "         1.13701589e-01,  4.84988913e-02,  1.19410828e-01,\n",
      "         3.29821408e-02, -1.88890114e-01,  7.18694478e-02,\n",
      "         1.14416197e-01, -1.76597565e-01,  3.64786014e-02,\n",
      "         5.57531193e-02, -1.99351102e-01,  8.93849880e-03,\n",
      "        -2.13563517e-02,  1.74919575e-01,  3.74053940e-02,\n",
      "        -1.14723727e-01, -1.74007595e-01,  1.53633580e-01,\n",
      "        -1.99423224e-01, -3.48711014e-02,  7.96156079e-02,\n",
      "        -1.45276368e-01, -1.40694186e-01, -2.85895914e-01,\n",
      "         1.63437687e-02,  4.30251837e-01,  1.61385804e-01,\n",
      "        -1.84508711e-01,  3.12087461e-02, -4.43348587e-02,\n",
      "        -3.60095128e-03,  1.44614965e-01,  1.32397652e-01,\n",
      "         3.82683501e-02, -7.07805678e-02, -7.23956153e-02,\n",
      "        -4.82146181e-02,  2.10255384e-01, -3.33046392e-02,\n",
      "        -3.77594866e-02,  2.10545316e-01, -4.37849164e-02,\n",
      "         6.91870898e-02,  1.15665793e-02,  3.29596549e-03,\n",
      "        -5.60821891e-02,  1.11066885e-02, -1.08072057e-01,\n",
      "         8.29026103e-05, -2.10090727e-02, -7.38006160e-02,\n",
      "        -1.58846490e-02,  9.98622701e-02, -1.19769290e-01,\n",
      "         1.26130611e-01, -2.27687582e-02,  7.52520487e-02,\n",
      "         1.55174956e-02,  5.13489917e-02, -8.18506181e-02,\n",
      "        -6.46104217e-02,  1.70246050e-01, -1.74658179e-01,\n",
      "         2.13551939e-01,  2.08811507e-01,  5.62272035e-02,\n",
      "         9.89365876e-02,  1.11065663e-01,  7.41437599e-02,\n",
      "         1.78347975e-02, -2.61698812e-02, -2.03776121e-01,\n",
      "        -4.68263328e-02,  9.67028514e-02, -1.24127418e-02,\n",
      "         6.38042390e-02,  1.43445618e-02],\n",
      "       [-1.26587972e-01,  9.64991748e-02,  1.02703266e-01,\n",
      "         7.12972879e-03, -5.33298925e-02, -7.25868046e-02,\n",
      "         2.67152488e-03, -3.05299312e-02,  1.60250992e-01,\n",
      "        -3.48758548e-02,  2.46299475e-01, -9.16556269e-02,\n",
      "        -2.61510968e-01, -9.42409337e-02, -3.94430757e-02,\n",
      "         1.56390786e-01, -6.29829019e-02, -2.43633986e-05,\n",
      "        -1.02966607e-01, -2.03769058e-02,  5.89410216e-02,\n",
      "         7.76666105e-02,  7.14259669e-02,  6.14314824e-02,\n",
      "         1.44526362e-03, -3.70976448e-01, -8.50881338e-02,\n",
      "        -4.21651378e-02,  5.86954355e-02, -1.51490420e-01,\n",
      "        -5.91759831e-02,  9.53996927e-03, -1.41285762e-01,\n",
      "        -1.67296737e-01,  4.43121716e-02,  7.50152841e-02,\n",
      "        -2.58777831e-02, -4.65221182e-02,  1.31161079e-01,\n",
      "         1.81507096e-02, -2.10310817e-01, -2.24281326e-02,\n",
      "         4.93792817e-02,  3.01713765e-01,  1.63349003e-01,\n",
      "         9.46536064e-02, -2.75075100e-02, -1.56595975e-01,\n",
      "         1.08540773e-01, -1.92164153e-01,  1.01059929e-01,\n",
      "         6.77084625e-02,  1.41564727e-01,  5.72132990e-02,\n",
      "         1.11057326e-01, -1.31475538e-01,  2.44492181e-02,\n",
      "         1.48369491e-01, -2.67813325e-01,  3.66850458e-02,\n",
      "         4.63688225e-02,  4.48601693e-03, -2.41849627e-02,\n",
      "        -1.65432952e-02,  1.63521215e-01,  1.22736700e-01,\n",
      "        -1.24190673e-01, -1.40435159e-01,  1.35693312e-01,\n",
      "        -1.69918969e-01,  1.20929703e-02,  1.35290086e-01,\n",
      "        -5.63103631e-02, -1.94671690e-01, -2.88947225e-01,\n",
      "         4.82168868e-02,  3.80012393e-01,  1.12327531e-01,\n",
      "        -2.37790465e-01, -7.38041177e-02, -3.16452719e-02,\n",
      "        -2.73724608e-02,  1.16088018e-01,  1.36442959e-01,\n",
      "        -7.28247091e-02,  1.75040700e-02, -6.81768507e-02,\n",
      "        -1.29884053e-02,  7.66297057e-02, -1.07802525e-02,\n",
      "        -7.85271376e-02,  2.26932049e-01,  4.21671867e-02,\n",
      "         8.33623111e-03,  6.44549578e-02,  1.10926218e-01,\n",
      "        -1.28148705e-01,  1.85931548e-02, -1.83352724e-01,\n",
      "        -8.01551789e-02,  9.52119678e-02, -6.31243512e-02,\n",
      "         7.05607235e-04,  6.28352091e-02, -1.77664027e-01,\n",
      "         1.76978320e-01,  3.86002772e-02, -3.14575434e-02,\n",
      "         3.78054678e-02, -3.39742079e-02, -5.66105247e-02,\n",
      "        -1.35806203e-02,  1.25541583e-01, -2.73060530e-01,\n",
      "         2.02197164e-01,  1.43527418e-01,  1.48550104e-02,\n",
      "         1.52237833e-01,  2.54294723e-02,  7.71425813e-02,\n",
      "         5.46981022e-02, -7.97674879e-02, -5.62265515e-02,\n",
      "        -6.39269501e-02,  6.22794926e-02, -4.22194600e-02,\n",
      "         8.29135701e-02, -3.27710025e-02]], dtype=float32), 'img': array([[b'vUKiRBkUImVPq[UiUNcPDZIAO@P@2@?1;@28A46E87?0.E./H//A)(?)(=--7,.5*,8(*:*,=-/A15B27>-4E15U@>eRLiZQtLBgP@mWIoZPgSMXF@Q@:A20=0A7+93\\'25*25+-6,,;./<*->**E1.B/-:+,4)/5)05&)/\\x1f$0 %9)05&-0!(8&+D00O<8jYQnI<cK>^G;U@7I60B10C46>057+3/#*+\\x1f%, $,!#.#$-!\"*\\x1c\\x1f8)\\'D3,=-&9,+;181&/6\\'/>/6:+09*/<-07(+<+-D11VB?hSO_H5Z@6U=4K6/;)\\'9),.!*(\\x1b$%\\x18\\x16$\\x17\\x16$\\x17\\x17$\\x16\\x16-  )\\x1c\\x1c5)*-#%(\\x1c\\x172$\\x1b<.$;/+<276,63&06)1/\"\\')\\x1d\\x1d3(&7,\\'5\\'$E33YEC]HGjO>V;4O5/L2.D..:\\',2\"+/\"*2*%-#\\x1d\\'\\x1c\\x15.!\\x1c4$$%\\x13\\x197$,0\\x1d%!\\x0e\\x10*\\x17\\x13-\\x1b\\x141\\x1f\\x1b1\\x1f\\x1f-\\x1b\\x1c1\\x1b\\x1a1\\x1b\\x1b3\\x1d\\x1e*\\x17\\x19(\\x19\\x1b3(*5*(;,,M9?YCIoQ@Y?5M2): \\x1a5\\x1d\\x199$$5\"%3\"(5%+/\\x1f\\x1f.\\x1c\\x165!\\x17(\\x11\\t#\\n\\x04/\\x13\\x0f8\\x17\\x14C\"\\x1bL, S3&N.!N-$O-\"T/ \\\\6+[6-Q.*< \\x1d7!\\x1f-\\x1c\\x17<+*I5=R=D\\x85gUaG6?%\\x15<%\\x17L5*K5,C-%>%#;\\x1b(7\\x16\\x1c9\\x17\\x13;\\x18\\n@\\x1b\\x08E\\x1e\\x08S)\\x12j9!tC)xG+yH-xG0\\x81O<\\x8aWB\\x95`G\\x95`J\\x9cfT\\x94cS\\x87[NfA48\\x1c\\x13)\\x15\\x130\\x19\\x1eI34\\x8bk[pVA_G4T=-K4&K1#?#\\x13I(\\x1a[/,e83g8/f5(j7(o:)u?*\\x8aT6\\x90Z;\\x8fY8\\x89S5\\x8dU=\\x90XE\\x90XD\\x96^E\\x9dcN\\xa1hV\\xa7qb\\xae~q\\x9etgeD<1\\x19\\x19;\"%M62\\x82^QsXFaH9D.!?\\'\\x1b8\\x1a\\rQ-\\x1akB,yL2~O;~K=}F@z?=\\x82EF\\x8aPJ\\x95cM\\x98fN\\x89X>\\x86U=\\x84Q?\\x8e[N\\x93_R\\x97dR\\x9ej\\\\\\xa6rg\\x99h`\\x8ed^\\x9dxsbFC/\\x19\\x1c7\\x1f\"J3,\\x8daXqTJ`F??\\'$3\\x19\\x16I(\\x1frG8\\x8c]H\\x88^E\\x88[I~NE}IG\\x83KM\\x82IK~EDyF<\\x7fM?\\x96cR\\x8e\\\\K}J<b/#^, i7*n;1s@:zKGvMK\\x95rpL34&\\x14\\x1b6 &K4-\\x8e]YgIFN445\\x1d\"M25Y52\\x85TIt@3S,\\'N%#O#%e67~NI~LAuA6\\x82HD\\x80G<\\x8cTE\\x93[I\\x7fG6m5&t<-zC3\\x82J=\\x85LDyD>k<8h@<?%(\\'\\x19#3!\\'>)#\\x9ad`dEEG274#)N31\\\\4)o@3m;2\\x7fJDzHAvG=\\x80NC\\x8eXJ\\x85I9\\x96WF\\xb0o`\\x90PA\\x94TE\\x9c^M\\x96YE\\x8cP8\\x8aM5\\x8eM9\\x94SC\\x90QE\\x85I@yB8\\x81NCqA>G!+<\"*<(%\\xb9\\x84\\x81V::E39+\\x1d\"9\\x1d\\x18c7*_-\\x1f{G=\\x93YN\\x86PB\\x80L;\\x8bWD\\xa0gT\\x94UC\\xb7ub\\xbf\\x7fg\\xb2q]\\x99XF\\xabkW\\xadoW\\xa8kN\\xa6gJ\\xa6cJ\\xa1^K\\x96UF\\x98[O\\xabqd\\xb1yi\\x93\\\\T[-2A&+B/-\\xc2\\x91\\x8dS>;2&*\"\\x15\\x19;\\x1e\\x18~M?\\x91WJ\\x8cQE\\x95[H\\x95]I\\x9beN\\xa0iR\\x9feM\\xafq[\\xc8\\x88o\\xc7\\x87k\\xc6\\x86l\\xa7gO\\x9f_F\\xa0`D\\xa0a?\\x9e^<\\x9d[=\\x9d[C\\xadlY\\xbb}l\\xc3\\x88v\\xbf\\x86r\\xa2j[i=8J//C0-\\xa7|wSB?&\\x1c \\x1b\\x10\\x13? \\x19\\x9fk\\\\\\xc7\\x88y\\xb3rd\\xa2eL\\x99]C\\xa0eJ\\xaanT\\xabnT\\xc7\\x89o\\xcd\\x8ft\\xcb\\x8dn\\xd1\\x91v\\xc1\\x81f\\xb3qW\\xabiL\\xabiH\\xaahD\\xb1qO\\xb8w[\\xbd|e\\xc3\\x84p\\xca\\x8dx\\xc8\\x8bu\\xa1hSh=0K1,;)&}WR?-,)\\x1e\"\\x1c\\x0e\\x11<\\x1b\\x14\\xadwf\\xd7\\x96\\x84\\xd1\\x8e}\\xbb{_\\xabkO\\xa9hM\\xa6eK\\xb2sY\\xcc\\x8fu\\xc4\\x88m\\xc2\\x85k\\xd5\\x95~\\xd0\\x8ey\\xb9va\\xa5`G\\xb8rV\\xbf{Z\\xc1\\x81_\\xc3\\x82f\\xc5\\x84m\\xc9\\x88s\\xd1\\x90|\\xc6\\x86p\\x9ccKe;*D+%@-+U3-2\\x1b\\x1b*\\x1c! \\x11\\x14;\\x1a\\x11\\xa8r_\\xcd\\x8dx\\xd4\\x94\\x80\\xd0\\x8er\\xc6\\x82g\\xbfx_\\xb1kT\\xb8v`\\xb2u^\\xa8mW\\xadn^\\xafna\\xb4oe\\xca\\x83y\\xa4[M\\xa5YH\\xbbt[\\xc1\\x80`\\xc2\\x80f\\xc8\\x85q\\xd1\\x8e~\\xcf\\x8c{\\xbbxe\\x8fS=V+\\x1a8\\x1f\\x1aF22W608\\x1d .\\x1d#%\\x14\\x177\\x16\\x0e\\x9ciS\\xc2\\x85m\\xc9\\x8bu\\xcb\\x88m\\xc6\\x7ff\\xb8nX\\xaddP\\xa5bN\\x83F2\\x87L:\\x8eOF};5g\"\\x1f\\x9cSQ\\xa1UP\\x98IA\\xabbP\\xb7xZ\\xbd{c\\xc4\\x81o\\xcb\\x87y\\xc4~q\\xb6qb\\x92UB\\\\2\"T:7J78\\x7f\\\\Y3%\\'\\'\\x1a\\x18)\\x15\\x12.\\r\\x0c\\x8e\\\\T\\xb7x^\\xc6\\x82[\\xc5z\\\\\\xbasX\\xa6bN\\x9f^L\\x9bXGs/\\x1dz6\\'};7\\x89E?\\x92KD\\x9cRG\\xa6XJ\\xa2SA\\xa5Z?\\xaekD\\xb6tQ\\xb9y[\\xbd|c\\xb9w_\\xacfQ\\x81F3c;,cD:I1){YW2%%#\\x16\\x10+\\x18\\x12*\\x0b\\x0b}MH\\xb4w]\\xbcxO\\xb9qP\\xb2mR\\xa2`K\\xa4cR\\xb9vf\\xb3l\\\\\\xaeeV\\xa8_U\\xaddX\\xb9ob\\xc0wf\\xbcs`\\xb2iS\\xa5^B\\xa6b?\\xa9hF\\xabkL\\xadmP\\xadlQ\\x98V<j3\\x1dU.\\x1fM-!@&\\x1d\\x87hg>.,4&\\x1e.\\x1c\\x15)\\r\\x0c_4/\\xa9pW\\xb0oI\\xabkG\\xa7gI\\xa1aH\\xb2p^\\xc1}m\\xc8\\x7fr\\xbepb\\xb9fU\\xb7gT\\xc4xd\\xc5~h\\xbcyb\\xb5t]\\xaajQ\\xa2`E\\xa1^C\\xa2`C\\x9f^A\\x9a[>\\x81F(`/\\x17P,\\x1bC#\\x16D)!\\x83heF1,<,!6&\\x1d)\\x12\\x0fG!\\x1d\\x98bM\\xa6hD\\xa4fB\\xa2cB\\xa7fK\\xb7t`\\xbdxi\\xb2ja\\x98L?\\x9fK3\\x94C,\\x99M6\\xa9dM\\xb8zd\\xb1xa\\xa4kU\\xa4eO\\xa0^F\\xa4_D\\x9d[=\\x8dQ3r? Y0\\x16L+\\x1aL- S7/\\x8bwpM2*@- 1#\\x18#\\x10\\r1\\x10\\x0c\\x83Q>\\x9fdC\\xa2d@\\xa2c@\\xa9gJ\\xadkS\\x9f\\\\Lz9/q-\"\\x804\\x1e\\x807\"s.\\x1ap0\\x1d}A/\\x90XG\\x96_N\\xa2hU\\xa3aJ\\xa6^D\\x9fZ>\\x88O3e:\\x1fS1\\x18S5!X;-I,&\\x8b|n[<2?*\\x1b7,\\x1e*\\x1b\\x17%\\x08\\x05h9)\\x9baB\\xa0_<\\xa5a?\\xa9dE\\xa0]D|>,\\\\$\\x1bq91\\x99\\\\M\\x8fSE|?2`$\\x19X\\x1d\\x12T\\x1a\\x11xA3\\x9cfQ\\xa5dL\\xa6\\\\B\\x9bU;~G/W1\\x1cN2\\x1cZ?*^A3O0,\\x83wftSHF1 4*\\x1b9,(*\\x0f\\x0cP\"\\x13\\x92X;\\xa3^<\\xacfD\\xb0iI\\x9aW=c(\\x16<\\n\\x03>\\x10\\x0b\\x90_W\\x8f]UD\\x0f\\nI\\x10\\nJ\\x0e\\nM\\x10\\x0e\\x7fF;\\xa0mT\\xa7fL\\xa8]C\\x99R9u>*U2#Q9%^E/\\\\@1]?:ulY\\x9d\\x85}R?56%\\x1a=(\\x1dA\"\\x17@\\x14\\x08u@.\\x9f\\\\8\\xa9f@\\xaekH\\xaciM\\x96UCp0*{GA\\xb5\\x94\\x83\\xc9\\x9a\\x8e\\x85G?\\x93KE\\x9eUK\\xa7`S\\xaelX\\xafoS\\xacgL\\xa3ZB\\x8bJ7f3\\'a>8]A;cJAYC<o]We\\\\J\\xaf\\x97\\x8b}h[4!\\x14>\\'\\x1bG)\\x1fH\"\\x19X)\\x1d\\x87M/\\x9dcE\\xa5jL\\xa8mT\\xb2xe\\xb0vk\\xb4\\x82x\\xc4\\x9f\\x90\\xce\\x9e\\x91\\xa2cX\\x9eVK\\xb7n_\\xb1kW\\xafnT\\xablK\\xa2`A\\x94Q8u9&i:/jHC`D>jPGhRKgVRVL<\\x9e\\x83v\\xaa\\x90\\x83X>1C)\\x1d?#\\x19?!\\x1aA\\x1e\\x16a3 \\x94fQ\\xbb\\x8fx\\xaf\\x82j\\xa9ze\\xb1\\x80o\\xb9\\x8a|\\xda\\xae\\xa2\\xe8\\xb4\\xa6\\xa2bS\\x90J7\\x9fW@\\xabfL\\xaajJ\\x9eb<\\x93X6\\x80G,h6#oG=dDAbFAnSIs]U>/+LA5\\xa0\\x83v\\xcd\\xae\\xa0\\x9d|mT3\\'> \\x177\\x1c\\x188\\x1d\\x19M) \\x85dX\\xe7\\xc9\\xb9\\xd1\\xb0\\x9c\\xbd\\x97\\x81\\xc0\\x95~\\xc6\\x97\\x83\\xc8\\x94\\x88\\xb5{j\\x88H1\\x89E*\\x9dX:\\xa5`B\\xa2b?\\x93[5\\x81M,h9!^7\\'Y81G+)A&#T<4R?9\\x1e\\x11\\x0fQE>\\xac\\x8d\\x85\\xde\\xb9\\xaf\\xd0\\xa4\\x98\\x92fZS,#:\\x1c\\x189\\x1f\\x1dG*$aF>\\xb3\\x9a\\x8e\\xcd\\xb2\\xa1\\xc9\\xa7\\x91\\xc3\\x97~\\xc7\\x93|\\xc0\\x82r\\xacmT\\xa4cC\\xa9fC\\xaafC\\xa5`A\\x9d\\\\?\\x88Q4m>&]9\\'K/%B)$<$\"R<:C1-<-,\\x1b\\x11\\x12WKH\\xaa\\x8a\\x89\\xe8\\xbe\\xba\\xe9\\xb4\\xac\\xca\\x92\\x87\\x8cZRU/*B# @$\\x1cM4,ZC8\\x81fW\\xa0zf\\xae}c\\xb2v]\\xb6rZ\\xb6tS\\xafoG\\xafnE\\xb0nJ\\xadhL\\x9f]HzD4Y/\"I-$?,&VD@`KH;))\"\\x17\\x19!\\x18\\x1b\\x16\\x0f\\x14^RQ\\x99y}\\xdc\\xb0\\xb0\\xf3\\xb9\\xb2\\xdf\\xa0\\x97\\xacsjsF@N+&B%\\x1aA\\'\\x1dN6+fI;\\xad\\x85q\\xb4~f\\xb1qV\\xabcF\\xa8d>\\xa9i<\\xabk?\\xadkG\\xabeL\\x96SEn82O\\'#C+)N?>gXV_LI \\x12\\x12\\x15\\x0f\\x16\\x15\\x10\\x16\\x17\\x13\\x18'],\n",
      "       [b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x14\\x11\\x18\\x15\\x15\\x17\\x15\\x16\\x1b\\x15\\x12<(\\x1cdD-~R5\\x87^>\\x92hG\\xa2rR\\xaexY\\xb5\\x7f\\\\\\xb7\\x81_\\xb7\\x80`\\xb8\\x7fb\\xb8\\x81e\\xbc\\x89n\\xbf\\x8dr\\xc0\\x8ft\\xbc\\x8dq\\xb8\\x85g\\xb3\\x80`\\xb4\\x83a\\xb0\\x81]\\xb0\\x83]\\xb1\\x83\\\\\\xa8\\x7f^\\x90qZH4) \\x15\\x11#\\x1e\\x1b.)&\\x10\\x10\\x0c\\x0e\\x10\\x12\\x1b\\x19\\x1a!\\x15\\x0fQ8\\'nJ1uL5lG0uQ:\\x8eeP\\xa6xd\\xb8\\x89n\\xc4\\x93x\\xc2\\x8et\\xc2\\x8cr\\xc3\\x8fu\\xc0\\x90v\\xc5\\x93y\\xc0\\x8eu\\xbe\\x8bs\\xba\\x86k\\xb1~`\\xad|\\\\\\xa8yW\\xa9|X\\xaf\\x82[\\xac\\x7fY\\x9asSsYE:+\"\\x1e\\x19\\x160+(\\x13\\x15\\x10\\x15\\x15\\x16$\\x1e\\x1c5%\\x1bY?-Z;%R0#U8,J0%Y;3{YR\\x9f{k\\xc2\\x9a\\x89\\xce\\xa1\\x90\\xd4\\xa4\\x91\\xce\\x9e\\x89\\xc7\\x98\\x80\\xcb\\x9b\\x84\\xc8\\x95~\\xc9\\x92}\\xc8\\x91y\\xc2\\x8ft\\xbb\\x89k\\xb2\\x83b\\xa9|Y\\xa7\\x80[\\xa7|V\\x99pMnS<4&\\x1c\\x1e\\x19\\x16#\\x1e\\x1b\\x10\\x10\\x0c\\x10\\x13\\x13 \\x18\\x15A+\\x1f]>+`A(_?.hL>nUIlQFkL@xVK\\xa1|s\\xc1\\x97\\x8d\\xd8\\xab\\x9b\\xd2\\xa6\\x92\\xd5\\xaa\\x96\\xd8\\xa9\\x97\\xd8\\xa9\\x97\\xd4\\xa7\\x93\\xd0\\xa0\\x8c\\xca\\x9a\\x84\\xc2\\x93y\\xbb\\x8ak\\xb0|[\\xa8~_\\xa5xT\\x95jGfK6$\\x18\\x13\\x15\\x12\\x0f\\x15\\x11\\x0e\\x0e\\r\\x0b\\x14\\x17\\x18 \\x17\\x13W:,zV>\\x82_B\\x92hK\\x98rY\\xa0~h\\xa8\\x84l\\xa4~f\\x91l]\\x94la\\xa9}p\\xc3\\x95\\x80\\xcf\\xa3\\x8d\\xd6\\xab\\x9a\\xd9\\xaa\\x9b\\xe1\\xb5\\xa5\\xd3\\xae\\x9b\\xca\\xa3\\x94\\xbd\\x95\\x87\\xaf\\x8by\\xa1{f\\x99mX\\x92kV\\x98oR\\x8deFjN;+\\x1c\\x17\\x12\\x0f\\n\\x11\\r\\n\\x0e\\r\\x0b\\x13\\x10\\x0e7\\'\\x1dqP:\\x82[?{U:vJ0pJ5rQ@\\x8cjY\\x9ezg\\xa1zf\\xa3xd\\xaf\\x81j\\xbb\\x8ao\\xc7\\x98\\x80\\xd4\\xa5\\x93\\xcf\\x9e\\x8a\\xc8\\x99\\x84\\xb1\\x88u\\x98re}^SmUJiTK]G?_E;uVC\\x83bHnO:J2(\\x17\\x11\\r\\x0f\\x0b\\x08\\x16\\x15\\x13&\\x1c\\x19W?0|W8{P/qH.qH5oMA[@9\\\\B<iJA\\x8ebO\\x9fqY\\xa8w[\\xb5\\x81e\\xc8\\x94\\x7f\\xc9\\x97\\x83\\xc4\\x91u\\xbe\\x8cq\\xae\\x81l\\xa3zk\\x9f}n\\x93zk}g[iRIdJ?[@.lM5oN8gG6\"\\x18\\x16\\x13\\r\\n\\x1a\\x19\\x17:*%jM9\\x80W2\\x8a]:\\x89^D\\x98_C\\xa5t_\\xac\\x83t\\xac\\x86y\\x99pd\\x8e^P\\x97gO\\x9afJ\\xafw_\\xc7\\x90~\\xc3\\x8ey\\xb9\\x83c\\xb5\\x81b\\xb1\\x82l\\xb2\\x83o\\xb3\\x89q\\xb9\\x95|\\xbb\\x98\\x7f\\xae\\x87p\\x97tb~]GlJ1mJ1qM:0%$\\x17\\x0f\\r \\x1b\\x1aW?,yU:\\x90bB\\x99eG\\x9bfL\\x97cF\\x96cF\\x98eL\\x9djU\\x9emY\\x9aoR\\x95gI\\x92_B\\xaaqW\\xbd\\x87l\\xb7\\x82e\\xabtV\\xb1\\x7fd\\xa6}h\\x92l]}_UePIkSH\\x88fS\\xa0xa\\x9dsY\\x84[@uR9kO;2)\"\\x16\\x11\\x0e\\'\\x1d\\x1aqW@\\x88cF\\x95eF\\xa1kO\\xaas[\\xb5r^\\xb7ta\\xb7sc\\xb6qb\\xb0o^\\xa0iO\\x98aG\\x98_F\\xa3iP\\xb0x^\\xa9sV\\xa3lN\\xb2\\x7fe\\xad\\x81l\\x98o`\\x89f\\\\tXQgI=lF3rH0\\x90eJ\\x94iM\\x86bHkN9/&\\x1e\\x14\\x10\\r1$\\x1b\\x82fL\\x90iK\\x9cjL\\xa2iQ\\xb2ye\\xbe\\x82p\\xc3\\x86y\\xc6\\x89~\\xc3\\x86x\\xb8{g\\xb5u`\\xa8jT\\x9fbL\\xacq[\\xads]\\xa5lS\\x9dfI\\xa2lR\\xacwb\\xaf}l\\xb3\\x85w\\xbb\\x91\\x83\\xb2\\x87v\\xa8yc\\x8eaH\\x84W:\\x97kM\\x8dgLiK58/\\'\\x17\\x13\\x10N=.\\x8coQ\\x95lL\\xa6rT\\xb1w`\\xbe\\x83s\\xc5\\x92\\x81\\xd1\\x9d\\x93\\xd2\\x9e\\x97\\xcb\\x98\\x88\\xbd\\x8ar\\xb3ze\\xa1gR\\xaamY\\xbc}j\\xb9yg\\xaanZ\\xa7pU\\xa8pU\\xado[\\xafsb\\xa9p]\\xa6nY\\xa9qZ\\xabs\\\\\\xa3tZ\\x9dnQ\\x90bC\\x91jMmN6=4,\\x15\\x12\\x0eaM9\\x90rQ\\x98pO\\xaey]\\xb9}i\\xc5\\x88x\\xcd\\x94\\x88\\xd8\\x9e\\x99\\xd2\\x99\\x95\\xc4\\x8b~\\xa3mV\\xa3oY\\x97`J\\xa9nY\\xb7xd\\xb9xf\\xado]\\xadw]\\xbf\\x89o\\xbe\\x80k\\xbf\\x81p\\xbe\\x81o\\xb9{e\\xb1s[\\xaepW\\xa3oU\\xa5sU\\x9cmM\\x88`CrQ9?6.\\x1c\\x17\\x14t[?\\x8cpM\\x98qQ\\xaf|b\\xbc\\x82m\\xc7\\x8cy\\xcf\\x98\\x8c\\xcc\\x95\\x87\\xbe\\x88x\\xb4~l\\x9egT\\x9b_K\\xa8lX\\xbd\\x80l\\xc2\\x85q\\xbb}j\\xaco^\\xa9t`\\xb1\\x7fj\\xd1\\x9b\\x87\\xd9\\x9e\\x8f\\xcf\\x95\\x88\\xc5\\x8c~\\xc0\\x84p\\xbf}c\\xb5xb\\xabsX\\xa0rR\\x8efIvT<E6-\\x1e\\x15\\x0f~`?\\x8cjH\\x9boQ\\xafx`\\xbb~j\\xc6\\x8av\\xc9\\x8f\\x7f\\xc4\\x8by\\xc6\\x8dy\\xb6}h\\xa7pY\\x9flU\\xb4\\x80l\\xd6\\xa1\\x92\\xda\\xa5\\x9a\\xc8\\x8f\\x83\\xaetb\\xa8r^\\xa3oZ\\xb9\\x83o\\xcd\\x92\\x84\\xdf\\xa4\\x9a\\xd7\\x9f\\x95\\xc8\\x8d\\x7f\\xc4\\x85r\\xba}h\\xb0x^\\xa3uU\\x94mPvS<L4%=\\'\\x19}^<\\x8afD\\x96iK\\xacw^\\xb9\\x80k\\xbf\\x88s\\xb9\\x81p\\xc0\\x89v\\xbc\\x84p\\xb9\\x82k\\xacx`\\x9akT\\xb5\\x85r\\xd4\\xa3\\x96\\xdf\\xae\\xa5\\xc9\\x97\\x89\\xb6\\x80l\\xb9\\x80m\\xb4{h\\xc2\\x8bw\\xc2\\x86v\\xcf\\x94\\x88\\xe3\\xad\\xa2\\xd5\\x9e\\x91\\xc7\\x8d|\\xc2\\x86p\\xb5}c\\xa4vV\\x93kNvS;eD1\\x96t`z_@\\x8dlI\\x91iJ\\xaa{`\\xb2\\x82i\\xa5x`\\xa1o`\\xa5sc\\xa2q_\\xa3s^\\xa4s^\\x9ahU\\xaaxe\\xb9\\x87u\\xc4\\x92\\x81\\xb8\\x88u\\xb0~i\\xb8~k\\xbf\\x82p\\xcc\\x93\\x80\\xce\\x92}\\xc6\\x8cy\\xd8\\xa4\\x94\\xd9\\xa6\\x95\\xc9\\x94\\x7f\\xc3\\x87q\\xbb\\x84i\\xa6xX\\x93lOvR:~[G\\xc5\\x9f\\x89w`?\\x91sN\\x92kL\\xa8y`\\xa7{f\\x94q[\\x8dhT\\x8dcP\\x92fR\\x93jT\\x97nY\\xa4sf\\xabzl\\xb8\\x86v\\xba\\x89w\\xb5\\x86u\\xa6ug\\xaevh\\xbd\\x80r\\xcd\\x8e\\x7f\\xdc\\x9f\\x8c\\xc7\\x8cy\\xd2\\x9a\\x87\\xd3\\x9d\\x89\\xcb\\x94\\x7f\\xc5\\x8ct\\xbc\\x87n\\xa7z^\\x93lQnL2\\x7f`G\\xbb\\x93|x_?\\x96xT\\x9arU\\xaf\\x80i\\xac\\x82n\\x9e~i\\x98hX\\x90cP\\x95hR\\xa0mX\\xafye\\xb6\\x89x\\xbd\\x92\\x82\\xbc\\x93\\x84\\xb5\\x8d\\x7f\\xb8\\x90\\x82\\xab\\x82s\\x9bo_\\xa2tc\\xaf\\x80m\\xc5\\x8f}\\xc3\\x8by\\xcd\\x95\\x82\\xcd\\x96\\x81\\xc9\\x92|\\xc3\\x8eu\\xb9\\x88o\\xa5z`\\x91lRsQ6xX@\\x98o\\\\uX?\\x98z[\\x97tW\\xb3\\x89q\\xb0\\x88q\\xa6\\x82l\\x9dhZ\\x80XD\\x8cjQ\\x9dmV\\xb5yf\\xc3\\x8e{\\xcd\\x9b\\x8b\\xd4\\xa5\\x9a\\xce\\xa2\\x9a\\xca\\x9c\\x92\\xbc\\x8c|\\xab}k\\xa1wc\\x9dva\\xa9|k\\xb2\\x82p\\xc0\\x8fz\\xc7\\x95}\\xc7\\x94z\\xbf\\x91t\\xb5\\x89n\\xa3|a\\x8ciNsS8\\x84bM\\x95m_hN8\\x94x\\\\\\x92sW\\xb2\\x8ft\\xba\\x94z\\xb3\\x8br\\xad\\x82h\\x87aG\\x88fN\\xaf\\x8ey\\xa7\\x82o\\xae}k\\xc0\\x8d\\x7f\\xd0\\x9e\\x93\\xd2\\x9f\\x97\\xca\\x94\\x88\\xc6\\x8e{\\xbe\\x88v\\xb2\\x81o\\xa7xg\\xa3zi\\xa9\\x82o\\xb6\\x8cu\\xc2\\x95y\\xc0\\x91r\\xb3\\x8bl\\xb1\\x8co\\xa3\\x80d\\x86eIyZ>\\x92mU\\xa3}nL9\"\\x87mR\\x8bpT\\xa7\\x88l\\xb9\\x94y\\xb7\\x8cr\\xbb\\x89f\\xacnV\\x97YK\\x8cfZ\\xa9\\x97\\x88\\xcc\\xba\\xa4\\xc3\\xad\\x97\\xbd\\xa0\\x8c\\xc8\\xa6\\x93\\xc2\\x9c\\x85\\xb8\\x91v\\xb1\\x8ap\\xac\\x84o\\xa1zg\\x9dzi\\xae\\x8cy\\xba\\x94|\\xbf\\x95w\\xb9\\x8ck\\xad\\x8bj\\xb2\\x91r\\x9f\\x7fb\\x81bEz[?\\xb2\\x8co\\x89dQ-%\\x19y`G\\x8fqV\\x9b|`\\xb4\\x92t\\xb3\\x8em\\xc0\\x91u\\xaf~c\\xa0mS\\x9chN\\x9flT\\xa8\\x81o\\xbc\\x9f\\x90\\xcd\\xb8\\xaa\\xce\\xbc\\xac\\xc1\\xab\\x9f\\xba\\xa1\\x9c\\xb2\\x9b\\x91\\x92uh\\x7fWJ\\x98mY\\xb4\\x8bs\\xbe\\x96}\\xbe\\x99\\x7f\\xae\\x89o\\xb6\\x94w\\xb5\\x91q\\x9f{[\\x82cFiP:O?>E66\\'\\x1d\\x19`K8\\x84jR\\x91rW\\xa4\\x82d\\xb1\\x8dn\\xbd\\x8fu\\xb6\\x87m\\xa3rX\\xb3\\x7fg\\xba\\x85n\\xc2\\x8by\\xbc\\x8b~\\xb7\\x8a~\\xa7xj\\x9chW\\x97dN\\x94eK\\xa0qS\\xb3\\x81a\\xb8\\x8bp\\xb7\\x8eu\\xc2\\x9c\\x82\\xbb\\x97}\\xab\\x88m\\xb9\\x97{\\xaf\\x8cn\\x99wZ~bJS>,*\\x1e\\x192&\" \\x16\\x16B4(zdP\\x8akQ\\x94rV\\xa7\\x86j\\xba\\x8dt\\xb6\\x88p\\xaf\\x7fh\\xb2\\x81j\\xbe\\x8cu\\xc7\\x98\\x83\\xcc\\xa0\\x8e\\xd0\\xa3\\x92\\xcc\\x98\\x85\\xc2\\x8cu\\xbc\\x87n\\xb5\\x82g\\xb3\\x84g\\xba\\x90o\\xba\\x92v\\xc0\\x9b\\x81\\xc0\\x9c\\x82\\xb2\\x8ft\\xb4\\x93x\\xb8\\x97}\\xa6\\x84j\\x91rY{dR@1&(!\\x1b5-\\'\\x1b\\x12\\x11\\x1f\\x18\\x12l[K\\x87iO\\x8emQ\\x98{b\\xb8\\x8dv\\xba\\x8ew\\xb3\\x85n\\xbc\\x8cv\\xbf\\x90{\\xb9\\x8e|\\xbc\\x95\\x85\\xc2\\x9c\\x8a\\xc6\\x9c\\x85\\xbf\\x94y\\xbd\\x90w\\xb9\\x8ar\\xbc\\x8fw\\xb9\\x94y\\xbc\\x99~\\xbf\\x9b\\x81\\xb7\\x95z\\xac\\x8bp\\xb7\\x98|\\xad\\x8ev\\x9c|e\\x89mZn[P$\\x1b\\x16\\x1c\\x1a\\x17/*(khd\\x80\\x7f{\\x93\\x86z\\x81fO\\x84fL\\x90u]\\xb0\\x88p\\xbd\\x92z\\xbb\\x8ct\\xbb\\x8cu\\xc1\\x91}\\xc0\\x8f\\x80\\xc4\\x97\\x88\\xc6\\x9b\\x89\\xca\\x9d\\x86\\xc6\\x99~\\xc4\\x95w\\xc6\\x94x\\xc3\\x92v\\xbd\\x93u\\xbc\\x97{\\xb8\\x94z\\xab\\x8ap\\xac\\x8et\\xac\\x8eu\\xa1\\x83n\\x94s_\\x8aqc\\xa0\\x94\\x8cH?9,(#2+*\\xc6\\xc7\\xc4\\xcf\\xd0\\xcd\\xcd\\xc5\\xbd|iX\\x7ffP\\x8cqZ\\xa6\\x82j\\xb3\\x88m\\xb4\\x83h\\xba\\x89q\\xbf\\x91}\\xc0\\x95\\x80\\xc6\\x9a\\x84\\xcd\\xa0\\x88\\xcb\\x9d\\x84\\xca\\x9a\\x81\\xc8\\x97\\x80\\xc4\\x96~\\xbe\\x95y\\xb7\\x91t\\xb3\\x91w\\xab\\x8as\\xac\\x8ex\\xab\\x90|\\xa6\\x8cz\\x99\\x80l\\x96vb\\x96\\x83{\\xb3\\xae\\xac\\x92\\x89|SJ;C80\\xdd\\xdd\\xd9\\xd5\\xd6\\xd5\\xea\\xe5\\xdd\\x87vf\\x81jT\\x83jS\\x9ez`\\xa2x\\\\\\xa0pS\\xae}d\\xbb\\x8cw\\xc2\\x95\\x82\\xc4\\x96\\x82\\xc5\\x96\\x80\\xc6\\x96\\x7f\\xca\\x9a\\x82\\xc8\\x9a\\x82\\xc1\\x97~\\xb4\\x8et\\xad\\x8ao\\xa8\\x8au\\xa1\\x86t\\xab\\x91\\x7f\\xa7\\x8e}\\x99\\x81q\\x93|h\\x91t_|of\\xa1\\xa4\\xa2\\xc8\\xc6\\xbcoiec[Z\\xd2\\xd3\\xce\\xe6\\xe9\\xe9\\xe5\\xe1\\xdb\\x95\\x85w\\x82mY\\x80iT\\x92t\\\\\\x9bw]\\xa4y_\\xb5\\x8as\\xbe\\x95\\x81\\xbe\\x96\\x83\\xbf\\x96\\x82\\xbb\\x90{\\xb5\\x89r\\xb0\\x84k\\xb8\\x8ft\\xb4\\x8fu\\xa6\\x84l\\xa4\\x85n\\x9d\\x83q\\xa7\\x8f~\\xa7\\x8c{\\x9e\\x83q\\x97{h\\x97}h}^JbTN\\xd5\\xd9\\xdc\\xd9\\xda\\xd5\\xcf\\xce\\xd0\\xd4\\xd3\\xd4\\xda\\xde\\xd7\\xe5\\xea\\xeb\\xe4\\xe1\\xdc\\x8e\\x80r\\x7fkX\\x80kW\\x7fkX\\x92va\\xa5\\x83n\\xb3\\x91\\x7f\\xbd\\x9c\\x8d\\xbc\\x9c\\x88\\xbf\\x9e\\x89\\xbb\\x98\\x82\\xb2\\x8dv\\xac\\x86k\\xb0\\x8an\\xac\\x8ao\\xa0\\x81j\\x98{h\\xa5\\x8ax\\xa9\\x8e{\\xa0\\x82n\\x9c|e\\xa0~f\\x94r^lG5\\xb5\\xa2\\x9f\\xec\\xec\\xf2\\xe2\\xe1\\xe0\\xd5\\xd9\\xd9\\xdf\\xe2\\xe2']],\n",
      "      dtype=object)}]\n",
      "[[0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]] [[-7.26971477e-02  7.17800707e-02  8.82160813e-02 -8.18104669e-02\n",
      "  -7.90959448e-02 -5.96554875e-02 -2.41319612e-02 -1.20586231e-01\n",
      "   1.17698476e-01 -1.59430653e-01  1.57633767e-01 -1.00669883e-01\n",
      "  -2.30072364e-01 -3.09263729e-02 -2.00881660e-02  1.83538437e-01\n",
      "  -1.32000074e-01 -1.60702944e-01 -1.22243211e-01  1.83078274e-02\n",
      "   3.06281596e-02  2.03765929e-02 -5.43838963e-02  6.30166978e-02\n",
      "  -5.66880330e-02 -3.32251608e-01 -6.35823607e-02 -8.61983448e-02\n",
      "  -6.09786436e-03  1.14731193e-02 -2.87986174e-02  9.69129801e-02\n",
      "  -1.35701567e-01 -4.09994163e-02  4.61715423e-02  1.07372642e-01\n",
      "  -1.41959414e-02 -4.57401611e-02  1.54507264e-01 -2.95228809e-02\n",
      "  -2.85151005e-01  7.09810108e-03  3.91827039e-02  1.83032677e-01\n",
      "   2.25876540e-01  5.88971376e-03 -7.08885491e-05 -8.97776335e-02\n",
      "   1.13409370e-01 -2.26962954e-01 -1.08883604e-02  1.13701589e-01\n",
      "   4.84988913e-02  1.19410828e-01  3.29821408e-02 -1.88890114e-01\n",
      "   7.18694478e-02  1.14416197e-01 -1.76597565e-01  3.64786014e-02\n",
      "   5.57531193e-02 -1.99351102e-01  8.93849880e-03 -2.13563517e-02\n",
      "   1.74919575e-01  3.74053940e-02 -1.14723727e-01 -1.74007595e-01\n",
      "   1.53633580e-01 -1.99423224e-01 -3.48711014e-02  7.96156079e-02\n",
      "  -1.45276368e-01 -1.40694186e-01 -2.85895914e-01  1.63437687e-02\n",
      "   4.30251837e-01  1.61385804e-01 -1.84508711e-01  3.12087461e-02\n",
      "  -4.43348587e-02 -3.60095128e-03  1.44614965e-01  1.32397652e-01\n",
      "   3.82683501e-02 -7.07805678e-02 -7.23956153e-02 -4.82146181e-02\n",
      "   2.10255384e-01 -3.33046392e-02 -3.77594866e-02  2.10545316e-01\n",
      "  -4.37849164e-02  6.91870898e-02  1.15665793e-02  3.29596549e-03\n",
      "  -5.60821891e-02  1.11066885e-02 -1.08072057e-01  8.29026103e-05\n",
      "  -2.10090727e-02 -7.38006160e-02 -1.58846490e-02  9.98622701e-02\n",
      "  -1.19769290e-01  1.26130611e-01 -2.27687582e-02  7.52520487e-02\n",
      "   1.55174956e-02  5.13489917e-02 -8.18506181e-02 -6.46104217e-02\n",
      "   1.70246050e-01 -1.74658179e-01  2.13551939e-01  2.08811507e-01\n",
      "   5.62272035e-02  9.89365876e-02  1.11065663e-01  7.41437599e-02\n",
      "   1.78347975e-02 -2.61698812e-02 -2.03776121e-01 -4.68263328e-02\n",
      "   9.67028514e-02 -1.24127418e-02  6.38042390e-02  1.43445618e-02]\n",
      " [-1.26587972e-01  9.64991748e-02  1.02703266e-01  7.12972879e-03\n",
      "  -5.33298925e-02 -7.25868046e-02  2.67152488e-03 -3.05299312e-02\n",
      "   1.60250992e-01 -3.48758548e-02  2.46299475e-01 -9.16556269e-02\n",
      "  -2.61510968e-01 -9.42409337e-02 -3.94430757e-02  1.56390786e-01\n",
      "  -6.29829019e-02 -2.43633986e-05 -1.02966607e-01 -2.03769058e-02\n",
      "   5.89410216e-02  7.76666105e-02  7.14259669e-02  6.14314824e-02\n",
      "   1.44526362e-03 -3.70976448e-01 -8.50881338e-02 -4.21651378e-02\n",
      "   5.86954355e-02 -1.51490420e-01 -5.91759831e-02  9.53996927e-03\n",
      "  -1.41285762e-01 -1.67296737e-01  4.43121716e-02  7.50152841e-02\n",
      "  -2.58777831e-02 -4.65221182e-02  1.31161079e-01  1.81507096e-02\n",
      "  -2.10310817e-01 -2.24281326e-02  4.93792817e-02  3.01713765e-01\n",
      "   1.63349003e-01  9.46536064e-02 -2.75075100e-02 -1.56595975e-01\n",
      "   1.08540773e-01 -1.92164153e-01  1.01059929e-01  6.77084625e-02\n",
      "   1.41564727e-01  5.72132990e-02  1.11057326e-01 -1.31475538e-01\n",
      "   2.44492181e-02  1.48369491e-01 -2.67813325e-01  3.66850458e-02\n",
      "   4.63688225e-02  4.48601693e-03 -2.41849627e-02 -1.65432952e-02\n",
      "   1.63521215e-01  1.22736700e-01 -1.24190673e-01 -1.40435159e-01\n",
      "   1.35693312e-01 -1.69918969e-01  1.20929703e-02  1.35290086e-01\n",
      "  -5.63103631e-02 -1.94671690e-01 -2.88947225e-01  4.82168868e-02\n",
      "   3.80012393e-01  1.12327531e-01 -2.37790465e-01 -7.38041177e-02\n",
      "  -3.16452719e-02 -2.73724608e-02  1.16088018e-01  1.36442959e-01\n",
      "  -7.28247091e-02  1.75040700e-02 -6.81768507e-02 -1.29884053e-02\n",
      "   7.66297057e-02 -1.07802525e-02 -7.85271376e-02  2.26932049e-01\n",
      "   4.21671867e-02  8.33623111e-03  6.44549578e-02  1.10926218e-01\n",
      "  -1.28148705e-01  1.85931548e-02 -1.83352724e-01 -8.01551789e-02\n",
      "   9.52119678e-02 -6.31243512e-02  7.05607235e-04  6.28352091e-02\n",
      "  -1.77664027e-01  1.76978320e-01  3.86002772e-02 -3.14575434e-02\n",
      "   3.78054678e-02 -3.39742079e-02 -5.66105247e-02 -1.35806203e-02\n",
      "   1.25541583e-01 -2.73060530e-01  2.02197164e-01  1.43527418e-01\n",
      "   1.48550104e-02  1.52237833e-01  2.54294723e-02  7.71425813e-02\n",
      "   5.46981022e-02 -7.97674879e-02 -5.62265515e-02 -6.39269501e-02\n",
      "   6.22794926e-02 -4.22194600e-02  8.29135701e-02 -3.27710025e-02]]\n",
      "[[[118  85  75 ...  23  19  24]]\n",
      "\n",
      " [[  0   0   0 ... 223 226 226]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  values = sess.run([variable_dataset])\n",
    "  print(values)\n",
    "  print(values[0]['age'], values[0]['enc'])\n",
    "  print(tf.io.decode_raw(values[0]['img'], tf.uint8).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZNLvw1uCEiz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  for i in range(4000//16):\n",
    "    values = sess.run([variable_dataset])\n",
    "    print(values[0]['age'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RK7vMyQWLp1V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {age: (?, ?), enc: (?, ?), img: (?, ?)}, types: {age: tf.int64, enc: tf.float32, img: tf.string}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "iSszxe2oKY02",
    "outputId": "ee5ce939-c513-4c70-9983-ae17faca6d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[36864,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/Adam/Square_10}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-61056af86d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       \u001b[0mloss_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[36864,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/Adam/Square_10}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "EPOCHS = 10000\n",
    "STEPS = 1024 // BATCH_SIZE\n",
    "\n",
    "\n",
    "train_loss_g = []\n",
    "val_loss_g = []\n",
    "\n",
    "train_loss_d = []\n",
    "val_loss_d = []\n",
    "\n",
    "\n",
    "train_acc_g = []\n",
    "val_acc_g = []\n",
    "\n",
    "train_acc_d = []\n",
    "val_acc_d = []\n",
    "\n",
    "\n",
    "y_fake = tf.zeros((BATCH_SIZE,))\n",
    "y_true = tf.ones((BATCH_SIZE,))\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "  K.set_session(sess)\n",
    "  \n",
    "  tf.initialize_all_variables().run()\n",
    "\n",
    "  # epochs\n",
    "  for e in range(EPOCHS):\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "      values = sess.run([variable_dataset])\n",
    "      row = values[0]\n",
    "\n",
    "      sz = row['img'].shape[0]\n",
    "\n",
    "#       if sz != BATCH_SIZE:\n",
    "#         continue\n",
    "\n",
    "      # train discriminator\n",
    "\n",
    "      # fake data\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      x = tf.random.normal((sz, noise_len,)).eval()\n",
    "      z_fake = generator.predict([c1, c2, x])\n",
    "\n",
    "      # real data\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      z_real = tf.reshape(tf.io.decode_raw(row['img'], tf.uint8), (-1, width, height, depth)).eval()\n",
    "\n",
    "      # train\n",
    "      loss_1, acc_1 = discriminator.train_on_batch([c1, c2, z_fake], y_fake.eval())\n",
    "      loss_2, acc_2 = discriminator.train_on_batch([c1, c2, z_real], y_true.eval())\n",
    "\n",
    "      batch_loss = 0.5 * (float(tf.reduce_mean(loss_1).eval()) + float(tf.reduce_mean(loss_2).eval()))\n",
    "      batch_acc = 0.5 * (float(tf.reduce_mean(acc_1).eval()) + float(tf.reduce_mean(acc_2).eval()))\n",
    "\n",
    "      loss.append(batch_loss)\n",
    "      acc.append(batch_acc)\n",
    "\n",
    "    train_loss_d.append(np.mean(np.array(loss)))\n",
    "    train_acc_d.append(np.mean(np.array(acc)))\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "      values = sess.run([variable_dataset])\n",
    "      row = values[0]\n",
    "\n",
    "      sz = row['img'].shape[0]\n",
    "\n",
    "#       if sz != BATCH_SIZE:\n",
    "#         continue\n",
    "\n",
    "      # train generator\n",
    "\n",
    "      # concatenate face + age + noise\n",
    "      c1 = row['enc']\n",
    "      c2 = tf.cast(row['age'], tf.float32).eval()\n",
    "      x = tf.random.normal((sz, noise_len,)).eval()\n",
    "\n",
    "      # train\n",
    "      loss_1, acc_1 = gan.train_on_batch([c1, c2, x], y_true.eval())\n",
    "\n",
    "      batch_loss = float(tf.reduce_mean(loss_1).eval())\n",
    "      batch_acc = float(tf.reduce_mean(acc_1).eval())\n",
    "\n",
    "      loss.append(batch_loss)\n",
    "      acc.append(batch_acc)\n",
    "\n",
    "    train_loss_g.append(np.mean(np.array(loss)))\n",
    "    train_acc_g.append(np.mean(np.array(acc)))\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, Steps: {}, Discriminator Loss: {:.3f}, Discriminator Accuracy: %{:.2f}, GAN Loss: {:.3f}, GAN Accuracy: %{:.2f}\".format(\n",
    "          e,\n",
    "          STEPS,\n",
    "          train_loss_d[-1],\n",
    "          train_loss_g[-1],\n",
    "          train_acc_d[-1],\n",
    "          train_acc_g[-1]\n",
    "      ))\n",
    " \n",
    "    if e % 100 == 1:\n",
    "\n",
    "      pth = os.path.join(models_path, 'gan.h5')\n",
    "      gan.save(pth)\n",
    "\n",
    "      pth = os.path.join(models_path, 'generator-{}-{}-{}.h5'.format(e, train_loss_g[-1], train_acc_g[-1]))\n",
    "      generator.save(pth)\n",
    "\n",
    "      pth = os.path.join(models_path, 'discriminator.h5')\n",
    "      discriminator.save(pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0Uxu-RaTBiI"
   },
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRFK2jHCpfpK"
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKLt5f22piWS"
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LzhKde-CaDu"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_g, label=\"Generator Loss\");\n",
    "plt.plot(train_loss_d, label=\"Discriminator Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YhSUa3fROSg"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_acc_g, label=\"Generator Accuracy\");\n",
    "plt.plot(train_acc_d, label=\"Discriminator Accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E93kpBKFC84Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Standalone Keras AGE-CGAN",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
