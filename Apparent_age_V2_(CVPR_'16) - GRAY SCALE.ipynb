{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zs6pEGD5YjT9",
    "outputId": "689820b6-69c0-46b6-d100-188a0b9019d6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os\n",
    "\n",
    "\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "root_path = './'\n",
    "src_pth = '/media/qamaruddin/3D88CA1A4434D0CA/GANs/dataset'\n",
    "tgt_pth = os.path.join(root_path, 'tf_dataset_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "qLZatZYfZIdK",
    "outputId": "e5a267c6-7fc3-40d9-fa7a-f041b6393680"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import wget\n",
    "import os\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import imutils\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GypwKx0LZPH6"
   },
   "outputs": [],
   "source": [
    "base_dir = src_pth\n",
    "data_root = pathlib.Path(base_dir)\n",
    "\n",
    "train_set = data_root.glob('train/*.jpg')\n",
    "val_set = data_root.glob('val/*.jpg')\n",
    "test_set = data_root.glob('test/*.jpg')\n",
    "\n",
    "train_y = pd.read_csv(os.path.join(base_dir, 'train/train_gt.csv'))\n",
    "val_y = pd.read_csv(os.path.join(base_dir, 'val/valid_gt.csv'))\n",
    "test_y = pd.read_csv(os.path.join(base_dir, 'test/test_gt.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zm2NxuVkZTgR"
   },
   "outputs": [],
   "source": [
    "train_y['age'] = train_y['mean'].apply(lambda x: ceil(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJ03Yb26aEJ2"
   },
   "outputs": [],
   "source": [
    "def groupify_age(x):\n",
    "    x = ceil(x)\n",
    "    if x < 10:\n",
    "        return 0\n",
    "    elif x < 20:\n",
    "        return 1\n",
    "    elif x < 30:\n",
    "        return 2\n",
    "    elif x < 40:\n",
    "        return 3\n",
    "    elif x < 50:\n",
    "        return 4\n",
    "    elif x < 60:\n",
    "        return 5\n",
    "    elif x < 70:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-EOudZZaH42"
   },
   "outputs": [],
   "source": [
    "train_y['age'] = train_y['mean'].apply(groupify_age)\n",
    "val_y['age'] = val_y['mean'].apply(groupify_age)\n",
    "test_y['age'] = test_y['mean'].apply(groupify_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hIP6YlwaLwP"
   },
   "outputs": [],
   "source": [
    "train_y = train_y.drop(columns=['mean', 'stdv'])\n",
    "val_y = val_y.drop(columns=['mean', 'stdv'])\n",
    "test_y = test_y.drop(columns=['mean', 'stdv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IrCr1f7aPH2"
   },
   "outputs": [],
   "source": [
    "train_y = pd.concat([train_y, pd.get_dummies(pd.Categorical(train_y['age']))], axis=1)\n",
    "val_y = pd.concat([val_y, pd.get_dummies(pd.Categorical(val_y['age']))], axis=1)\n",
    "test_y = pd.concat([test_y, pd.get_dummies(pd.Categorical(test_y['age']))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBDkbjleaSnf"
   },
   "outputs": [],
   "source": [
    "train_y = train_y.set_index(['image'])\n",
    "val_y = val_y.set_index(['image'])\n",
    "test_y = test_y.set_index(['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GD3wFF-2aYAn"
   },
   "outputs": [],
   "source": [
    "train_y = train_y.drop(columns=['age'])\n",
    "val_y = val_y.drop(columns=['age'])\n",
    "test_y = test_y.drop(columns=['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "rLpVQAaLabXM",
    "outputId": "4841ceec-eae7-470b-fa3e-101e20faafba"
   },
   "outputs": [],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "OIHwoJMVaov4",
    "outputId": "b0ac280d-77c2-4e21-c95d-ee5323f1c6d0"
   },
   "outputs": [],
   "source": [
    "train_y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "yGjkE7pParFA",
    "outputId": "fb5ae0a4-fd56-4027-a368-83b793cc7403"
   },
   "outputs": [],
   "source": [
    "train_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "XjUVuOTtbIcy",
    "outputId": "889fdd16-55a0-4fb4-9bc3-63c4bd78232b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "img_path = os.path.join(src_pth, \"test/005694.jpg\")\n",
    "img = face_recognition.load_image_file(img_path)\n",
    "\n",
    "locations = face_recognition.face_locations(img)\n",
    "encodings = face_recognition.face_encodings(img, locations)\n",
    "\n",
    "for encoding, location in zip(encodings, locations):\n",
    "    top, right, bottom, left = location\n",
    "    face = img[top:bottom, left:right]\n",
    "    rsz = imutils.resize(face, width=32, height=32)\n",
    "    cropped = rsz[0:32, 0:32]\n",
    "    gray = rgb2gray(cropped)\n",
    "    # display images\n",
    "    fig, ax = plt.subplots(1,5)\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(face)\n",
    "    ax[2].imshow(rsz)\n",
    "    ax[3].imshow(cropped)\n",
    "    ax[4].imshow(gray, cmap='gray')\n",
    "    plt.show();\n",
    "    \n",
    "    gray = np.expand_dims(rgb2gray(cropped), axis=-1)\n",
    "    \n",
    "    print(face.shape, rsz.shape, cropped.shape, gray.shape)\n",
    "    print(gray.ravel().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "NROzxkZfU8d_",
    "outputId": "8a7a508e-ef39-4c09-ef3d-4de06fb87797"
   },
   "outputs": [],
   "source": [
    "\n",
    "img_path = os.path.join(src_pth, \"test/005822.jpg\")\n",
    "img = face_recognition.load_image_file(img_path)\n",
    "\n",
    "locations = face_recognition.face_locations(img)\n",
    "encodings = face_recognition.face_encodings(img, locations)\n",
    "\n",
    "for encoding, location in zip(encodings, locations):\n",
    "    top, right, bottom, left = location\n",
    "    face = img[top:bottom, left:right]\n",
    "    rsz = imutils.resize(face, width=32)\n",
    "    cropped = rsz[0:32, 0:32]\n",
    "    \n",
    "    width, height, depth = cropped.shape\n",
    "    print(width, height, depth)\n",
    "    padded = np.pad(cropped, ((32-width, 0), (0,0), (0,0)), 'constant', constant_values=0)\n",
    "    print(padded.shape)\n",
    "    # display images\n",
    "    fig, ax = plt.subplots(1,5)\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(face)\n",
    "    ax[2].imshow(rsz)\n",
    "    ax[3].imshow(cropped)\n",
    "    ax[4].imshow(padded)\n",
    "    plt.show();\n",
    "    \n",
    "    print(face.shape, rsz.shape, cropped.shape, padded.shape)\n",
    "    print(cropped.ravel().shape)\n",
    "    print(padded.ravel().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "qtS5ygSVVIB_",
    "outputId": "aaf4eda0-8968-486b-867d-e2a6e22e2a58"
   },
   "outputs": [],
   "source": [
    "\n",
    "img_path = os.path.join(src_pth, \"test/005977.jpg\")\n",
    "img = face_recognition.load_image_file(img_path)\n",
    "\n",
    "locations = face_recognition.face_locations(img)\n",
    "encodings = face_recognition.face_encodings(img, locations)\n",
    "\n",
    "for encoding, location in zip(encodings, locations):\n",
    "    top, right, bottom, left = location\n",
    "    face = img[top:bottom, left:right]\n",
    "    rsz = imutils.resize(face, width=32, height=32)\n",
    "    cropped = rsz[0:32, 0:32]\n",
    "    # display images\n",
    "    fig, ax = plt.subplots(1,4)\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(face)\n",
    "    ax[2].imshow(rsz)\n",
    "    ax[3].imshow(cropped)\n",
    "    plt.show();\n",
    "    \n",
    "    print(face.shape, rsz.shape, cropped.shape)\n",
    "    print(cropped.ravel().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "Uv3R6JDlVUDw",
    "outputId": "63afa25e-23fe-4b25-c9a1-eda37b1d1a6c"
   },
   "outputs": [],
   "source": [
    "\n",
    "img_path = os.path.join(src_pth, \"test/006186.jpg\")\n",
    "img = face_recognition.load_image_file(img_path)\n",
    "\n",
    "locations = face_recognition.face_locations(img)\n",
    "encodings = face_recognition.face_encodings(img, locations)\n",
    "\n",
    "for encoding, location in zip(encodings, locations):\n",
    "    top, right, bottom, left = location\n",
    "    face = img[top:bottom, left:right]\n",
    "    rsz = imutils.resize(face, width=32, height=32)\n",
    "    cropped = rsz[0:32, 0:32]\n",
    "    # display images\n",
    "    fig, ax = plt.subplots(1,4)\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(face)\n",
    "    ax[2].imshow(rsz)\n",
    "    ax[3].imshow(cropped)\n",
    "    plt.show();\n",
    "    \n",
    "    print(face.shape, rsz.shape, cropped.shape)\n",
    "    print(cropped.ravel().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ph7L8Zq7asri"
   },
   "outputs": [],
   "source": [
    "def encode_binary(writer, source_set, label_set):\n",
    "\n",
    "counter = 0\n",
    "for image in source_set:\n",
    "    if '(' in str(image) and ')' in str(image):\n",
    "      # skip duplicates\n",
    "      continue\n",
    "    idx = str(image).split('/')[-1]\n",
    "    try:\n",
    "      img = face_recognition.load_image_file(image)\n",
    "    except:\n",
    "      # avoid div by zero\n",
    "      continue\n",
    "    locations = face_recognition.face_locations(img)\n",
    "    encodings = face_recognition.face_encodings(img, locations)\n",
    "\n",
    "    for encoding, location in zip(encodings, locations):\n",
    "        y = label_set .loc[idx]\n",
    "\n",
    "        top, right, bottom, left = location\n",
    "        face = img[top:bottom, left:right]\n",
    "        rsz = imutils.resize(face, width=32, height=32)\n",
    "        cropped = rsz[0:32, 0:32]\n",
    "        width, height, depth = cropped.shape\n",
    "        padded = np.pad(cropped, ((32-width, 0), (0,0), (0,0)), 'constant', constant_values=0)\n",
    "        gray = rgb2gray(padded)\n",
    "        gray = np.expand_dims(gray, axis=-1)\n",
    "\n",
    "        print(gray.ravel().shape)\n",
    "\n",
    "        assert gray.ravel().shape == (1024,)\n",
    "\n",
    "        feature = {\n",
    "            'enc': tf.train.Feature(float_list=tf.train.FloatList(value=encoding)),\n",
    "            'age': tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
    "            'img': tf.train.Feature(bytes_list=tf.train.BytesList(value=[gray.tostring()]))\n",
    "        }\n",
    "\n",
    "        record = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "        writer.write(record.SerializeToString())\n",
    "\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(\"Complete: {}\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "9Xc5LzNJhUjm",
    "outputId": "4e4b3b98-4e1d-4063-cd16-8bb8dea6fc65"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(tgt_pth):\n",
    "    os.makedirs(tgt_pth)\n",
    "\n",
    "\n",
    "target_file = os.path.join(tgt_pth, 'train.tfrecords')\n",
    "\n",
    "with tf.python_io.TFRecordWriter(target_file) as writer:\n",
    "    \n",
    "    print(\"Processing Training:\")\n",
    "    \n",
    "    encode_binary(writer, train_set, train_y)\n",
    "\n",
    "    print(\"Processing Validation:\")\n",
    "    encode_binary(writer, val_set, val_y)\n",
    "\n",
    "    print(\"Processing Testing:\")\n",
    "    encode_binary(writer, test_set, test_y)\n",
    "\n",
    "print(\"Complete, Thank you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqHAvmYChthH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Apparent age V2 (CVPR '16)",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
