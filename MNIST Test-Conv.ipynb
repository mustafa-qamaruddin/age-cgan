{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAQBOBYyi9sc"
   },
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1554977904593,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "BIEdHLeqDLJH",
    "outputId": "90567bca-f98c-4b16-c01f-adc92d510da4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "root_path = './'\n",
    "\n",
    "models_path = os.path.join(root_path, 'saved_models_mnist_v7')\n",
    "if not os.path.exists(models_path):\n",
    "    os.mkdir(models_path)\n",
    "\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = (x_train / 127.5) - 1, (x_test / 127.5) - 1\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2751,
     "status": "ok",
     "timestamp": 1554977904597,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "MxSDNtvqj0Xs",
    "outputId": "876f60f6-e4ef-4454-bfa5-f3ff6b5a8f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(60000, 28, 28, 1) (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "y_train = to_categorical(y_train)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-5tD_u3kY9T"
   },
   "outputs": [],
   "source": [
    "def custom_loader():\n",
    "\n",
    "  trainset_size = x_train.shape[0]\n",
    "\n",
    "  p = 0\n",
    "  while True:\n",
    "\n",
    "    idx_from = (p * BATCH_SIZE) % trainset_size\n",
    "\n",
    "    idx_to = idx_from + BATCH_SIZE\n",
    "\n",
    "    batch_x = x_train[idx_from: idx_to]\n",
    "    batch_y = y_train[idx_from: idx_to]\n",
    "    \n",
    "    p += 1\n",
    "  \n",
    "    yield batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2498,
     "status": "ok",
     "timestamp": 1554977904621,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "3YQeAq8il_eI",
    "outputId": "40a7ee0a-86f7-4c97-c0d1-43276af0db75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 28, 28, 1) (256, 10)\n",
      "(256, 28, 28, 1) (256, 10)\n",
      "(256, 28, 28, 1) (256, 10)\n"
     ]
    }
   ],
   "source": [
    "custom_gen = custom_loader()\n",
    "for i in range(3):\n",
    "  batch_x, batch_y = next(custom_gen)\n",
    "  print(batch_x.shape, batch_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMouydu3i9sp"
   },
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3123,
     "status": "ok",
     "timestamp": 1554977905340,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "HAuHCfjlFBOy",
    "outputId": "abf88c5b-9df8-41dc-9017-9d8a2007a0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "D M1:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 6, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 3)           867       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 2, 3)           0         \n",
      "=================================================================\n",
      "Total params: 5,859\n",
      "Trainable params: 5,763\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "D M2:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 23        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 23\n",
      "Trainable params: 23\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "G M2:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_1 (Conv2DTr (None, 13, 13, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 27, 27, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 27, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         33        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 9,281\n",
      "Trainable params: 9,121\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "G M1:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 121)               7381      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 121)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 11, 11, 1)         0         \n",
      "=================================================================\n",
      "Total params: 7,381\n",
      "Trainable params: 7,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc_len = 0\n",
    "age_len = 10\n",
    "img_shape = (28, 28, 1)\n",
    "width, height, depth = (28, 28, 1)\n",
    "img_len = np.prod(img_shape)\n",
    "latent_dim = enc_len + age_len + img_len\n",
    "noise_len = 50  # 32 x 32 x 3\n",
    "input_dim = enc_len + age_len + noise_len\n",
    "cond_len = enc_len + age_len\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    conv = keras.Sequential([\n",
    "        # conv block 1\n",
    "        keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2,\n",
    "            input_shape=img_shape\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        # conv block 2\n",
    "        keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # conv block 3\n",
    "        keras.layers.Conv2D(\n",
    "            filters=3,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.leaky_relu),\n",
    "    ])\n",
    "    \n",
    "    print(\"D M1:\")\n",
    "    conv.summary()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # output\n",
    "        keras.layers.Dense(1, input_shape=(age_len+12,)),\n",
    "        keras.layers.Activation(tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "    print(\"D M2:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # condition\n",
    "#     c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # image\n",
    "    z = keras.layers.Input(shape=img_shape)\n",
    "    \n",
    "    # convolution\n",
    "    zout = conv(z)\n",
    "    \n",
    "    # flatten image\n",
    "    z_flat = keras.layers.Flatten()(zout)\n",
    "    \n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c2, z_flat])\n",
    "    \n",
    "    # real or fake\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    return keras.models.Model([c2, z], outputs)\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    \n",
    "    conv = keras.Sequential([\n",
    "        # transpose conv block 1\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=1,\n",
    "            input_shape=(11, 11, 1)\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # transpose conv block 2\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        # transpose conv block 3\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=(2, 2),\n",
    "            strides=1\n",
    "        ),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        # transpose conv block 4\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters=1,\n",
    "            kernel_size=(1, 1),\n",
    "            strides=1\n",
    "        ),\n",
    "        \n",
    "        # output\n",
    "        keras.layers.Activation(tf.nn.tanh)\n",
    "    ])\n",
    "    \n",
    "    print(\"G M2:\")\n",
    "    conv.summary()\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # dense 1\n",
    "        keras.layers.Dense(121, input_shape=(input_dim,)),\n",
    "        keras.layers.Activation(tf.nn.relu),\n",
    "        \n",
    "        # reshape 1d to 3d\n",
    "        keras.layers.Reshape((11, 11, 1))\n",
    "    ])\n",
    "    \n",
    "    print(\"G M1:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # condition\n",
    "#     c1 = keras.layers.Input(shape=(enc_len,))\n",
    "    c2 = keras.layers.Input(shape=(age_len,))\n",
    "    \n",
    "    # noise\n",
    "    x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "    # concatenation\n",
    "    inputs = keras.layers.concatenate([c2, x])\n",
    "    \n",
    "    # flat dense output\n",
    "    out_1 = model(inputs)\n",
    "    \n",
    "    # transpose conv output\n",
    "    outputs = conv(out_1)\n",
    "    \n",
    "    return keras.models.Model([c2, x], outputs)\n",
    "\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3046,
     "status": "ok",
     "timestamp": 1554977905345,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "tfo8J8jQ4-FH",
    "outputId": "022c24ae-1c6e-40ad-e167-964953449961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 60)           0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 11, 11, 1)    7381        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 28, 28, 1)    9281        sequential_4[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 16,662\n",
      "Trainable params: 16,502\n",
      "Non-trainable params: 160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3013,
     "status": "ok",
     "timestamp": 1554977905348,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "ObTb7HIf5CqA",
    "outputId": "1bdb05c0-cd96-46c6-a124-68ac9ee9ddb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 2, 2, 3)      5859        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12)           0           sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 22)           0           input_1[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1)            23          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,882\n",
      "Trainable params: 5,786\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctWfkxy5i9tR"
   },
   "source": [
    "## Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHTmYpPeImn5"
   },
   "outputs": [],
   "source": [
    "GLR = 0.02  # generator\n",
    "DLR = 0.02  # discriminator\n",
    "\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer=keras.optimizers.Adam(DLR, 0.5),\n",
    "    loss=keras.losses.mse,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# condition\n",
    "# c1 = keras.layers.Input(shape=(enc_len,))\n",
    "c2 = keras.layers.Input(shape=(age_len,))\n",
    "\n",
    "# noise\n",
    "x = keras.layers.Input(shape=(noise_len,))\n",
    "\n",
    "# freeze discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# output\n",
    "z = generator([c2, x])\n",
    "out = discriminator([c2, z])\n",
    "\n",
    "# GAN\n",
    "gan = keras.models.Model(inputs=[c2, x], outputs=out)\n",
    "\n",
    "gan.compile(\n",
    "    optimizer=keras.optimizers.Adam(GLR , 0.5),\n",
    "    loss=keras.losses.mse,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1554977905707,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "o_76rZ0ti9tc",
    "outputId": "8eb9fa73-4621-40e3-fab1-fd2d52d7bbe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 28, 28, 1)    16662       input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            5882        input_5[0][0]                    \n",
      "                                                                 model_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,544\n",
      "Trainable params: 16,502\n",
      "Non-trainable params: 6,042\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REaxJyLqi9tp"
   },
   "source": [
    "## Visualization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25210,
     "status": "ok",
     "timestamp": 1554977927807,
     "user": {
      "displayName": "Mustafa Qamar-ud-Din",
      "photoUrl": "https://lh5.googleusercontent.com/-JYdQ9YNJp_I/AAAAAAAAAAI/AAAAAAAAG-w/S5nt9QpYyIw/s64/photo.jpg",
      "userId": "09937818909262344238"
     },
     "user_tz": -120
    },
    "id": "4kA4g6_lt3D8",
    "outputId": "c5b38cce-ad98-49ac-9b13-950a8e2356ca"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os\n",
    "\n",
    "\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "root_path = './'\n",
    "tgt_pth = os.path.join(root_path, 'visualize_mnist-v19')\n",
    "\n",
    "if not os.path.exists(tgt_pth):\n",
    "  os.mkdir(tgt_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3nB78iWi9ts"
   },
   "outputs": [],
   "source": [
    "def visualizeGAN(e, z_real, z_fake):\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 18))\n",
    "\n",
    "    r_real = 0\n",
    "    r_fake = 0\n",
    "    for row, axe in enumerate(axes):\n",
    "        for col, cell in enumerate(axe):\n",
    "            if row % 2 == 0:\n",
    "                cell.imshow(\n",
    "                    np.squeeze(\n",
    "                        0.5 * z_real[r_real * 4 + col] + 0.5,\n",
    "                        axis=-1\n",
    "                    ),\n",
    "                    cmap='gray'\n",
    "                )\n",
    "            else:\n",
    "                cell.imshow(\n",
    "                    np.squeeze(\n",
    "                        0.5 * z_fake[r_fake * 4 + col] + 0.5,\n",
    "                        axis=-1\n",
    "                    ),\n",
    "                    cmap='gray'\n",
    "                )\n",
    "\n",
    "            cell.axis(\"off\")\n",
    "\n",
    "        if row % 2 == 0:\n",
    "            r_real += 1\n",
    "        else:\n",
    "            r_fake += 1\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(os.path.join(tgt_pth, '{}.jpg'.format(str(e).zfill(3))))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noise():\n",
    "    \n",
    "    y_true = tf.ones((BATCH_SIZE,))\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # run once\n",
    "        y_true = y_true.eval()\n",
    "\n",
    "        while True:\n",
    "            batch_x, batch_y = next(custom_gen)\n",
    "\n",
    "            sz = batch_x.shape[0]\n",
    "\n",
    "            if sz != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # fake data\n",
    "            c2 = tf.cast(batch_y, tf.float32).eval()\n",
    "            x = tf.random.normal((sz, noise_len,)).eval()\n",
    "            \n",
    "            yield c2, x, y_true\n",
    "\n",
    "\n",
    "def load_batch():\n",
    "    \n",
    "    y_fake = tf.zeros((BATCH_SIZE,))\n",
    "    y_true = tf.ones((BATCH_SIZE,))\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # run once\n",
    "        y_fake = y_fake.eval()\n",
    "        y_true = y_true.eval()\n",
    "\n",
    "        while True:\n",
    "            batch_x, batch_y = next(custom_gen)\n",
    "\n",
    "            sz = batch_x.shape[0]\n",
    "\n",
    "            if sz != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            # fake data\n",
    "            c2 = tf.cast(batch_y, tf.float32).eval()\n",
    "            x = tf.random.normal((sz, noise_len,)).eval()\n",
    "            z_fake = generator.predict([c2, x])\n",
    "\n",
    "            # real data\n",
    "            c2 = tf.cast(batch_y, tf.float32).eval()\n",
    "            z_real = batch_x\n",
    "                        \n",
    "            yield c2, x, z_fake, y_fake, z_real, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GNNmDUZi9t3"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 0, D:[ACC: %52.54, LOSS: 34.31], G:[ACC: %43.36, LOSS: 30.13]\n",
      "E: 1, D:[ACC: %48.63, LOSS: 34.91], G:[ACC: %20.70, LOSS: 54.06]\n",
      "E: 2, D:[ACC: %65.62, LOSS: 21.87], G:[ACC: %9.38, LOSS: 64.69]\n",
      "E: 3, D:[ACC: %67.97, LOSS: 24.43], G:[ACC: %34.77, LOSS: 43.47]\n",
      "E: 4, D:[ACC: %57.62, LOSS: 28.74], G:[ACC: %39.06, LOSS: 38.37]\n",
      "E: 5, D:[ACC: %46.09, LOSS: 37.74], G:[ACC: %59.77, LOSS: 25.75]\n",
      "E: 6, D:[ACC: %68.16, LOSS: 22.00], G:[ACC: %21.88, LOSS: 55.83]\n",
      "E: 7, D:[ACC: %79.30, LOSS: 14.05], G:[ACC: %9.77, LOSS: 72.73]\n",
      "E: 8, D:[ACC: %75.98, LOSS: 15.61], G:[ACC: %23.83, LOSS: 61.54]\n",
      "E: 9, D:[ACC: %67.38, LOSS: 21.68], G:[ACC: %16.02, LOSS: 60.22]\n",
      "E: 10, D:[ACC: %53.32, LOSS: 31.99], G:[ACC: %21.09, LOSS: 56.72]\n",
      "E: 11, D:[ACC: %64.84, LOSS: 22.86], G:[ACC: %11.33, LOSS: 66.84]\n",
      "E: 12, D:[ACC: %63.09, LOSS: 22.15], G:[ACC: %12.11, LOSS: 58.82]\n",
      "E: 13, D:[ACC: %45.31, LOSS: 30.14], G:[ACC: %17.19, LOSS: 54.05]\n",
      "E: 14, D:[ACC: %88.09, LOSS: 10.88], G:[ACC: %3.52, LOSS: 70.82]\n",
      "E: 15, D:[ACC: %47.85, LOSS: 31.73], G:[ACC: %55.47, LOSS: 29.23]\n",
      "E: 16, D:[ACC: %78.71, LOSS: 14.86], G:[ACC: %24.61, LOSS: 47.31]\n",
      "E: 17, D:[ACC: %51.76, LOSS: 30.03], G:[ACC: %51.17, LOSS: 31.62]\n",
      "E: 18, D:[ACC: %52.54, LOSS: 27.87], G:[ACC: %36.72, LOSS: 36.78]\n",
      "E: 19, D:[ACC: %78.32, LOSS: 15.04], G:[ACC: %18.36, LOSS: 51.86]\n",
      "E: 20, D:[ACC: %67.38, LOSS: 21.03], G:[ACC: %3.91, LOSS: 68.89]\n",
      "E: 21, D:[ACC: %61.13, LOSS: 23.25], G:[ACC: %27.34, LOSS: 41.60]\n",
      "E: 22, D:[ACC: %56.05, LOSS: 27.28], G:[ACC: %23.83, LOSS: 44.43]\n",
      "E: 23, D:[ACC: %49.41, LOSS: 29.65], G:[ACC: %23.44, LOSS: 40.30]\n",
      "E: 24, D:[ACC: %66.41, LOSS: 20.10], G:[ACC: %12.89, LOSS: 45.42]\n",
      "E: 25, D:[ACC: %67.58, LOSS: 21.55], G:[ACC: %14.06, LOSS: 44.61]\n",
      "E: 26, D:[ACC: %71.48, LOSS: 19.30], G:[ACC: %10.94, LOSS: 49.93]\n",
      "E: 27, D:[ACC: %67.19, LOSS: 19.95], G:[ACC: %10.55, LOSS: 48.71]\n",
      "E: 28, D:[ACC: %63.87, LOSS: 21.37], G:[ACC: %9.77, LOSS: 54.52]\n",
      "E: 29, D:[ACC: %58.79, LOSS: 23.32], G:[ACC: %17.58, LOSS: 50.61]\n",
      "E: 30, D:[ACC: %70.70, LOSS: 18.49], G:[ACC: %10.94, LOSS: 50.87]\n",
      "E: 31, D:[ACC: %63.48, LOSS: 21.14], G:[ACC: %13.28, LOSS: 48.67]\n",
      "E: 32, D:[ACC: %69.53, LOSS: 19.12], G:[ACC: %17.97, LOSS: 47.21]\n",
      "E: 33, D:[ACC: %70.90, LOSS: 18.59], G:[ACC: %19.14, LOSS: 46.60]\n",
      "E: 34, D:[ACC: %77.73, LOSS: 16.94], G:[ACC: %10.55, LOSS: 51.57]\n",
      "E: 35, D:[ACC: %76.17, LOSS: 17.05], G:[ACC: %5.47, LOSS: 60.22]\n",
      "E: 36, D:[ACC: %92.38, LOSS: 9.44], G:[ACC: %1.95, LOSS: 71.87]\n",
      "E: 37, D:[ACC: %91.41, LOSS: 6.76], G:[ACC: %0.78, LOSS: 77.03]\n",
      "E: 38, D:[ACC: %97.27, LOSS: 3.81], G:[ACC: %1.56, LOSS: 79.41]\n",
      "E: 39, D:[ACC: %92.38, LOSS: 7.20], G:[ACC: %3.12, LOSS: 80.12]\n",
      "E: 40, D:[ACC: %83.40, LOSS: 13.42], G:[ACC: %3.91, LOSS: 67.75]\n",
      "E: 41, D:[ACC: %89.65, LOSS: 8.37], G:[ACC: %0.39, LOSS: 79.37]\n",
      "E: 42, D:[ACC: %83.40, LOSS: 12.09], G:[ACC: %0.39, LOSS: 80.40]\n",
      "E: 43, D:[ACC: %79.49, LOSS: 14.20], G:[ACC: %0.00, LOSS: 83.19]\n",
      "E: 44, D:[ACC: %95.31, LOSS: 4.44], G:[ACC: %0.39, LOSS: 87.58]\n",
      "E: 45, D:[ACC: %95.12, LOSS: 4.38], G:[ACC: %0.78, LOSS: 85.79]\n",
      "E: 46, D:[ACC: %97.66, LOSS: 2.47], G:[ACC: %1.17, LOSS: 86.08]\n",
      "E: 47, D:[ACC: %95.31, LOSS: 4.21], G:[ACC: %0.78, LOSS: 80.91]\n",
      "E: 48, D:[ACC: %86.13, LOSS: 9.36], G:[ACC: %0.00, LOSS: 91.33]\n",
      "E: 49, D:[ACC: %50.00, LOSS: 42.73], G:[ACC: %1.17, LOSS: 86.83]\n",
      "E: 50, D:[ACC: %77.15, LOSS: 17.41], G:[ACC: %10.55, LOSS: 64.31]\n",
      "E: 51, D:[ACC: %82.03, LOSS: 12.64], G:[ACC: %2.34, LOSS: 78.69]\n",
      "E: 52, D:[ACC: %91.21, LOSS: 6.70], G:[ACC: %1.56, LOSS: 82.88]\n",
      "E: 53, D:[ACC: %94.34, LOSS: 4.76], G:[ACC: %1.56, LOSS: 82.37]\n",
      "E: 54, D:[ACC: %93.16, LOSS: 5.70], G:[ACC: %3.52, LOSS: 78.62]\n",
      "E: 55, D:[ACC: %95.70, LOSS: 3.72], G:[ACC: %4.69, LOSS: 79.05]\n",
      "E: 56, D:[ACC: %95.70, LOSS: 4.11], G:[ACC: %2.34, LOSS: 84.35]\n",
      "E: 57, D:[ACC: %96.68, LOSS: 3.14], G:[ACC: %3.12, LOSS: 83.78]\n",
      "E: 58, D:[ACC: %94.53, LOSS: 4.51], G:[ACC: %3.52, LOSS: 80.71]\n",
      "E: 59, D:[ACC: %96.68, LOSS: 3.22], G:[ACC: %0.78, LOSS: 83.52]\n",
      "E: 60, D:[ACC: %95.70, LOSS: 4.31], G:[ACC: %1.95, LOSS: 85.29]\n",
      "E: 61, D:[ACC: %95.70, LOSS: 4.46], G:[ACC: %0.39, LOSS: 92.65]\n",
      "E: 62, D:[ACC: %50.00, LOSS: 39.77], G:[ACC: %61.33, LOSS: 26.81]\n",
      "E: 63, D:[ACC: %53.91, LOSS: 36.36], G:[ACC: %8.59, LOSS: 64.45]\n",
      "E: 64, D:[ACC: %37.11, LOSS: 41.20], G:[ACC: %48.05, LOSS: 37.61]\n",
      "E: 65, D:[ACC: %84.18, LOSS: 11.64], G:[ACC: %4.69, LOSS: 69.29]\n",
      "E: 66, D:[ACC: %50.98, LOSS: 29.70], G:[ACC: %10.55, LOSS: 54.95]\n",
      "E: 67, D:[ACC: %61.91, LOSS: 24.47], G:[ACC: %7.03, LOSS: 54.84]\n",
      "E: 68, D:[ACC: %72.85, LOSS: 17.71], G:[ACC: %11.33, LOSS: 62.88]\n",
      "E: 69, D:[ACC: %68.95, LOSS: 20.39], G:[ACC: %18.36, LOSS: 59.14]\n",
      "E: 70, D:[ACC: %60.16, LOSS: 26.69], G:[ACC: %27.73, LOSS: 51.75]\n",
      "E: 71, D:[ACC: %64.26, LOSS: 24.75], G:[ACC: %19.14, LOSS: 58.47]\n",
      "E: 72, D:[ACC: %63.48, LOSS: 23.22], G:[ACC: %4.30, LOSS: 75.49]\n",
      "E: 73, D:[ACC: %59.96, LOSS: 24.39], G:[ACC: %0.39, LOSS: 75.94]\n",
      "E: 74, D:[ACC: %71.09, LOSS: 18.56], G:[ACC: %0.78, LOSS: 76.90]\n",
      "E: 75, D:[ACC: %74.41, LOSS: 17.41], G:[ACC: %1.56, LOSS: 79.60]\n",
      "E: 76, D:[ACC: %76.76, LOSS: 16.28], G:[ACC: %3.52, LOSS: 75.01]\n",
      "E: 77, D:[ACC: %78.12, LOSS: 15.56], G:[ACC: %4.30, LOSS: 75.00]\n",
      "E: 78, D:[ACC: %76.37, LOSS: 16.26], G:[ACC: %7.03, LOSS: 69.41]\n",
      "E: 79, D:[ACC: %75.59, LOSS: 16.51], G:[ACC: %19.92, LOSS: 52.21]\n",
      "E: 80, D:[ACC: %67.97, LOSS: 20.12], G:[ACC: %20.70, LOSS: 49.47]\n",
      "E: 81, D:[ACC: %78.71, LOSS: 14.83], G:[ACC: %25.39, LOSS: 45.55]\n",
      "E: 82, D:[ACC: %84.96, LOSS: 11.82], G:[ACC: %53.12, LOSS: 29.66]\n",
      "E: 83, D:[ACC: %87.70, LOSS: 9.65], G:[ACC: %56.64, LOSS: 26.86]\n",
      "E: 84, D:[ACC: %88.48, LOSS: 9.34], G:[ACC: %64.06, LOSS: 24.31]\n",
      "E: 85, D:[ACC: %89.26, LOSS: 7.66], G:[ACC: %45.70, LOSS: 32.69]\n",
      "E: 86, D:[ACC: %71.68, LOSS: 20.18], G:[ACC: %13.67, LOSS: 54.05]\n",
      "E: 87, D:[ACC: %70.51, LOSS: 18.66], G:[ACC: %14.45, LOSS: 54.74]\n",
      "E: 88, D:[ACC: %68.95, LOSS: 20.55], G:[ACC: %6.25, LOSS: 64.76]\n",
      "E: 89, D:[ACC: %69.14, LOSS: 21.01], G:[ACC: %9.38, LOSS: 62.42]\n",
      "E: 90, D:[ACC: %77.34, LOSS: 16.21], G:[ACC: %4.69, LOSS: 66.49]\n",
      "E: 91, D:[ACC: %64.84, LOSS: 21.31], G:[ACC: %8.20, LOSS: 66.29]\n",
      "E: 92, D:[ACC: %64.65, LOSS: 22.99], G:[ACC: %21.88, LOSS: 49.29]\n",
      "E: 93, D:[ACC: %78.12, LOSS: 15.70], G:[ACC: %22.27, LOSS: 48.64]\n",
      "E: 94, D:[ACC: %76.37, LOSS: 16.59], G:[ACC: %16.80, LOSS: 51.70]\n",
      "E: 95, D:[ACC: %82.81, LOSS: 11.40], G:[ACC: %35.55, LOSS: 37.39]\n",
      "E: 96, D:[ACC: %92.58, LOSS: 6.84], G:[ACC: %21.09, LOSS: 47.32]\n",
      "E: 97, D:[ACC: %88.48, LOSS: 9.04], G:[ACC: %32.81, LOSS: 42.24]\n",
      "E: 98, D:[ACC: %63.28, LOSS: 22.32], G:[ACC: %17.19, LOSS: 56.65]\n",
      "E: 99, D:[ACC: %69.14, LOSS: 19.71], G:[ACC: %19.53, LOSS: 53.53]\n",
      "E: 100, D:[ACC: %49.41, LOSS: 30.59], G:[ACC: %8.98, LOSS: 63.01]\n",
      "E: 101, D:[ACC: %53.71, LOSS: 31.17], G:[ACC: %46.09, LOSS: 32.05]\n",
      "E: 102, D:[ACC: %73.63, LOSS: 16.49], G:[ACC: %6.64, LOSS: 64.00]\n",
      "E: 103, D:[ACC: %64.45, LOSS: 24.27], G:[ACC: %2.73, LOSS: 71.62]\n",
      "E: 104, D:[ACC: %46.09, LOSS: 33.78], G:[ACC: %9.77, LOSS: 57.09]\n",
      "E: 105, D:[ACC: %73.24, LOSS: 17.29], G:[ACC: %6.64, LOSS: 58.08]\n",
      "E: 106, D:[ACC: %59.18, LOSS: 24.62], G:[ACC: %8.59, LOSS: 56.43]\n",
      "E: 107, D:[ACC: %71.09, LOSS: 18.79], G:[ACC: %42.19, LOSS: 35.77]\n",
      "E: 108, D:[ACC: %63.28, LOSS: 22.60], G:[ACC: %1.17, LOSS: 79.11]\n",
      "E: 109, D:[ACC: %68.36, LOSS: 20.26], G:[ACC: %0.00, LOSS: 90.05]\n",
      "E: 110, D:[ACC: %90.23, LOSS: 8.85], G:[ACC: %0.00, LOSS: 96.06]\n",
      "E: 111, D:[ACC: %95.12, LOSS: 4.79], G:[ACC: %0.00, LOSS: 98.76]\n",
      "E: 112, D:[ACC: %97.27, LOSS: 2.75], G:[ACC: %0.00, LOSS: 99.52]\n",
      "E: 113, D:[ACC: %96.68, LOSS: 3.50], G:[ACC: %0.00, LOSS: 99.62]\n",
      "E: 114, D:[ACC: %98.63, LOSS: 1.48], G:[ACC: %0.00, LOSS: 99.57]\n",
      "E: 115, D:[ACC: %89.65, LOSS: 7.67], G:[ACC: %0.00, LOSS: 99.92]\n",
      "E: 116, D:[ACC: %44.73, LOSS: 33.89], G:[ACC: %19.53, LOSS: 52.97]\n",
      "E: 117, D:[ACC: %60.94, LOSS: 23.89], G:[ACC: %10.55, LOSS: 57.25]\n",
      "E: 118, D:[ACC: %46.09, LOSS: 32.61], G:[ACC: %7.42, LOSS: 58.74]\n",
      "E: 119, D:[ACC: %74.22, LOSS: 18.56], G:[ACC: %7.03, LOSS: 61.15]\n",
      "E: 120, D:[ACC: %71.88, LOSS: 18.62], G:[ACC: %5.86, LOSS: 64.79]\n",
      "E: 121, D:[ACC: %67.58, LOSS: 19.96], G:[ACC: %8.98, LOSS: 54.58]\n",
      "E: 122, D:[ACC: %69.73, LOSS: 19.53], G:[ACC: %14.06, LOSS: 51.47]\n",
      "E: 123, D:[ACC: %55.66, LOSS: 26.78], G:[ACC: %21.48, LOSS: 45.34]\n",
      "E: 124, D:[ACC: %55.66, LOSS: 26.21], G:[ACC: %19.53, LOSS: 46.72]\n",
      "E: 125, D:[ACC: %63.28, LOSS: 22.95], G:[ACC: %30.47, LOSS: 36.60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 126, D:[ACC: %59.96, LOSS: 23.79], G:[ACC: %35.16, LOSS: 33.51]\n",
      "E: 127, D:[ACC: %81.25, LOSS: 14.48], G:[ACC: %53.12, LOSS: 28.02]\n",
      "E: 128, D:[ACC: %68.36, LOSS: 20.01], G:[ACC: %57.03, LOSS: 25.04]\n",
      "E: 129, D:[ACC: %54.10, LOSS: 26.59], G:[ACC: %50.78, LOSS: 26.45]\n",
      "E: 130, D:[ACC: %56.45, LOSS: 24.72], G:[ACC: %43.75, LOSS: 30.22]\n",
      "E: 131, D:[ACC: %61.52, LOSS: 24.17], G:[ACC: %52.73, LOSS: 25.95]\n",
      "E: 132, D:[ACC: %82.03, LOSS: 14.33], G:[ACC: %66.41, LOSS: 20.77]\n",
      "E: 133, D:[ACC: %77.93, LOSS: 15.51], G:[ACC: %48.05, LOSS: 30.95]\n",
      "E: 134, D:[ACC: %43.16, LOSS: 35.07], G:[ACC: %21.88, LOSS: 46.69]\n",
      "E: 135, D:[ACC: %81.84, LOSS: 13.84], G:[ACC: %35.16, LOSS: 36.94]\n",
      "E: 136, D:[ACC: %78.52, LOSS: 15.03], G:[ACC: %54.30, LOSS: 27.32]\n",
      "E: 137, D:[ACC: %73.24, LOSS: 18.18], G:[ACC: %27.34, LOSS: 41.45]\n",
      "E: 138, D:[ACC: %39.84, LOSS: 35.54], G:[ACC: %3.91, LOSS: 67.82]\n",
      "E: 139, D:[ACC: %23.63, LOSS: 44.19], G:[ACC: %23.05, LOSS: 38.59]\n",
      "E: 140, D:[ACC: %47.07, LOSS: 28.97], G:[ACC: %25.39, LOSS: 37.28]\n",
      "E: 141, D:[ACC: %55.66, LOSS: 25.68], G:[ACC: %28.52, LOSS: 38.42]\n",
      "E: 142, D:[ACC: %60.35, LOSS: 23.85], G:[ACC: %31.64, LOSS: 35.70]\n",
      "E: 143, D:[ACC: %67.77, LOSS: 22.03], G:[ACC: %43.75, LOSS: 29.96]\n",
      "E: 144, D:[ACC: %66.60, LOSS: 21.55], G:[ACC: %32.42, LOSS: 33.52]\n",
      "E: 145, D:[ACC: %50.78, LOSS: 28.19], G:[ACC: %31.25, LOSS: 33.84]\n",
      "E: 146, D:[ACC: %62.70, LOSS: 22.83], G:[ACC: %33.20, LOSS: 32.94]\n",
      "E: 147, D:[ACC: %51.56, LOSS: 26.55], G:[ACC: %28.91, LOSS: 32.33]\n",
      "E: 148, D:[ACC: %53.71, LOSS: 26.72], G:[ACC: %32.03, LOSS: 32.78]\n",
      "E: 149, D:[ACC: %50.98, LOSS: 26.86], G:[ACC: %35.55, LOSS: 30.80]\n",
      "E: 150, D:[ACC: %59.77, LOSS: 23.74], G:[ACC: %42.97, LOSS: 27.43]\n",
      "E: 151, D:[ACC: %50.20, LOSS: 27.13], G:[ACC: %32.81, LOSS: 32.31]\n",
      "E: 152, D:[ACC: %55.27, LOSS: 26.26], G:[ACC: %17.97, LOSS: 37.45]\n",
      "E: 153, D:[ACC: %51.56, LOSS: 26.66], G:[ACC: %31.64, LOSS: 30.39]\n",
      "E: 154, D:[ACC: %59.77, LOSS: 23.74], G:[ACC: %16.02, LOSS: 37.34]\n",
      "E: 155, D:[ACC: %63.67, LOSS: 23.01], G:[ACC: %26.95, LOSS: 31.68]\n",
      "E: 156, D:[ACC: %63.48, LOSS: 23.18], G:[ACC: %38.67, LOSS: 28.07]\n",
      "E: 157, D:[ACC: %57.03, LOSS: 24.85], G:[ACC: %10.55, LOSS: 39.31]\n",
      "E: 158, D:[ACC: %55.47, LOSS: 26.87], G:[ACC: %20.70, LOSS: 35.55]\n",
      "E: 159, D:[ACC: %58.79, LOSS: 24.48], G:[ACC: %28.12, LOSS: 32.09]\n",
      "E: 160, D:[ACC: %54.30, LOSS: 25.14], G:[ACC: %27.34, LOSS: 32.74]\n",
      "E: 161, D:[ACC: %63.67, LOSS: 22.17], G:[ACC: %40.62, LOSS: 28.54]\n",
      "E: 162, D:[ACC: %65.82, LOSS: 21.42], G:[ACC: %30.08, LOSS: 32.64]\n",
      "E: 163, D:[ACC: %63.09, LOSS: 22.64], G:[ACC: %14.45, LOSS: 39.82]\n",
      "E: 164, D:[ACC: %64.26, LOSS: 22.26], G:[ACC: %15.62, LOSS: 38.10]\n",
      "E: 165, D:[ACC: %62.11, LOSS: 22.68], G:[ACC: %12.89, LOSS: 37.69]\n",
      "E: 166, D:[ACC: %51.37, LOSS: 26.87], G:[ACC: %8.20, LOSS: 39.88]\n",
      "E: 167, D:[ACC: %58.20, LOSS: 24.49], G:[ACC: %7.03, LOSS: 41.47]\n",
      "E: 168, D:[ACC: %61.13, LOSS: 24.34], G:[ACC: %3.12, LOSS: 41.37]\n",
      "E: 169, D:[ACC: %76.56, LOSS: 19.33], G:[ACC: %3.12, LOSS: 38.56]\n",
      "E: 170, D:[ACC: %36.52, LOSS: 29.15], G:[ACC: %2.34, LOSS: 44.51]\n",
      "E: 171, D:[ACC: %92.97, LOSS: 10.82], G:[ACC: %3.52, LOSS: 43.37]\n",
      "E: 172, D:[ACC: %94.34, LOSS: 11.28], G:[ACC: %3.91, LOSS: 45.40]\n",
      "E: 173, D:[ACC: %87.89, LOSS: 11.13], G:[ACC: %1.95, LOSS: 48.36]\n",
      "E: 174, D:[ACC: %84.38, LOSS: 11.81], G:[ACC: %1.17, LOSS: 53.44]\n",
      "E: 175, D:[ACC: %88.09, LOSS: 12.56], G:[ACC: %0.78, LOSS: 56.68]\n",
      "E: 176, D:[ACC: %91.99, LOSS: 10.31], G:[ACC: %1.17, LOSS: 61.03]\n",
      "E: 177, D:[ACC: %97.66, LOSS: 2.43], G:[ACC: %1.95, LOSS: 62.96]\n",
      "E: 178, D:[ACC: %98.83, LOSS: 1.13], G:[ACC: %3.91, LOSS: 60.33]\n",
      "E: 179, D:[ACC: %99.22, LOSS: 2.25], G:[ACC: %6.64, LOSS: 58.99]\n",
      "E: 180, D:[ACC: %94.53, LOSS: 6.53], G:[ACC: %7.42, LOSS: 61.38]\n",
      "E: 181, D:[ACC: %95.12, LOSS: 4.43], G:[ACC: %1.17, LOSS: 70.18]\n",
      "E: 182, D:[ACC: %97.85, LOSS: 2.97], G:[ACC: %0.78, LOSS: 75.54]\n",
      "E: 183, D:[ACC: %98.83, LOSS: 2.14], G:[ACC: %0.78, LOSS: 76.54]\n",
      "E: 184, D:[ACC: %99.02, LOSS: 2.07], G:[ACC: %1.95, LOSS: 76.56]\n",
      "E: 185, D:[ACC: %95.90, LOSS: 3.71], G:[ACC: %1.56, LOSS: 79.95]\n",
      "E: 186, D:[ACC: %97.46, LOSS: 2.46], G:[ACC: %0.78, LOSS: 84.00]\n",
      "E: 187, D:[ACC: %97.46, LOSS: 2.20], G:[ACC: %0.00, LOSS: 85.18]\n",
      "E: 188, D:[ACC: %99.61, LOSS: 0.92], G:[ACC: %0.00, LOSS: 86.99]\n",
      "E: 189, D:[ACC: %99.61, LOSS: 0.84], G:[ACC: %0.39, LOSS: 87.18]\n",
      "E: 190, D:[ACC: %99.41, LOSS: 0.91], G:[ACC: %0.00, LOSS: 88.12]\n",
      "E: 191, D:[ACC: %99.22, LOSS: 0.93], G:[ACC: %0.00, LOSS: 89.15]\n",
      "E: 192, D:[ACC: %99.80, LOSS: 0.50], G:[ACC: %0.00, LOSS: 90.04]\n",
      "E: 193, D:[ACC: %100.00, LOSS: 0.58], G:[ACC: %0.00, LOSS: 90.50]\n",
      "E: 194, D:[ACC: %98.44, LOSS: 1.36], G:[ACC: %0.00, LOSS: 90.75]\n",
      "E: 195, D:[ACC: %99.41, LOSS: 0.73], G:[ACC: %0.00, LOSS: 91.51]\n",
      "E: 196, D:[ACC: %99.61, LOSS: 0.62], G:[ACC: %0.39, LOSS: 91.73]\n",
      "E: 197, D:[ACC: %98.63, LOSS: 1.55], G:[ACC: %0.00, LOSS: 91.97]\n",
      "E: 198, D:[ACC: %99.41, LOSS: 0.73], G:[ACC: %0.00, LOSS: 92.22]\n",
      "E: 199, D:[ACC: %99.02, LOSS: 1.34], G:[ACC: %0.00, LOSS: 92.42]\n",
      "E: 200, D:[ACC: %98.24, LOSS: 2.08], G:[ACC: %0.00, LOSS: 94.11]\n",
      "E: 201, D:[ACC: %96.68, LOSS: 3.10], G:[ACC: %0.00, LOSS: 94.53]\n",
      "E: 202, D:[ACC: %98.83, LOSS: 1.85], G:[ACC: %0.00, LOSS: 94.91]\n",
      "E: 203, D:[ACC: %99.02, LOSS: 1.21], G:[ACC: %0.00, LOSS: 95.13]\n",
      "E: 204, D:[ACC: %99.41, LOSS: 1.07], G:[ACC: %0.00, LOSS: 95.83]\n",
      "E: 205, D:[ACC: %99.80, LOSS: 0.46], G:[ACC: %0.00, LOSS: 96.14]\n",
      "E: 206, D:[ACC: %99.61, LOSS: 1.04], G:[ACC: %0.00, LOSS: 95.59]\n",
      "E: 207, D:[ACC: %99.80, LOSS: 0.58], G:[ACC: %0.00, LOSS: 97.03]\n",
      "E: 208, D:[ACC: %99.80, LOSS: 1.03], G:[ACC: %0.00, LOSS: 96.64]\n",
      "E: 209, D:[ACC: %98.44, LOSS: 2.46], G:[ACC: %0.00, LOSS: 97.98]\n",
      "E: 210, D:[ACC: %39.84, LOSS: 54.21], G:[ACC: %58.59, LOSS: 24.83]\n",
      "E: 211, D:[ACC: %49.22, LOSS: 50.61], G:[ACC: %91.41, LOSS: 7.32]\n",
      "E: 212, D:[ACC: %48.44, LOSS: 51.04], G:[ACC: %99.61, LOSS: 0.29]\n",
      "E: 213, D:[ACC: %50.00, LOSS: 49.99], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 214, D:[ACC: %50.00, LOSS: 49.98], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 215, D:[ACC: %50.20, LOSS: 49.79], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 216, D:[ACC: %50.00, LOSS: 49.96], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 217, D:[ACC: %49.80, LOSS: 50.14], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 218, D:[ACC: %50.00, LOSS: 49.92], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 219, D:[ACC: %49.80, LOSS: 49.59], G:[ACC: %100.00, LOSS: 0.01]\n",
      "E: 220, D:[ACC: %50.00, LOSS: 49.88], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 221, D:[ACC: %50.39, LOSS: 49.55], G:[ACC: %100.00, LOSS: 0.01]\n",
      "E: 222, D:[ACC: %49.80, LOSS: 49.70], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 223, D:[ACC: %49.80, LOSS: 49.95], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 224, D:[ACC: %50.00, LOSS: 49.87], G:[ACC: %100.00, LOSS: 0.05]\n",
      "E: 225, D:[ACC: %50.39, LOSS: 49.34], G:[ACC: %100.00, LOSS: 0.06]\n",
      "E: 226, D:[ACC: %50.39, LOSS: 49.32], G:[ACC: %100.00, LOSS: 0.05]\n",
      "E: 227, D:[ACC: %50.20, LOSS: 49.26], G:[ACC: %100.00, LOSS: 0.11]\n",
      "E: 228, D:[ACC: %50.20, LOSS: 49.15], G:[ACC: %100.00, LOSS: 0.11]\n",
      "E: 229, D:[ACC: %50.98, LOSS: 48.16], G:[ACC: %98.05, LOSS: 1.52]\n",
      "E: 230, D:[ACC: %52.15, LOSS: 46.26], G:[ACC: %78.91, LOSS: 15.60]\n",
      "E: 231, D:[ACC: %41.21, LOSS: 54.58], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 232, D:[ACC: %50.00, LOSS: 49.61], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 233, D:[ACC: %50.00, LOSS: 49.62], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 234, D:[ACC: %50.00, LOSS: 49.33], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 235, D:[ACC: %50.98, LOSS: 48.44], G:[ACC: %100.00, LOSS: 0.00]\n",
      "E: 236, D:[ACC: %53.71, LOSS: 44.47], G:[ACC: %98.44, LOSS: 1.06]\n",
      "E: 237, D:[ACC: %60.74, LOSS: 34.06], G:[ACC: %0.00, LOSS: 98.88]\n",
      "E: 238, D:[ACC: %50.78, LOSS: 46.92], G:[ACC: %0.78, LOSS: 95.57]\n",
      "E: 239, D:[ACC: %47.85, LOSS: 47.59], G:[ACC: %2.34, LOSS: 90.09]\n",
      "E: 240, D:[ACC: %47.85, LOSS: 45.60], G:[ACC: %6.25, LOSS: 84.02]\n",
      "E: 241, D:[ACC: %52.15, LOSS: 42.35], G:[ACC: %7.03, LOSS: 80.01]\n",
      "E: 242, D:[ACC: %46.29, LOSS: 45.79], G:[ACC: %3.91, LOSS: 82.97]\n",
      "E: 243, D:[ACC: %41.99, LOSS: 44.72], G:[ACC: %4.69, LOSS: 78.07]\n",
      "E: 244, D:[ACC: %42.97, LOSS: 43.67], G:[ACC: %3.91, LOSS: 67.66]\n",
      "E: 245, D:[ACC: %42.19, LOSS: 40.63], G:[ACC: %4.69, LOSS: 59.04]\n",
      "E: 246, D:[ACC: %42.58, LOSS: 36.28], G:[ACC: %5.47, LOSS: 63.35]\n",
      "E: 247, D:[ACC: %39.65, LOSS: 33.10], G:[ACC: %7.03, LOSS: 52.68]\n",
      "E: 248, D:[ACC: %44.53, LOSS: 29.99], G:[ACC: %14.84, LOSS: 53.00]\n",
      "E: 249, D:[ACC: %49.41, LOSS: 27.84], G:[ACC: %21.88, LOSS: 47.60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 250, D:[ACC: %35.35, LOSS: 32.16], G:[ACC: %17.19, LOSS: 42.48]\n",
      "E: 251, D:[ACC: %48.63, LOSS: 27.93], G:[ACC: %21.48, LOSS: 35.15]\n",
      "E: 252, D:[ACC: %66.60, LOSS: 22.75], G:[ACC: %36.33, LOSS: 29.79]\n",
      "E: 253, D:[ACC: %72.07, LOSS: 18.68], G:[ACC: %50.78, LOSS: 27.37]\n",
      "E: 254, D:[ACC: %66.60, LOSS: 19.67], G:[ACC: %47.66, LOSS: 29.28]\n",
      "E: 255, D:[ACC: %63.09, LOSS: 22.69], G:[ACC: %15.23, LOSS: 38.97]\n",
      "E: 256, D:[ACC: %51.37, LOSS: 28.06], G:[ACC: %8.98, LOSS: 41.71]\n",
      "E: 257, D:[ACC: %58.01, LOSS: 24.36], G:[ACC: %10.16, LOSS: 42.36]\n",
      "E: 258, D:[ACC: %45.12, LOSS: 28.56], G:[ACC: %11.72, LOSS: 42.18]\n",
      "E: 259, D:[ACC: %64.65, LOSS: 22.59], G:[ACC: %11.72, LOSS: 46.85]\n",
      "E: 260, D:[ACC: %59.57, LOSS: 24.46], G:[ACC: %10.94, LOSS: 46.15]\n",
      "E: 261, D:[ACC: %52.54, LOSS: 26.10], G:[ACC: %15.62, LOSS: 45.38]\n",
      "E: 262, D:[ACC: %45.12, LOSS: 29.47], G:[ACC: %21.48, LOSS: 38.56]\n",
      "E: 263, D:[ACC: %51.37, LOSS: 26.14], G:[ACC: %19.53, LOSS: 41.34]\n",
      "E: 264, D:[ACC: %55.27, LOSS: 26.31], G:[ACC: %17.58, LOSS: 40.79]\n",
      "E: 265, D:[ACC: %54.69, LOSS: 25.20], G:[ACC: %22.27, LOSS: 38.12]\n",
      "E: 266, D:[ACC: %56.05, LOSS: 23.97], G:[ACC: %19.14, LOSS: 41.05]\n",
      "E: 267, D:[ACC: %58.01, LOSS: 24.02], G:[ACC: %28.52, LOSS: 35.35]\n",
      "E: 268, D:[ACC: %53.71, LOSS: 25.69], G:[ACC: %33.98, LOSS: 32.29]\n",
      "E: 269, D:[ACC: %60.16, LOSS: 24.48], G:[ACC: %30.08, LOSS: 34.40]\n",
      "E: 270, D:[ACC: %53.12, LOSS: 25.82], G:[ACC: %29.69, LOSS: 32.20]\n",
      "E: 271, D:[ACC: %59.96, LOSS: 23.38], G:[ACC: %33.98, LOSS: 33.17]\n",
      "E: 272, D:[ACC: %63.87, LOSS: 22.00], G:[ACC: %39.45, LOSS: 30.67]\n",
      "E: 273, D:[ACC: %54.49, LOSS: 25.41], G:[ACC: %42.58, LOSS: 28.38]\n",
      "E: 274, D:[ACC: %53.71, LOSS: 26.34], G:[ACC: %39.06, LOSS: 28.72]\n",
      "E: 275, D:[ACC: %47.07, LOSS: 27.79], G:[ACC: %39.45, LOSS: 28.24]\n",
      "E: 276, D:[ACC: %51.37, LOSS: 24.26], G:[ACC: %35.94, LOSS: 30.56]\n",
      "E: 277, D:[ACC: %49.02, LOSS: 25.34], G:[ACC: %28.52, LOSS: 32.71]\n",
      "E: 278, D:[ACC: %47.85, LOSS: 26.22], G:[ACC: %30.86, LOSS: 31.05]\n",
      "E: 279, D:[ACC: %57.23, LOSS: 23.43], G:[ACC: %21.48, LOSS: 33.74]\n",
      "E: 280, D:[ACC: %53.52, LOSS: 25.55], G:[ACC: %19.14, LOSS: 35.32]\n",
      "E: 281, D:[ACC: %62.50, LOSS: 22.12], G:[ACC: %19.92, LOSS: 36.49]\n",
      "E: 282, D:[ACC: %60.16, LOSS: 22.98], G:[ACC: %10.94, LOSS: 39.74]\n",
      "E: 283, D:[ACC: %58.40, LOSS: 23.50], G:[ACC: %6.64, LOSS: 43.04]\n",
      "E: 284, D:[ACC: %68.75, LOSS: 20.59], G:[ACC: %9.77, LOSS: 42.64]\n",
      "E: 285, D:[ACC: %56.64, LOSS: 24.51], G:[ACC: %12.50, LOSS: 41.46]\n",
      "E: 286, D:[ACC: %59.96, LOSS: 23.75], G:[ACC: %11.33, LOSS: 41.18]\n",
      "E: 287, D:[ACC: %54.88, LOSS: 25.25], G:[ACC: %9.77, LOSS: 42.31]\n",
      "E: 288, D:[ACC: %61.91, LOSS: 22.29], G:[ACC: %10.94, LOSS: 42.89]\n",
      "E: 289, D:[ACC: %62.70, LOSS: 21.83], G:[ACC: %10.55, LOSS: 43.95]\n",
      "E: 290, D:[ACC: %65.43, LOSS: 22.30], G:[ACC: %7.42, LOSS: 46.39]\n",
      "E: 291, D:[ACC: %58.40, LOSS: 23.45], G:[ACC: %6.25, LOSS: 46.92]\n",
      "E: 292, D:[ACC: %56.25, LOSS: 25.42], G:[ACC: %1.95, LOSS: 45.19]\n",
      "E: 293, D:[ACC: %57.62, LOSS: 25.66], G:[ACC: %4.30, LOSS: 45.73]\n",
      "E: 294, D:[ACC: %64.06, LOSS: 22.23], G:[ACC: %4.30, LOSS: 42.71]\n",
      "E: 295, D:[ACC: %66.41, LOSS: 21.40], G:[ACC: %3.91, LOSS: 44.27]\n",
      "E: 296, D:[ACC: %73.05, LOSS: 18.95], G:[ACC: %3.12, LOSS: 45.86]\n",
      "E: 297, D:[ACC: %89.26, LOSS: 12.05], G:[ACC: %3.12, LOSS: 43.15]\n",
      "E: 298, D:[ACC: %90.04, LOSS: 11.35], G:[ACC: %0.78, LOSS: 47.29]\n",
      "E: 299, D:[ACC: %98.05, LOSS: 5.31], G:[ACC: %0.78, LOSS: 49.35]\n",
      "E: 300, D:[ACC: %95.12, LOSS: 5.94], G:[ACC: %2.34, LOSS: 50.32]\n",
      "E: 301, D:[ACC: %99.41, LOSS: 2.13], G:[ACC: %0.39, LOSS: 53.06]\n",
      "E: 302, D:[ACC: %99.80, LOSS: 4.22], G:[ACC: %1.17, LOSS: 60.97]\n",
      "E: 303, D:[ACC: %97.85, LOSS: 3.42], G:[ACC: %0.39, LOSS: 74.07]\n",
      "E: 304, D:[ACC: %99.80, LOSS: 0.90], G:[ACC: %0.39, LOSS: 82.29]\n",
      "E: 305, D:[ACC: %99.61, LOSS: 0.64], G:[ACC: %1.17, LOSS: 85.62]\n",
      "E: 306, D:[ACC: %99.61, LOSS: 0.56], G:[ACC: %0.00, LOSS: 88.06]\n",
      "E: 307, D:[ACC: %99.41, LOSS: 0.71], G:[ACC: %0.00, LOSS: 88.20]\n",
      "E: 308, D:[ACC: %99.41, LOSS: 0.47], G:[ACC: %0.00, LOSS: 88.93]\n",
      "E: 309, D:[ACC: %100.00, LOSS: 0.28], G:[ACC: %0.39, LOSS: 88.79]\n",
      "E: 310, D:[ACC: %99.61, LOSS: 0.62], G:[ACC: %1.17, LOSS: 90.41]\n",
      "E: 311, D:[ACC: %97.66, LOSS: 1.95], G:[ACC: %0.00, LOSS: 94.61]\n",
      "E: 312, D:[ACC: %99.61, LOSS: 0.45], G:[ACC: %0.00, LOSS: 95.70]\n",
      "E: 313, D:[ACC: %99.80, LOSS: 0.36], G:[ACC: %0.00, LOSS: 95.55]\n",
      "E: 314, D:[ACC: %99.61, LOSS: 0.51], G:[ACC: %0.00, LOSS: 95.62]\n",
      "E: 315, D:[ACC: %99.80, LOSS: 0.40], G:[ACC: %0.00, LOSS: 94.86]\n",
      "E: 316, D:[ACC: %97.27, LOSS: 2.09], G:[ACC: %2.34, LOSS: 93.18]\n",
      "E: 317, D:[ACC: %97.27, LOSS: 2.06], G:[ACC: %0.00, LOSS: 97.32]\n",
      "E: 318, D:[ACC: %100.00, LOSS: 0.37], G:[ACC: %0.00, LOSS: 97.96]\n",
      "E: 319, D:[ACC: %99.02, LOSS: 0.96], G:[ACC: %0.00, LOSS: 97.39]\n",
      "E: 320, D:[ACC: %100.00, LOSS: 0.49], G:[ACC: %0.00, LOSS: 97.19]\n",
      "E: 321, D:[ACC: %99.61, LOSS: 0.63], G:[ACC: %0.00, LOSS: 97.54]\n",
      "E: 322, D:[ACC: %99.02, LOSS: 1.19], G:[ACC: %0.00, LOSS: 97.35]\n",
      "E: 323, D:[ACC: %99.80, LOSS: 0.48], G:[ACC: %0.00, LOSS: 98.06]\n",
      "E: 324, D:[ACC: %99.02, LOSS: 0.74], G:[ACC: %0.00, LOSS: 97.96]\n",
      "E: 325, D:[ACC: %100.00, LOSS: 0.17], G:[ACC: %0.00, LOSS: 97.79]\n",
      "E: 326, D:[ACC: %100.00, LOSS: 0.21], G:[ACC: %0.00, LOSS: 97.57]\n",
      "E: 327, D:[ACC: %99.80, LOSS: 0.40], G:[ACC: %0.39, LOSS: 97.18]\n",
      "E: 328, D:[ACC: %99.22, LOSS: 0.66], G:[ACC: %0.39, LOSS: 97.64]\n",
      "E: 329, D:[ACC: %99.80, LOSS: 0.37], G:[ACC: %0.00, LOSS: 97.93]\n",
      "E: 330, D:[ACC: %99.02, LOSS: 1.00], G:[ACC: %0.39, LOSS: 96.59]\n",
      "E: 331, D:[ACC: %100.00, LOSS: 0.24], G:[ACC: %0.39, LOSS: 97.38]\n",
      "E: 332, D:[ACC: %99.80, LOSS: 0.40], G:[ACC: %0.00, LOSS: 97.50]\n",
      "E: 333, D:[ACC: %100.00, LOSS: 0.35], G:[ACC: %0.00, LOSS: 97.61]\n",
      "E: 334, D:[ACC: %98.44, LOSS: 1.42], G:[ACC: %0.00, LOSS: 98.47]\n",
      "E: 335, D:[ACC: %99.02, LOSS: 1.57], G:[ACC: %0.39, LOSS: 96.43]\n",
      "E: 336, D:[ACC: %99.61, LOSS: 0.37], G:[ACC: %0.39, LOSS: 96.61]\n",
      "E: 337, D:[ACC: %99.41, LOSS: 0.55], G:[ACC: %0.39, LOSS: 97.15]\n",
      "E: 338, D:[ACC: %78.32, LOSS: 14.36], G:[ACC: %0.00, LOSS: 99.95]\n",
      "E: 339, D:[ACC: %50.00, LOSS: 49.98], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 340, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 341, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 342, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 343, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 344, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 345, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 346, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 347, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 348, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 349, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 350, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 351, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 352, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 353, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 354, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 355, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 356, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 357, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 358, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 359, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 360, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 361, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 362, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 363, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 364, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 365, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 366, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 367, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 368, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 369, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 370, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 371, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 372, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 373, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 374, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 375, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 376, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 377, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 378, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 379, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 380, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 381, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 382, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 383, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 384, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 385, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 386, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 387, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 388, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 389, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 390, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 391, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 392, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 393, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 394, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 395, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 396, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 397, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 398, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 399, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 400, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 401, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 402, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 403, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 404, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 405, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 406, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 407, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 408, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 409, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 410, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 411, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 412, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 413, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 414, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 415, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 416, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 417, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 418, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 419, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 420, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 421, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 422, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 423, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 424, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 425, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 426, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 427, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 428, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 429, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 430, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 431, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 432, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 433, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 434, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 435, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 436, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 437, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 438, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 439, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 440, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 441, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 442, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 443, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 444, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 445, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 446, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 447, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 448, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 449, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 450, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 451, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 452, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 453, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 454, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 455, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 456, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 457, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 458, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 459, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 460, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 461, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 462, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 463, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 464, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 465, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 466, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 467, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 468, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 469, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 470, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 471, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 472, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 473, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 474, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 475, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 476, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 477, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 478, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 479, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 480, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 481, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 482, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 483, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 484, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 485, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 486, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 487, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 488, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 489, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 490, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 491, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 492, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 493, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 494, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 495, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 496, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 497, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 498, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 499, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 500, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 501, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 502, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 503, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 504, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 505, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 506, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 507, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 508, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 509, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n",
      "E: 510, D:[ACC: %50.00, LOSS: 50.00], G:[ACC: %0.00, LOSS: 100.00]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "STEPS = 1  # 60000 // BATCH_SIZE\n",
    "\n",
    "\n",
    "train_loss_g = []\n",
    "train_loss_d = []\n",
    "\n",
    "train_acc_g = []\n",
    "train_acc_d = []\n",
    "\n",
    "\n",
    "disc_itr = load_batch()\n",
    "gen_itr = load_noise()\n",
    "\n",
    "\n",
    "# epochs\n",
    "for e in range(EPOCHS):\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "        \n",
    "        c2, x, z_fake, y_fake, z_real, y_real = next(disc_itr)\n",
    "    \n",
    "        # train\n",
    "        loss_2, acc_2 = discriminator.train_on_batch([c2, z_real], y_real)\n",
    "        loss_1, acc_1 = discriminator.train_on_batch([c2, z_fake], y_fake)\n",
    "\n",
    "        batch_loss = 0.5 * (loss_1 + loss_2)\n",
    "        batch_acc = 0.5 * (acc_1 + acc_2)\n",
    "\n",
    "        loss.append(batch_loss)\n",
    "        acc.append(batch_acc)\n",
    "\n",
    "    train_loss_d.append(np.mean(np.array(loss)))\n",
    "    train_acc_d.append(np.mean(np.array(acc)))\n",
    "\n",
    "    #batches\n",
    "    loss = []\n",
    "    acc = []\n",
    "\n",
    "    for p in range(STEPS):\n",
    "\n",
    "      c2, x, y_true = next(gen_itr)\n",
    "\n",
    "      # train\n",
    "      loss_1, acc_1 = gan.train_on_batch([c2, x], y_true)\n",
    "\n",
    "      loss.append(loss_1)\n",
    "      acc.append(acc_1)\n",
    "\n",
    "    train_loss_g.append(np.mean(np.array(loss)))\n",
    "    train_acc_g.append(np.mean(np.array(acc)))\n",
    "\n",
    "\n",
    "    print(\"E: {}, D:[ACC: %{:.2f}, LOSS: {:.2f}], G:[ACC: %{:.2f}, LOSS: {:.2f}]\".format(\n",
    "          e,\n",
    "          train_acc_d[-1] * 100,\n",
    "          train_loss_d[-1] * 100,\n",
    "          train_acc_g[-1] * 100,\n",
    "          train_loss_g[-1] * 100\n",
    "      ))\n",
    "\n",
    "    if e % 100 == 0:\n",
    "        ## visualize results\n",
    "        c2, x, z_fake, y_fake, z_real, y_real = next(disc_itr)\n",
    "        visualizeGAN(e, z_real, z_fake)\n",
    "        \n",
    "        ## save model\n",
    "        pth = os.path.join(models_path, 'gan.h5')\n",
    "        gan.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'generator-{}-{}-{}.h5'.format(e, train_loss_g[-1], train_acc_g[-1]))\n",
    "        generator.save(pth)\n",
    "\n",
    "        pth = os.path.join(models_path, 'discriminator.h5')\n",
    "        discriminator.save(pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnlcqEI8i9uH"
   },
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LzhKde-CaDu"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_loss_g, label=\"Generator Loss\");\n",
    "plt.plot(train_loss_d, label=\"Discriminator Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9iCkvcai9uS"
   },
   "source": [
    "## Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YhSUa3fROSg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(train_acc_g, label=\"Generator Accuracy\");\n",
    "plt.plot(train_acc_d, label=\"Discriminator Accuracy\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1koOVNb_i9vD"
   },
   "outputs": [],
   "source": [
    "generator.save('./mnist-gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.save('./mnist-disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save('./mnist-gan.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST Test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
